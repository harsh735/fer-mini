{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, concat, slice, stack, tensor, tidy, unstack, util, io, Tensor, add, addN, mod, mul, div, divNoNan, floorDiv, sub, minimum, maximum, pow, squaredDifference, abs, acos, acosh, asin, asinh, atan, atan2, atanh, ceil, complex, cos, cosh, elu, erf, exp, expm1, floor, log, log1p, imag, neg, reciprocal, real, relu, round, selu, sigmoid, sin, sign, sinh, softplus, sqrt, square, tanh, tan, clipByValue, rsqrt, prod, leakyRelu, prelu, scalar, conv1d, conv2d, fused, conv2dTranspose, depthwiseConv2d, conv3d, avgPool, maxPool, maxPoolWithArgmax, avgPool3d, maxPool3d, fill, linspace, multinomial, oneHot, ones, onesLike, randomUniform, range, truncatedNormal, zeros, zerosLike, image, whereAsync, setdiff1dAsync, topk, tensor1d, equal, notEqual, greater, greaterEqual, less, lessEqual, logicalAnd, logicalNot, logicalOr, where, matMul, transpose, batchNorm, localResponseNormalization, softmax, logSoftmax, sparseToDense, max, mean, min, sum, all, any, argMax, argMin, gather, reverse, stridedSlice, tile, split, scatterND, gatherND, fft, ifft, rfft, irfft, cast, expandDims, squeeze, reshape, pad, spaceToBatchND, batchToSpaceND, depthToSpace } from \"@tensorflow/tfjs-core\";\n\nvar DataType,\n    SaverDef,\n    __assign = function () {\n  return (__assign = Object.assign || function (e) {\n    for (var t, a = 1, r = arguments.length; a < r; a++) for (var n in t = arguments[a]) Object.prototype.hasOwnProperty.call(t, n) && (e[n] = t[n]);\n\n    return e;\n  }).apply(this, arguments);\n};\n\nfunction __awaiter(e, t, a, r) {\n  return new (a || (a = Promise))(function (n, s) {\n    function o(e) {\n      try {\n        u(r.next(e));\n      } catch (e) {\n        s(e);\n      }\n    }\n\n    function p(e) {\n      try {\n        u(r.throw(e));\n      } catch (e) {\n        s(e);\n      }\n    }\n\n    function u(e) {\n      e.done ? n(e.value) : new a(function (t) {\n        t(e.value);\n      }).then(o, p);\n    }\n\n    u((r = r.apply(e, t || [])).next());\n  });\n}\n\nfunction __generator(e, t) {\n  var a,\n      r,\n      n,\n      s,\n      o = {\n    label: 0,\n    sent: function () {\n      if (1 & n[0]) throw n[1];\n      return n[1];\n    },\n    trys: [],\n    ops: []\n  };\n  return s = {\n    next: p(0),\n    throw: p(1),\n    return: p(2)\n  }, \"function\" == typeof Symbol && (s[Symbol.iterator] = function () {\n    return this;\n  }), s;\n\n  function p(s) {\n    return function (p) {\n      return function (s) {\n        if (a) throw new TypeError(\"Generator is already executing.\");\n\n        for (; o;) try {\n          if (a = 1, r && (n = 2 & s[0] ? r.return : s[0] ? r.throw || ((n = r.return) && n.call(r), 0) : r.next) && !(n = n.call(r, s[1])).done) return n;\n\n          switch (r = 0, n && (s = [2 & s[0], n.value]), s[0]) {\n            case 0:\n            case 1:\n              n = s;\n              break;\n\n            case 4:\n              return o.label++, {\n                value: s[1],\n                done: !1\n              };\n\n            case 5:\n              o.label++, r = s[1], s = [0];\n              continue;\n\n            case 7:\n              s = o.ops.pop(), o.trys.pop();\n              continue;\n\n            default:\n              if (!(n = (n = o.trys).length > 0 && n[n.length - 1]) && (6 === s[0] || 2 === s[0])) {\n                o = 0;\n                continue;\n              }\n\n              if (3 === s[0] && (!n || s[1] > n[0] && s[1] < n[3])) {\n                o.label = s[1];\n                break;\n              }\n\n              if (6 === s[0] && o.label < n[1]) {\n                o.label = n[1], n = s;\n                break;\n              }\n\n              if (n && o.label < n[2]) {\n                o.label = n[2], o.ops.push(s);\n                break;\n              }\n\n              n[2] && o.ops.pop(), o.trys.pop();\n              continue;\n          }\n\n          s = t.call(e, o);\n        } catch (e) {\n          s = [6, e], r = 0;\n        } finally {\n          a = n = 0;\n        }\n\n        if (5 & s[0]) throw s[1];\n        return {\n          value: s[0] ? s[1] : void 0,\n          done: !0\n        };\n      }([s, p]);\n    };\n  }\n}\n\n!function (e) {\n  e[e.DT_INVALID = 0] = \"DT_INVALID\", e[e.DT_FLOAT = 1] = \"DT_FLOAT\", e[e.DT_DOUBLE = 2] = \"DT_DOUBLE\", e[e.DT_INT32 = 3] = \"DT_INT32\", e[e.DT_UINT8 = 4] = \"DT_UINT8\", e[e.DT_INT16 = 5] = \"DT_INT16\", e[e.DT_INT8 = 6] = \"DT_INT8\", e[e.DT_STRING = 7] = \"DT_STRING\", e[e.DT_COMPLEX64 = 8] = \"DT_COMPLEX64\", e[e.DT_INT64 = 9] = \"DT_INT64\", e[e.DT_BOOL = 10] = \"DT_BOOL\", e[e.DT_QINT8 = 11] = \"DT_QINT8\", e[e.DT_QUINT8 = 12] = \"DT_QUINT8\", e[e.DT_QINT32 = 13] = \"DT_QINT32\", e[e.DT_BFLOAT16 = 14] = \"DT_BFLOAT16\", e[e.DT_FLOAT_REF = 101] = \"DT_FLOAT_REF\", e[e.DT_DOUBLE_REF = 102] = \"DT_DOUBLE_REF\", e[e.DT_INT32_REF = 103] = \"DT_INT32_REF\", e[e.DT_UINT8_REF = 104] = \"DT_UINT8_REF\", e[e.DT_INT16_REF = 105] = \"DT_INT16_REF\", e[e.DT_INT8_REF = 106] = \"DT_INT8_REF\", e[e.DT_STRING_REF = 107] = \"DT_STRING_REF\", e[e.DT_COMPLEX64_REF = 108] = \"DT_COMPLEX64_REF\", e[e.DT_INT64_REF = 109] = \"DT_INT64_REF\", e[e.DT_BOOL_REF = 110] = \"DT_BOOL_REF\", e[e.DT_QINT8_REF = 111] = \"DT_QINT8_REF\", e[e.DT_QUINT8_REF = 112] = \"DT_QUINT8_REF\", e[e.DT_QINT32_REF = 113] = \"DT_QINT32_REF\", e[e.DT_BFLOAT16_REF = 114] = \"DT_BFLOAT16_REF\";\n}(DataType || (DataType = {})), function (e) {\n  !function (e) {\n    e[e.LEGACY = 0] = \"LEGACY\", e[e.V1 = 1] = \"V1\", e[e.V2 = 2] = \"V2\";\n  }(e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}));\n}(SaverDef || (SaverDef = {}));\nvar CUSTOM_OPS = {};\n\nfunction registerOp(e, t) {\n  var a = {\n    tfOpName: e,\n    category: \"custom\",\n    inputs: [],\n    attrs: [],\n    customExecutor: t\n  };\n  CUSTOM_OPS[e] = a;\n}\n\nfunction getRegisteredOp(e) {\n  return CUSTOM_OPS[e];\n}\n\nfunction deregisterOp(e) {\n  delete CUSTOM_OPS[e];\n}\n\nfunction getParamValue(e, t, a, r) {\n  var n = t.inputParams[e];\n\n  if (n && void 0 !== n.inputIndexStart) {\n    var s = n.inputIndexStart,\n        o = 0 === n.inputIndexEnd ? void 0 : void 0 === n.inputIndexEnd ? s + 1 : n.inputIndexEnd;\n    if (\"tensor\" === n.type) return getTensor(t.inputNames[n.inputIndexStart], a, r);\n    if (\"tensors\" === n.type) return t.inputNames.slice(s, o).map(function (e) {\n      return getTensor(e, a, r);\n    });\n    var p = Array.prototype.slice.call(getTensor(t.inputNames.slice(s)[0], a, r).dataSync());\n    return \"number\" === n.type ? p[0] : p;\n  }\n\n  var u = t.attrParams[e];\n  return u && u.value;\n}\n\nfunction getTensor(e, t, a) {\n  var r = parseNodeName(e),\n      n = r[0],\n      s = r[1],\n      o = a.currentContextIds.find(function (e) {\n    return !!t[getNodeNameWithContextId(n, e)];\n  });\n  return void 0 !== o ? t[getNodeNameWithContextId(n, o)][s] : void 0;\n}\n\nfunction getTensorsForCurrentContenxt(e, t, a) {\n  return t[getNodeNameWithContextId(e, a.currentContextId)];\n}\n\nfunction getNodeNameAndIndex(e, t) {\n  var a = parseNodeName(e),\n      r = a[0],\n      n = a[1];\n  return [getNodeNameWithContextId(r, t && t.currentContextId), n];\n}\n\nfunction getNodeNameWithContextId(e, t) {\n  return t ? e + \"-\" + t : e;\n}\n\nfunction parseNodeName(e) {\n  var t = e.lastIndexOf(\":\");\n  return -1 === t ? [e, 0] : [e.substring(0, t), Number(e.substring(t + 1))];\n}\n\nfunction split$1(e, t) {\n  for (var a = [], r = 0; r < e.length; r += t) a.push(e.slice(r, r + t));\n\n  return a;\n}\n\nvar json = [{\n  tfOpName: \"Add\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AddV2\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AddN\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"BiasAdd\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sub\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"RealDiv\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Div\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"DivNoNan\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorDiv\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mul\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Maximum\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Minimum\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Pow\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"SquaredDifference\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mod\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorMod\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    arithmetic = Object.freeze({\n  json: json\n}),\n    json$1 = [{\n  tfOpName: \"Abs\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acos\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asin\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan2\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"y\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ceil\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ClipByValue\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"clip_value_min\",\n    name: \"clipValueMin\",\n    type: \"number\"\n  }, {\n    tfName: \"clip_value_max\",\n    name: \"clipValueMax\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Complex\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"real\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"imag\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ComplexAbs\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Cos\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Cosh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Elu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Exp\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Floor\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Imag\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"Tout\",\n    name: \"outputType\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Neg\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Real\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"Tout\",\n    name: \"outputType\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Prelu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"alpha\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu6\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"clipValueMin\",\n    name: \"clipValueMin\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"clipValueMax\",\n    name: \"clipValueMax\",\n    type: \"number\",\n    defaultValue: 6\n  }]\n}, {\n  tfOpName: \"Selu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sigmoid\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sin\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sinh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sqrt\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Rsqrt\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Square\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tan\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tanh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sign\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Round\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Expm1\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log1p\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reciprocal\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Softplus\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asinh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acosh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atanh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Erf\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Prod\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axes\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\",\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LeakyRelu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"alpha\",\n    name: \"alpha\",\n    type: \"number\",\n    defaultValue: .2\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    basicMath = Object.freeze({\n  json: json$1\n}),\n    json$2 = [{\n  tfOpName: \"LoopCond\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Switch\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"data\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Merge\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Enter\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"frame_name\",\n    name: \"frameName\",\n    type: \"string\"\n  }, {\n    tfName: \"is_constant\",\n    name: \"isConstant\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Exit\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NextIteration\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"size\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape\",\n    name: \"elementShape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dynamic_size\",\n    name: \"dynamicSize\",\n    type: \"bool\"\n  }, {\n    tfName: \"clear_after_read\",\n    name: \"clearAfterRead\",\n    type: \"bool\"\n  }, {\n    tfName: \"identical_element_shapes\",\n    name: \"identicalElementShapes\",\n    type: \"bool\"\n  }, {\n    tfName: \"tensor_array_name\",\n    name: \"name\",\n    type: \"string\"\n  }]\n}, {\n  tfOpName: \"TensorArrayWriteV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"index\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayReadV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"index\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayGatherV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape\",\n    name: \"elementShape\",\n    type: \"shape\"\n  }]\n}, {\n  tfOpName: \"TensorArrayScatterV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArrayConcatV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape_except0\",\n    name: \"elementShapeExcept0\",\n    type: \"shape\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArraySplitV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"lengths\",\n    type: \"number[]\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArraySizeV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"flowIn\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"TensorArrayCloseV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }]\n}],\n    control = Object.freeze({\n  json: json$2\n}),\n    json$3 = [{\n  tfOpName: \"AvgPool\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPool\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPoolWithArgmax\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"include_batch_in_index\",\n    name: \"includeBatchInIndex\",\n    type: \"bool\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AvgPool3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPool3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Conv1D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"stride\",\n    name: \"stride\",\n    type: \"number\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NWC\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"dilation\",\n    name: \"dilation\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"Conv2D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"useCudnnOnGpu\",\n    name: \"useCudnnOnGpu\",\n    type: \"bool\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"_FusedConv2D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"explicit_paddings\",\n    name: \"explicitPaddings\",\n    type: \"number[]\",\n    defaultValue: []\n  }, {\n    tfName: \"use_cudnn_on_gpu\",\n    name: \"useCudnnOnGpu\",\n    type: \"bool\",\n    defaultValue: !0\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\",\n    defaultValue: [1, 1, 1, 1]\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }, {\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: 1e-4\n  }]\n}, {\n  tfOpName: \"Conv2DBackpropInput\",\n  category: \"convolution\",\n  inputs: [{\n    start: 2,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 0,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2d\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"input\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2dNative\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"input\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"FusedDepthwiseConv2dNative\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\",\n    defaultValue: [1, 1, 1, 1]\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }]\n}, {\n  tfOpName: \"Conv3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}],\n    convolution = Object.freeze({\n  json: json$3\n}),\n    json$4 = [{\n  tfOpName: \"Fill\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }, {\n    start: 1,\n    name: \"value\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"LinSpace\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"start\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"stop\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"num\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"OneHot\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"depth\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"onValue\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    start: 3,\n    name: \"offValue\",\n    type: \"number\",\n    defaultValue: 0\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ones\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"OnesLike\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"RandomUniform\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"minval\",\n    name: \"minval\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"maxval\",\n    name: \"maxval\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Range\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"start\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"stop\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"step\",\n    type: \"number\",\n    defaultValue: 0\n  }],\n  attrs: [{\n    tfName: \"Tidx\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TruncatedNormal\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"means\",\n    name: \"mean\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"stddev\",\n    name: \"stdDev\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\"\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"T\",\n    name: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Zeros\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ZerosLike\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Multinomial\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"logits\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"numSamples\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\"\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"output_dtype\",\n    name: \"output_dtype\",\n    type: \"dtype\"\n  }]\n}],\n    creation = Object.freeze({\n  json: json$4\n}),\n    json$5 = [{\n  tfOpName: \"NonMaxSuppressionV2\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"NonMaxSuppressionV3\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }, {\n    start: 4,\n    name: \"scoreThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"NonMaxSuppressionV5\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }, {\n    start: 4,\n    name: \"scoreThreshold\",\n    type: \"number\"\n  }, {\n    start: 5,\n    name: \"softNmsSigma\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Where\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"condition\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ListDiff\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"y\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    dynamic = Object.freeze({\n  json: json$5\n}),\n    json$6 = [{\n  tfOpName: \"TopKV2\",\n  category: \"evaluation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"k\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"sorted\",\n    name: \"sorted\",\n    type: \"bool\"\n  }]\n}],\n    evaluation = Object.freeze({\n  json: json$6\n}),\n    json$7 = [{\n  tfOpName: \"PlaceholderWithDefault\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"default\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"shape\",\n    name: \"shape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Placeholder\",\n  category: \"graph\",\n  attrs: [{\n    tfName: \"shape\",\n    name: \"shape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Const\",\n  category: \"graph\"\n}, {\n  tfOpName: \"Identity\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"IdentityN\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"x\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Snapshot\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Rank\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Size\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Shape\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"ShapeN\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"x\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Print\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"data\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"message\",\n    name: \"message\",\n    type: \"string\"\n  }, {\n    tfName: \"first_n\",\n    name: \"firstN\",\n    type: \"number\",\n    notSupported: !0\n  }, {\n    tfName: \"summarize\",\n    name: \"summarize\",\n    type: \"number\",\n    defaultValue: 3\n  }]\n}, {\n  tfOpName: \"NoOp\",\n  category: \"graph\",\n  inputs: []\n}, {\n  tfOpName: \"StopGradient\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"FakeQuantWithMinMaxVars\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"min\",\n    name: \"min\",\n    type: \"number\"\n  }, {\n    tfName: \"max\",\n    name: \"max\",\n    type: \"number\"\n  }]\n}],\n    graph = Object.freeze({\n  json: json$7\n}),\n    json$8 = [{\n  tfOpName: \"ResizeBilinear\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"images\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"size\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"align_corners\",\n    name: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ResizeNearestNeighbor\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"images\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"size\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"align_corners\",\n    name: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"CropAndResize\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"image\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"boxInd\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"cropSize\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"method\",\n    name: \"method\",\n    type: \"string\"\n  }, {\n    tfName: \"extrapolation_value\",\n    name: \"extrapolationValue\",\n    type: \"number\"\n  }]\n}],\n    image$1 = Object.freeze({\n  json: json$8\n}),\n    json$9 = [{\n  tfOpName: \"Equal\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NotEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Greater\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"GreaterEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Less\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LessEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalAnd\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalNot\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalOr\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Select\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"condition\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"SelectV2\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"condition\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    logical = Object.freeze({\n  json: json$9\n}),\n    json$10 = [{\n  tfOpName: \"_FusedMatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }, {\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: 1e-4\n  }, {\n    tfName: \"transpose_a\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"transpose_b\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"transpose_a\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"transpose_b\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"BatchMatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"adj_x\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"adj_y\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"BatchMatMulV2\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"adj_x\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"adj_y\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Transpose\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"perm\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    matrices = Object.freeze({\n  json: json$10\n}),\n    json$11 = [{\n  tfOpName: \"FusedBatchNorm\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FusedBatchNormV2\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FusedBatchNormV3\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LRN\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"depth_radius\",\n    name: \"radius\",\n    type: \"number\",\n    defaultValue: 5\n  }, {\n    tfName: \"bias\",\n    name: \"bias\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"alpha\",\n    name: \"alpha\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"beta\",\n    name: \"beta\",\n    type: \"number\",\n    defaultValue: .5\n  }]\n}, {\n  tfOpName: \"Softmax\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"LogSoftmax\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"defaultValue\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !0,\n    notSupported: !0\n  }]\n}],\n    normalization = Object.freeze({\n  json: json$11\n}),\n    json$12 = [{\n  tfOpName: \"Max\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Mean\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Min\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Sum\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"All\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Any\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"ArgMax\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"ArgMin\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Prod\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}],\n    reduction = Object.freeze({\n  json: json$12\n}),\n    json$13 = [{\n  tfOpName: \"ConcatV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    end: -1,\n    name: \"tensors\",\n    type: \"tensors\"\n  }, {\n    start: -1,\n    name: \"axis\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"N\",\n    name: \"n\",\n    type: \"number\",\n    defaultValue: 2\n  }]\n}, {\n  tfOpName: \"Concat\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 1,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }, {\n    start: 0,\n    name: \"axis\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"N\",\n    name: \"n\",\n    type: \"number\",\n    defaultValue: 2\n  }]\n}, {\n  tfOpName: \"GatherV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Gather\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reverse\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"dims\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ReverseV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Slice\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"begin\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"size\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"StridedSlice\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"begin\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"end\",\n    type: \"number[]\"\n  }, {\n    start: 3,\n    name: \"strides\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"begin_mask\",\n    name: \"beginMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"end_mask\",\n    name: \"endMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"new_axis_mask\",\n    name: \"newAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"ellipsis_mask\",\n    name: \"ellipsisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"shrink_axis_mask\",\n    name: \"shrinkAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Pack\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Unpack\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"num\",\n    name: \"num\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tile\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"reps\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Split\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    start: 1,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"num_split\",\n    name: \"numOrSizeSplits\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"SplitV\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"numOrSizeSplits\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"ScatterNd\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"values\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"GatherNd\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"defaultValue\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !1,\n    notSupported: !0\n  }]\n}],\n    sliceJoin = Object.freeze({\n  json: json$13\n}),\n    json$14 = [{\n  tfOpName: \"FFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"IFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"RFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"fft_length\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"IRFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"fft_length\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}],\n    spectral = Object.freeze({\n  json: json$14\n}),\n    json$15 = [{\n  tfOpName: \"Cast\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"SrcT\",\n    name: \"sdtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"DstT\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ExpandDims\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Pad\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"padding\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"constant_value\",\n    name: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"PadV2\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"padding\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Reshape\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Squeeze\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    tfDeprecatedName: \"squeeze_dims\",\n    name: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"SpaceToBatchND\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"paddings\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"BatchToSpaceND\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"crops\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthToSpace\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"block_size\",\n    name: \"blockSize\",\n    type: \"number\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\"\n  }]\n}],\n    transformation = Object.freeze({\n  json: json$15\n}),\n    OperationMapper = function () {\n  function e() {\n    var e = [arithmetic, basicMath, control, convolution, creation, dynamic, evaluation, logical, image$1, graph, matrices, normalization, reduction, sliceJoin, spectral, transformation],\n        t = [].concat.apply([], e.map(function (e) {\n      return e.json;\n    }));\n    this.opMappers = t.reduce(function (e, t) {\n      return e[t.tfOpName] = t, e;\n    }, {});\n  }\n\n  return Object.defineProperty(e, \"Instance\", {\n    get: function () {\n      return this._instance || (this._instance = new this());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.transformGraph = function (e, t) {\n    var a = this;\n    void 0 === t && (t = {});\n    var r = [],\n        n = [],\n        s = e.node.reduce(function (e, t) {\n      return e[t.name] = a.mapNode(t), t.op.startsWith(\"Placeholder\") && r.push(e[t.name]), \"Const\" === t.op && n.push(e[t.name]), e;\n    }, {}),\n        o = [],\n        p = [],\n        u = {},\n        i = {};\n    null != t && (u = this.mapSignatureEntries(t.inputs), i = this.mapSignatureEntries(t.outputs));\n    var m = Object.keys(s);\n    return m.forEach(function (e) {\n      var t = s[e];\n      t.inputNames.forEach(function (e) {\n        var a = getNodeNameAndIndex(e)[0];\n        t.inputs.push(s[a]), s[a].children.push(t);\n      });\n    }), 0 === Object.keys(i).length ? m.forEach(function (e) {\n      var t = s[e];\n      0 === t.children.length && p.push(t);\n    }) : Object.keys(i).forEach(function (e) {\n      var t = getNodeNameAndIndex(e)[0],\n          a = s[t];\n      null != a && (a.signatureKey = i[e], p.push(a));\n    }), Object.keys(u).length > 0 ? Object.keys(u).forEach(function (e) {\n      var t = getNodeNameAndIndex(e)[0],\n          a = s[t];\n      a && (a.signatureKey = u[e], o.push(a));\n    }) : o = r, {\n      nodes: s,\n      inputs: o,\n      outputs: p,\n      weights: n,\n      placeholders: r,\n      signature: t\n    };\n  }, e.prototype.mapSignatureEntries = function (e) {\n    return Object.keys(e || {}).reduce(function (t, a) {\n      return t[e[a].name] = a, t;\n    }, {});\n  }, e.prototype.mapNode = function (e) {\n    var t = getRegisteredOp(e.op) || this.opMappers[e.op] || {};\n    null == e.attr && (e.attr = {});\n    var a = {\n      name: e.name,\n      op: e.op,\n      category: t.category,\n      inputNames: (e.input || []).map(function (e) {\n        return e.startsWith(\"^\") ? e.substr(1) : e;\n      }),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: e.attr\n    };\n    return null != t.inputs && (a.inputParams = t.inputs.reduce(function (e, t) {\n      return e[t.name] = {\n        type: t.type,\n        inputIndexStart: t.start,\n        inputIndexEnd: t.end\n      }, e;\n    }, {})), null != t.attrs && (a.attrParams = t.attrs.reduce(function (t, a) {\n      var r = a.type,\n          n = void 0;\n\n      switch (a.type) {\n        case \"string\":\n          void 0 === (n = getStringParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getStringParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"string[]\":\n          void 0 === (n = getStringArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getStringArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"number\":\n          void 0 === (n = getNumberParam(e.attr, a.tfName, a.defaultValue || 0)) && a.tfDeprecatedName && (n = getNumberParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"number[]\":\n          void 0 === (n = getNumericArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getNumericArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"bool\":\n          void 0 === (n = getBoolParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getBoolParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"bool[]\":\n          void 0 === (n = getBoolArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getBoolArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"shape\":\n          void 0 === (n = getTensorShapeParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getTensorShapeParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"shape[]\":\n          void 0 === (n = getTensorShapeArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getTensorShapeArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"dtype\":\n          void 0 === (n = getDtypeParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getDtypeParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"dtype[]\":\n          void 0 === (n = getDtypeArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getDtypeArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"tensor\":\n        case \"tensors\":\n          break;\n\n        default:\n          throw new Error(\"Unsupported param type: \" + a.type + \" for op: \" + e.op);\n      }\n\n      return t[a.name] = {\n        value: n,\n        type: r\n      }, t;\n    }, {})), a;\n  }, e;\n}();\n\nfunction decodeBase64(e) {\n  var t = env().global;\n  if (void 0 !== t.atob) return t.atob(e);\n  if (\"undefined\" != typeof Buffer) return new Buffer(e, \"base64\").toString();\n  throw new Error(\"Unable to decode base64 in this environment. Missing built-in atob() or Buffer()\");\n}\n\nfunction parseStringParam(e, t) {\n  var a = Array.isArray(e) ? String.fromCharCode.apply(null, e) : decodeBase64(e);\n  return t ? a : a.toLowerCase();\n}\n\nfunction getStringParam(e, t, a, r) {\n  void 0 === r && (r = !1);\n  var n = e[t];\n  return null != n ? parseStringParam(n.s, r) : a;\n}\n\nfunction getBoolParam(e, t, a) {\n  var r = e[t];\n  return r ? r.b : a;\n}\n\nfunction getNumberParam(e, t, a) {\n  var r = e[t] || {},\n      n = null != r.i ? r.i : null != r.f ? r.f : a;\n  return \"number\" == typeof n ? n : parseInt(n, 10);\n}\n\nfunction parseDtypeParam(e) {\n  switch (\"string\" == typeof e && (e = DataType[e]), e) {\n    case DataType.DT_FLOAT:\n      return \"float32\";\n\n    case DataType.DT_INT32:\n    case DataType.DT_INT64:\n    case DataType.DT_INT8:\n    case DataType.DT_UINT8:\n      return \"int32\";\n\n    case DataType.DT_BOOL:\n      return \"bool\";\n\n    case DataType.DT_DOUBLE:\n      return \"float32\";\n\n    case DataType.DT_STRING:\n      return \"string\";\n\n    default:\n      return null;\n  }\n}\n\nfunction getDtypeParam(e, t, a) {\n  var r = e[t];\n  return r && r.type ? parseDtypeParam(r.type) : a;\n}\n\nfunction getDtypeArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.type ? r.list.type.map(function (e) {\n    return parseDtypeParam(e);\n  }) : a;\n}\n\nfunction parseTensorShapeParam(e) {\n  if (!e.unknownRank) return null != e.dim ? e.dim.map(function (e) {\n    return \"number\" == typeof e.size ? e.size : parseInt(e.size, 10);\n  }) : [];\n}\n\nfunction getTensorShapeParam(e, t, a) {\n  var r = e[t];\n  return r && r.shape ? parseTensorShapeParam(r.shape) : a;\n}\n\nfunction getNumericArrayParam(e, t, a) {\n  var r = e[t];\n  return r ? ((r.list.f && r.list.f.length ? r.list.f : r.list.i) || []).map(function (e) {\n    return \"number\" == typeof e ? e : parseInt(e, 10);\n  }) : a;\n}\n\nfunction getStringArrayParam(e, t, a, r) {\n  void 0 === r && (r = !1);\n  var n = e[t];\n  return n && n.list && n.list.s ? n.list.s.map(function (e) {\n    return parseStringParam(e, r);\n  }) : a;\n}\n\nfunction getTensorShapeArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.shape ? r.list.shape.map(function (e) {\n    return parseTensorShapeParam(e);\n  }) : a;\n}\n\nfunction getBoolArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.b ? r.list.b : a;\n}\n\nvar NodeValueImpl = function () {\n  function e(e, t, a) {\n    var r = this;\n    this.node = e, this.tensorMap = t, this.context = a, this.inputs = [], this.attrs = {}, this.inputs = e.inputNames.map(function (e) {\n      return r.getInput(e);\n    }), null != e.rawAttrs && (this.attrs = Object.keys(e.rawAttrs).reduce(function (e, t) {\n      return e[t] = r.getAttr(t), e;\n    }, {}));\n  }\n\n  return e.prototype.getInput = function (e) {\n    return getTensor(e, this.tensorMap, this.context);\n  }, e.prototype.getAttr = function (e, t) {\n    var a = this.node.rawAttrs[e];\n    if (null != a.tensor) return getTensor(e, this.tensorMap, this.context);\n    if (null != a.i || null != a.f) return getNumberParam(this.node.rawAttrs, e, t);\n    if (null != a.s) return getStringParam(this.node.rawAttrs, e, t);\n    if (null != a.b) return getBoolParam(this.node.rawAttrs, e, t);\n    if (null != a.shape) return getTensorShapeParam(this.node.rawAttrs, e, t);\n    if (null != a.type) return getDtypeParam(this.node.rawAttrs, e, t);\n\n    if (null != a.list) {\n      if (null != a.list.i || null != a.list.f) return getNumericArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.s) return getStringArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.shape) return getTensorShapeArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.b) return getBoolArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.type) return getDtypeArrayParam(this.node.rawAttrs, e, t);\n    }\n\n    return t;\n  }, e;\n}(),\n    executeOp = function (e, t, a) {\n  switch (e.op) {\n    case \"BiasAdd\":\n    case \"AddV2\":\n    case \"Add\":\n      return [add(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"AddN\":\n      return [addN(getParamValue(\"tensors\", e, t, a))];\n\n    case \"FloorMod\":\n    case \"Mod\":\n      return [mod(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Mul\":\n      return [mul(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"RealDiv\":\n    case \"Div\":\n      return [div(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"DivNoNan\":\n      return [divNoNan(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"FloorDiv\":\n      return [floorDiv(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Sub\":\n      return [sub(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Minimum\":\n      return [minimum(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Maximum\":\n      return [maximum(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Pow\":\n      return [pow(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"SquaredDifference\":\n      return [squaredDifference(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$1 = function (e, t, a) {\n  switch (e.op) {\n    case \"Abs\":\n    case \"ComplexAbs\":\n      return [abs(getParamValue(\"x\", e, t, a))];\n\n    case \"Acos\":\n      return [acos(getParamValue(\"x\", e, t, a))];\n\n    case \"Acosh\":\n      return [acosh(getParamValue(\"x\", e, t, a))];\n\n    case \"Asin\":\n      return [asin(getParamValue(\"x\", e, t, a))];\n\n    case \"Asinh\":\n      return [asinh(getParamValue(\"x\", e, t, a))];\n\n    case \"Atan\":\n      return [atan(getParamValue(\"x\", e, t, a))];\n\n    case \"Atan2\":\n      return [atan2(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n    case \"Atanh\":\n      return [atanh(getParamValue(\"x\", e, t, a))];\n\n    case \"Ceil\":\n      return [ceil(getParamValue(\"x\", e, t, a))];\n\n    case \"Complex\":\n      return [complex(getParamValue(\"real\", e, t, a), getParamValue(\"imag\", e, t, a))];\n\n    case \"Cos\":\n      return [cos(getParamValue(\"x\", e, t, a))];\n\n    case \"Cosh\":\n      return [cosh(getParamValue(\"x\", e, t, a))];\n\n    case \"Elu\":\n      return [elu(getParamValue(\"x\", e, t, a))];\n\n    case \"Erf\":\n      return [erf(getParamValue(\"x\", e, t, a))];\n\n    case \"Exp\":\n      return [exp(getParamValue(\"x\", e, t, a))];\n\n    case \"Expm1\":\n      return [expm1(getParamValue(\"x\", e, t, a))];\n\n    case \"Floor\":\n      return [floor(getParamValue(\"x\", e, t, a))];\n\n    case \"Log\":\n      return [log(getParamValue(\"x\", e, t, a))];\n\n    case \"Log1p\":\n      return [log1p(getParamValue(\"x\", e, t, a))];\n\n    case \"Imag\":\n      return [imag(getParamValue(\"x\", e, t, a))];\n\n    case \"Neg\":\n      return [neg(getParamValue(\"x\", e, t, a))];\n\n    case \"Reciprocal\":\n      return [reciprocal(getParamValue(\"x\", e, t, a))];\n\n    case \"Real\":\n      return [real(getParamValue(\"x\", e, t, a))];\n\n    case \"Relu\":\n      return [relu(getParamValue(\"x\", e, t, a))];\n\n    case \"Round\":\n      return [round(getParamValue(\"x\", e, t, a))];\n\n    case \"Selu\":\n      return [selu(getParamValue(\"x\", e, t, a))];\n\n    case \"Sigmoid\":\n      return [sigmoid(getParamValue(\"x\", e, t, a))];\n\n    case \"Sin\":\n      return [sin(getParamValue(\"x\", e, t, a))];\n\n    case \"Sign\":\n      return [sign(getParamValue(\"x\", e, t, a))];\n\n    case \"Sinh\":\n      return [sinh(getParamValue(\"x\", e, t, a))];\n\n    case \"Softplus\":\n      return [softplus(getParamValue(\"x\", e, t, a))];\n\n    case \"Sqrt\":\n      return [sqrt(getParamValue(\"x\", e, t, a))];\n\n    case \"Square\":\n      return [square(getParamValue(\"x\", e, t, a))];\n\n    case \"Tanh\":\n      return [tanh(getParamValue(\"x\", e, t, a))];\n\n    case \"Tan\":\n      return [tan(getParamValue(\"x\", e, t, a))];\n\n    case \"Relu6\":\n    case \"ClipByValue\":\n      return [clipByValue(getParamValue(\"x\", e, t, a), getParamValue(\"clipValueMin\", e, t, a), getParamValue(\"clipValueMax\", e, t, a))];\n\n    case \"Rsqrt\":\n      return [rsqrt(getTensor(e.inputNames[0], t, a))];\n\n    case \"Prod\":\n      return [prod(getParamValue(\"x\", e, t, a), getParamValue(\"axes\", e, t, a))];\n\n    case \"LeakyRelu\":\n      return [leakyRelu(getParamValue(\"x\", e, t, a), getParamValue(\"alpha\", e, t, a))];\n\n    case \"Prelu\":\n      return [prelu(getParamValue(\"x\", e, t, a), getParamValue(\"alpha\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    TensorArray = function () {\n  function e(t, a, r, n, s, o, p) {\n    this.name = t, this.dtype = a, this.maxSize = r, this.elementShape = n, this.identicalElementShapes = s, this.dynamicSize = o, this.clearAfterRead = p, this.tensors = [], this.closed_ = !1, this.id = e.nextId++;\n  }\n\n  return Object.defineProperty(e.prototype, \"closed\", {\n    get: function () {\n      return this.closed_;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.clearAndClose = function () {\n    this.tensors.forEach(function (e) {\n      return e.tensor.dispose();\n    }), this.tensors = [], this.closed_ = !0;\n  }, e.prototype.size = function () {\n    return this.tensors.length;\n  }, e.prototype.read = function (e) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || e >= this.tensors.length) throw new Error(\"Tried to read from index \" + e + \", but array size is: \" + this.tensors.length);\n    var t = this.tensors[e];\n    if (t.cleared) throw new Error(\"TensorArray \" + this.name + \": Could not read index \" + e + \" twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).\");\n    return this.clearAfterRead && (t.cleared = !0), t.read = !0, t.tensor;\n  }, e.prototype.readMany = function (e) {\n    var t = this;\n    return e.map(function (e) {\n      return t.read(e);\n    });\n  }, e.prototype.write = function (e, t) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || !this.dynamicSize && e >= this.maxSize) throw new Error(\"Tried to write to index \" + e + \", but array is not resizeable and size is: \" + this.maxSize);\n    var a = this.tensors[e] || {};\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \",\\n          because the value dtype is \" + t.dtype + \", but TensorArray dtype is \" + this.dtype + \".\");\n    if (0 !== this.size() || null != this.elementShape && 0 !== this.elementShape.length || (this.elementShape = t.shape), this.assertShapesMatchAllowUndefinedSize(this.elementShape, t.shape, \"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \".\"), a && a.read) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been read.\");\n    if (a && a.written) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been written.\");\n    a.tensor = t, a.written = !0, this.tensors[e] = a;\n  }, e.prototype.writeMany = function (e, t) {\n    var a = this;\n    if (e.length !== t.length) throw new Error(\"TensorArray \" + this.name + \": could not write multiple tensors,because the index size: \" + e.length + \" is not the same as tensors size: \" + t.length + \".\");\n    e.forEach(function (e, r) {\n      return a.write(e, t[r]);\n    });\n  }, e.prototype.gather = function (e, t) {\n    if (t && t !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but gather requested dtype \" + t);\n\n    if (!e) {\n      e = [];\n\n      for (var a = 0; a < this.size(); a++) e.push(a);\n    }\n\n    if (0 === e.length) return tensor([], [0].concat(this.elementShape));\n    var r = this.readMany(e);\n    return this.assertShapesMatchAllowUndefinedSize(this.elementShape, r[0].shape, \"TensorArray shape mismatch: \"), stack(r, 0);\n  }, e.prototype.concat = function (e) {\n    if (e && e !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but concat requested dtype \" + e);\n    if (0 === this.size()) return tensor([], [0].concat(this.elementShape));\n\n    for (var t = [], a = 0; a < this.size(); a++) t.push(a);\n\n    var r = this.readMany(t);\n    return this.assertShapesMatchAllowUndefinedSize(this.elementShape, r[0].shape, \"TensorArray shape mismatch: tensor array shape (\" + this.elementShape + \") vs first tensor shape (\" + r[0].shape + \")\"), concat(r, 0);\n  }, e.prototype.scatter = function (e, t) {\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    if (e.length !== t.shape[0]) throw new Error(\"Expected len(indices) == tensor.shape[0], but saw: \" + e.length + \" vs. \" + t.shape[0]);\n    var a = Math.max.apply(Math, e);\n    if (!this.dynamicSize && a >= this.maxSize) throw new Error(\"Max index must be < array size (\" + a + \"  vs. \" + this.maxSize + \")\");\n    this.writeMany(e, unstack(t, 0));\n  }, e.prototype.split = function (e, t) {\n    var a = this;\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    var r = 0,\n        n = e.map(function (e) {\n      return r += e;\n    });\n    if (r !== t.shape[0]) throw new Error(\"Expected sum of lengths to be equal to\\n          tensor.shape[0], but sum of lengths is\\n        \" + r + \", and tensor's shape is: \" + t.shape);\n    if (!this.dynamicSize && e.length !== this.maxSize) throw new Error(\"TensorArray's size is not equal to the size of lengths (\" + this.maxSize + \" vs. \" + e.length + \"), and the TensorArray is not marked as dynamically resizeable\");\n    var s = 0 === r ? 0 : t.size / r,\n        o = [];\n    tidy(function () {\n      t = t.reshape([1, r, s]);\n\n      for (var p = 0; p < e.length; ++p) {\n        var u = [0, 0 === p ? 0 : n[p - 1], 0],\n            i = [1, e[p], s];\n        o[p] = slice(t, u, i).reshape(a.elementShape);\n      }\n\n      return o;\n    });\n\n    for (var p = [], u = 0; u < e.length; u++) p[u] = u;\n\n    this.writeMany(p, o);\n  }, e.prototype.assertShapesMatchAllowUndefinedSize = function (e, t, a) {\n    void 0 === a && (a = \"\"), util.assert(this.shapesEqualAllowUndefinedSize(e, t), function () {\n      return a + \" Shapes \" + e + \" and \" + t + \" must match\";\n    });\n  }, e.prototype.shapesEqualAllowUndefinedSize = function (e, t) {\n    if (e.length !== t.length) return !1;\n\n    for (var a = 0; a < e.length; a++) if (-1 !== e[a] && -1 !== t[a] && e[a] !== t[a]) return !1;\n\n    return !0;\n  }, e.nextId = 0, e;\n}(),\n    _this = void 0,\n    executeOp$2 = function (e, t, a) {\n  return __awaiter(_this, void 0, void 0, function () {\n    var r, n, s, o, p, u, i, m, l, c, d, y, f, g, h, N, x, V, b, P, T, v, O, S, _, w, A, D, E, I, M, C, k, z, F;\n\n    return __generator(this, function (j) {\n      switch (j.label) {\n        case 0:\n          switch (e.op) {\n            case \"LoopCond\":\n              return [3, 1];\n\n            case \"Switch\":\n              return [3, 2];\n\n            case \"Merge\":\n              return [3, 4];\n\n            case \"Enter\":\n              return [3, 5];\n\n            case \"Exit\":\n              return [3, 6];\n\n            case \"NextIteration\":\n              return [3, 7];\n\n            case \"TensorArrayV3\":\n              return [3, 8];\n\n            case \"TensorArrayWriteV3\":\n              return [3, 9];\n\n            case \"TensorArrayReadV3\":\n              return [3, 10];\n\n            case \"TensorArrayGatherV3\":\n              return [3, 11];\n\n            case \"TensorArrayScatterV3\":\n              return [3, 12];\n\n            case \"TensorArrayConcatV3\":\n              return [3, 13];\n\n            case \"TensorArraySplitV3\":\n              return [3, 14];\n\n            case \"TensorArraySizeV3\":\n              return [3, 15];\n\n            case \"TensorArrayCloseV3\":\n              return [3, 16];\n          }\n\n          return [3, 17];\n\n        case 1:\n          return [2, [getParamValue(\"pred\", e, t, a).clone()]];\n\n        case 2:\n          return r = getParamValue(\"pred\", e, t, a), n = getParamValue(\"data\", e, t, a), [4, r.data()];\n\n        case 3:\n          return [2, j.sent()[0] ? [void 0, n.clone()] : [n.clone(), void 0]];\n\n        case 4:\n          return [2, (s = e.inputNames.find(function (e) {\n            return void 0 !== getTensor(e, t, a);\n          })) ? [getTensor(s, t, a).clone()] : void 0];\n\n        case 5:\n          return o = getParamValue(\"frameName\", e, t, a), p = getParamValue(\"tensor\", e, t, a), a.enterFrame(o), [2, [p.clone()]];\n\n        case 6:\n          return u = getParamValue(\"tensor\", e, t, a), a.exitFrame(), [2, [u.clone()]];\n\n        case 7:\n          return i = getParamValue(\"tensor\", e, t, a), a.nextIteration(), [2, [i.clone()]];\n\n        case 8:\n          return m = getParamValue(\"size\", e, t, a), l = getParamValue(\"dtype\", e, t, a), c = getParamValue(\"elementShape\", e, t, a), d = getParamValue(\"dynamicSize\", e, t, a), y = getParamValue(\"clearAfterRead\", e, t, a), f = getParamValue(\"identicalElementShapes\", e, t, a), g = getParamValue(\"name\", e, t, a), h = new TensorArray(g, l, m, c, f, d, y), a.addTensorArray(h), [2, [scalar(h.id), scalar(1)]];\n\n        case 9:\n          return N = getParamValue(\"tensorArrayId\", e, t, a), x = getParamValue(\"index\", e, t, a), V = getParamValue(\"tensor\", e, t, a), a.getTensorArray(N).write(x, V), [2, [scalar(1)]];\n\n        case 10:\n          return b = getParamValue(\"tensorArrayId\", e, t, a), P = getParamValue(\"index\", e, t, a), [2, [a.getTensorArray(b).read(P)]];\n\n        case 11:\n          return T = getParamValue(\"tensorArrayId\", e, t, a), v = getParamValue(\"indices\", e, t, a), O = getParamValue(\"dtype\", e, t, a), [2, [a.getTensorArray(T).gather(v, O)]];\n\n        case 12:\n          return S = getParamValue(\"tensorArrayId\", e, t, a), _ = getParamValue(\"indices\", e, t, a), w = getParamValue(\"tensor\", e, t, a), a.getTensorArray(S).scatter(_, w), [2, [scalar(1)]];\n\n        case 13:\n          return A = getParamValue(\"tensorArrayId\", e, t, a), D = a.getTensorArray(A), E = getParamValue(\"dtype\", e, t, a), [2, [D.concat(E)]];\n\n        case 14:\n          return I = getParamValue(\"tensorArrayId\", e, t, a), M = getParamValue(\"tensor\", e, t, a), C = getParamValue(\"lengths\", e, t, a), a.getTensorArray(I).split(C, M), [2, [scalar(1)]];\n\n        case 15:\n          return k = getParamValue(\"tensorArrayId\", e, t, a), z = a.getTensorArray(k), [2, [scalar(z.size(), \"int32\")]];\n\n        case 16:\n          return F = getParamValue(\"tensorArrayId\", e, t, a), a.getTensorArray(F).clearAndClose(), [2, [scalar(0)]];\n\n        case 17:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n},\n    executeOp$3 = function (e, t, a) {\n  switch (e.op) {\n    case \"Conv1D\":\n      var r = getParamValue(\"stride\", e, t, a),\n          n = getParamValue(\"pad\", e, t, a),\n          s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(),\n          o = getParamValue(\"dilation\", e, t, a);\n      return [conv1d(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), r, n, s, o)];\n\n    case \"Conv2D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      var p = getParamValue(\"dilations\", e, t, a);\n      return [conv2d(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, s, [p[1], p[2]])];\n\n    case \"_FusedConv2D\":\n    case \"FusedDepthwiseConv2dNative\":\n      var u = getParamValue(\"fusedOps\", e, t, a),\n          i = u[0],\n          m = u[1],\n          l = \"biasadd\" === i,\n          c = \"prelu\" === m,\n          d = \"fusedbatchnorm\" === i,\n          y = getParamValue(\"numArgs\", e, t, a);\n\n      if (l) {\n        if (c && 2 !== y) throw new Error(\"FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.\");\n        if (!c && 1 !== y) throw new Error(\"FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.\");\n      }\n\n      if (d) throw new Error(\"FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.\");\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(), p = getParamValue(\"dilations\", e, t, a);\n      var f = getParamValue(\"args\", e, t, a),\n          g = f[0],\n          h = f[1];\n      return [(\"_FusedConv2D\" === e.op ? fused.conv2d : fused.depthwiseConv2d)({\n        x: getParamValue(\"x\", e, t, a),\n        filter: getParamValue(\"filter\", e, t, a),\n        strides: [r[1], r[2]],\n        pad: n,\n        dataFormat: s,\n        dilations: [p[1], p[2]],\n        bias: g,\n        activation: m,\n        preluActivationWeights: h\n      })];\n\n    case \"Conv2DBackpropInput\":\n    case \"Conv2dTranspose\":\n      var N = getParamValue(\"outputShape\", e, t, a);\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      return [conv2dTranspose(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), N, [r[1], r[2]], n)];\n\n    case \"DepthwiseConv2dNative\":\n    case \"DepthwiseConv2d\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), p = getParamValue(\"dilations\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [depthwiseConv2d(getParamValue(\"input\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, s, [p[1], p[2]])];\n\n    case \"Conv3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(), p = getParamValue(\"dilations\", e, t, a);\n      return [conv3d(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2], r[3]], n, s, [p[1], p[2], p[3]])];\n\n    case \"AvgPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      var x = getParamValue(\"kernelSize\", e, t, a);\n      return [avgPool(getParamValue(\"x\", e, t, a), [x[1], x[2]], [r[1], r[2]], n)];\n\n    case \"MaxPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [maxPool(getParamValue(\"x\", e, t, a), [x[1], x[2]], [r[1], r[2]], n)];\n\n    case \"MaxPoolWithArgmax\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      var V = getParamValue(\"includeBatchInIndex\", e, t, a),\n          b = maxPoolWithArgmax(getParamValue(\"x\", e, t, a), [x[1], x[2]], [r[1], r[2]], n, V);\n      return [b.result, b.indexes];\n\n    case \"AvgPool3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [avgPool3d(getParamValue(\"x\", e, t, a), [x[1], x[2], x[3]], [r[1], r[2], r[3]], n)];\n\n    case \"MaxPool3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [maxPool3d(getParamValue(\"x\", e, t, a), [x[1], x[2], x[3]], [r[1], r[2], r[3]], n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$4 = function (e, t, a) {\n  switch (e.op) {\n    case \"Fill\":\n      var r = getParamValue(\"shape\", e, t, a),\n          n = getParamValue(\"dtype\", e, t, a),\n          s = getParamValue(\"value\", e, t, a);\n      return [fill(r, s, n)];\n\n    case \"LinSpace\":\n      var o = getParamValue(\"start\", e, t, a),\n          p = getParamValue(\"stop\", e, t, a),\n          u = getParamValue(\"num\", e, t, a);\n      return [linspace(o, p, u)];\n\n    case \"Multinomial\":\n      var i = getParamValue(\"logits\", e, t, a),\n          m = getParamValue(\"numSamples\", e, t, a),\n          l = getParamValue(\"seed\", e, t, a);\n      return [multinomial(i, m, l)];\n\n    case \"OneHot\":\n      var c = getParamValue(\"indices\", e, t, a),\n          d = getParamValue(\"depth\", e, t, a),\n          y = getParamValue(\"onValue\", e, t, a),\n          f = getParamValue(\"offValue\", e, t, a);\n      return [oneHot(c, d, y, f)];\n\n    case \"Ones\":\n      return [ones(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"OnesLike\":\n      return [onesLike(getParamValue(\"x\", e, t, a))];\n\n    case \"RandomUniform\":\n      return [randomUniform(getParamValue(\"shape\", e, t, a), getParamValue(\"minval\", e, t, a), getParamValue(\"maxval\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"Range\":\n      o = getParamValue(\"start\", e, t, a);\n      var g = getParamValue(\"stop\", e, t, a),\n          h = getParamValue(\"step\", e, t, a);\n      return [range(o, g, h, getParamValue(\"dtype\", e, t, a))];\n\n    case \"TruncatedNormal\":\n      r = getParamValue(\"shape\", e, t, a);\n      var N = getParamValue(\"mean\", e, t, a),\n          x = getParamValue(\"stdDev\", e, t, a);\n      l = getParamValue(\"seed\", e, t, a);\n      return [truncatedNormal(r, N, x, getParamValue(\"dtype\", e, t, a), l)];\n\n    case \"Zeros\":\n      return [zeros(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"ZerosLike\":\n      return [zerosLike(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    _this$1 = void 0,\n    executeOp$5 = function (e, t, a) {\n  return __awaiter(_this$1, void 0, void 0, function () {\n    var r, n, s, o, p, u, i, m;\n    return __generator(this, function (l) {\n      switch (l.label) {\n        case 0:\n          switch (e.op) {\n            case \"NonMaxSuppressionV5\":\n            case \"NonMaxSuppressionV3\":\n            case \"NonMaxSuppressionV2\":\n              return [3, 1];\n\n            case \"Where\":\n              return [3, 5];\n\n            case \"ListDiff\":\n              return [3, 7];\n          }\n\n          return [3, 8];\n\n        case 1:\n          return r = getParamValue(\"boxes\", e, t, a), n = getParamValue(\"scores\", e, t, a), s = getParamValue(\"maxOutputSize\", e, t, a), o = getParamValue(\"iouThreshold\", e, t, a), p = getParamValue(\"scoreThreshold\", e, t, a), \"NonMaxSuppressionV5\" !== e.op ? [3, 3] : (u = getParamValue(\"softNmsSigma\", e, t, a), [4, image.nonMaxSuppressionWithScoreAsync(r, n, s, o, p, u)]);\n\n        case 2:\n          return [2, [(m = l.sent()).selectedIndices, m.selectedScores]];\n\n        case 3:\n          return [4, image.nonMaxSuppressionAsync(r, n, s, o, p)];\n\n        case 4:\n          return [2, [l.sent()]];\n\n        case 5:\n          return i = getParamValue(\"condition\", e, t, a).asType(\"bool\"), [4, whereAsync(i)];\n\n        case 6:\n          return m = [l.sent()], i.dispose(), [2, m];\n\n        case 7:\n          return [2, setdiff1dAsync(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n        case 8:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n},\n    executeOp$6 = function (e, t, a) {\n  switch (e.op) {\n    case \"TopKV2\":\n      var r = getParamValue(\"x\", e, t, a),\n          n = getParamValue(\"k\", e, t, a),\n          s = getParamValue(\"sorted\", e, t, a),\n          o = topk(r, n, s);\n      return [o.values, o.indices];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$7 = function (e, t, a) {\n  switch (e.op) {\n    case \"Const\":\n      return t[e.name];\n\n    case \"PlaceholderWithDefault\":\n      var r = getParamValue(\"default\", e, t, a);\n      return [getTensor(e.name, t, a) || r];\n\n    case \"Placeholder\":\n      return [getTensor(e.name, t, a)];\n\n    case \"Identity\":\n    case \"StopGradient\":\n    case \"FakeQuantWithMinMaxVars\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"IdentityN\":\n      return getParamValue(\"x\", e, t, a).map(function (e) {\n        return e.clone();\n      });\n\n    case \"Snapshot\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"Shape\":\n      return [tensor1d(getParamValue(\"x\", e, t, a).shape, \"int32\")];\n\n    case \"ShapeN\":\n      return getParamValue(\"x\", e, t, a).map(function (e) {\n        return tensor1d(e.shape);\n      });\n\n    case \"Size\":\n      return [scalar(getParamValue(\"x\", e, t, a).size, \"int32\")];\n\n    case \"Rank\":\n      return [scalar(getParamValue(\"x\", e, t, a).rank, \"int32\")];\n\n    case \"NoOp\":\n      return [scalar(1)];\n\n    case \"Print\":\n      var n = getParamValue(\"x\", e, t, a),\n          s = getParamValue(\"data\", e, t, a),\n          o = getParamValue(\"message\", e, t, a),\n          p = getParamValue(\"summarize\", e, t, a);\n      console.warn(\"The graph has a tf.print() operation,usually used for debugging, which slows down performance.\"), console.log(o);\n\n      for (var u = 0; u < s.length; u++) console.log(Array.prototype.slice.call(s[u].dataSync()).slice(0, p));\n\n      return [n];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$8 = function (e, t, a) {\n  switch (e.op) {\n    case \"ResizeBilinear\":\n      var r = getParamValue(\"images\", e, t, a),\n          n = getParamValue(\"size\", e, t, a),\n          s = getParamValue(\"alignCorners\", e, t, a);\n      return [image.resizeBilinear(r, [n[0], n[1]], s)];\n\n    case \"ResizeNearestNeighbor\":\n      r = getParamValue(\"images\", e, t, a), n = getParamValue(\"size\", e, t, a), s = getParamValue(\"alignCorners\", e, t, a);\n      return [image.resizeNearestNeighbor(r, [n[0], n[1]], s)];\n\n    case \"CropAndResize\":\n      var o = getParamValue(\"image\", e, t, a),\n          p = getParamValue(\"boxes\", e, t, a),\n          u = getParamValue(\"boxInd\", e, t, a),\n          i = getParamValue(\"cropSize\", e, t, a),\n          m = getParamValue(\"method\", e, t, a),\n          l = getParamValue(\"extrapolationValue\", e, t, a);\n      return [image.cropAndResize(o, p, u, i, m, l)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$9 = function (e, t, a) {\n  switch (e.op) {\n    case \"Equal\":\n      return [equal(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"NotEqual\":\n      return [notEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Greater\":\n      return [greater(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"GreaterEqual\":\n      return [greaterEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Less\":\n      return [less(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LessEqual\":\n      return [lessEqual(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LogicalAnd\":\n      return [logicalAnd(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LogicalNot\":\n      return [logicalNot(getParamValue(\"a\", e, t, a))];\n\n    case \"LogicalOr\":\n      return [logicalOr(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Select\":\n    case \"SelectV2\":\n      return [where(getParamValue(\"condition\", e, t, a), getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$10 = function (e, t, a) {\n  switch (e.op) {\n    case \"BatchMatMul\":\n    case \"BatchMatMulV2\":\n    case \"MatMul\":\n      return [matMul(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a), getParamValue(\"transposeA\", e, t, a), getParamValue(\"transposeB\", e, t, a))];\n\n    case \"Transpose\":\n      return [transpose(getParamValue(\"x\", e, t, a), getParamValue(\"perm\", e, t, a))];\n\n    case \"_FusedMatMul\":\n      var r = getParamValue(\"fusedOps\", e, t, a),\n          n = r[0],\n          s = r[1],\n          o = \"biasadd\" === n,\n          p = \"prelu\" === s,\n          u = getParamValue(\"numArgs\", e, t, a);\n\n      if (o) {\n        if (p && 2 !== u) throw new Error(\"Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.\");\n        if (!p && 1 !== u) throw new Error(\"Fused MatMul with BiasAdd must have one extra argument: bias.\");\n      }\n\n      var i = getParamValue(\"args\", e, t, a),\n          m = i[0],\n          l = i[1];\n      return [fused.matMul({\n        a: getParamValue(\"a\", e, t, a),\n        b: getParamValue(\"b\", e, t, a),\n        transposeA: getParamValue(\"transposeA\", e, t, a),\n        transposeB: getParamValue(\"transposeB\", e, t, a),\n        bias: m,\n        activation: s,\n        preluActivationWeights: l\n      })];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$11 = function (e, t, a) {\n  switch (e.op) {\n    case \"FusedBatchNorm\":\n    case \"FusedBatchNormV2\":\n    case \"FusedBatchNormV3\":\n      return [batchNorm(getParamValue(\"x\", e, t, a), getParamValue(\"mean\", e, t, a), getParamValue(\"variance\", e, t, a), getParamValue(\"offset\", e, t, a), getParamValue(\"scale\", e, t, a), getParamValue(\"epsilon\", e, t, a))];\n\n    case \"LRN\":\n      return [localResponseNormalization(getParamValue(\"x\", e, t, a), getParamValue(\"radius\", e, t, a), getParamValue(\"bias\", e, t, a), getParamValue(\"alpha\", e, t, a), getParamValue(\"beta\", e, t, a))];\n\n    case \"Softmax\":\n      return [softmax(getParamValue(\"x\", e, t, a))];\n\n    case \"LogSoftmax\":\n      return [logSoftmax(getParamValue(\"x\", e, t, a))];\n\n    case \"SparseToDense\":\n      return [sparseToDense(getParamValue(\"sparseIndices\", e, t, a), getParamValue(\"outputShape\", e, t, a), getParamValue(\"sparseValues\", e, t, a), getParamValue(\"defaultValue\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$12 = function (e, t, a) {\n  switch (e.op) {\n    case \"Max\":\n      var r = getParamValue(\"axis\", e, t, a),\n          n = getParamValue(\"keepDims\", e, t, a);\n      return [max(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Mean\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [mean(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Min\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [min(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Sum\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [sum(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"All\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [all(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Any\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [any(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"ArgMax\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [argMax(getParamValue(\"x\", e, t, a), r)];\n\n    case \"ArgMin\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [argMin(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Prod\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [prod(getParamValue(\"x\", e, t, a), r, n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$13 = function (e, t, a) {\n  switch (e.op) {\n    case \"ConcatV2\":\n    case \"Concat\":\n      var r = getParamValue(\"n\", e, t, a),\n          n = getParamValue(\"axis\", e, t, a),\n          s = getParamValue(\"tensors\", e, t, a);\n      return s = s.slice(0, r), [concat(s, n)];\n\n    case \"GatherV2\":\n    case \"Gather\":\n      n = getParamValue(\"axis\", e, t, a);\n      var o = getParamValue(\"x\", e, t, a),\n          p = getParamValue(\"indices\", e, t, a);\n      return [gather(o, p.asType(\"int32\"), n)];\n\n    case \"ReverseV2\":\n    case \"Reverse\":\n      n = getParamValue(\"axis\", e, t, a), o = getParamValue(\"x\", e, t, a);\n      return [reverse(o, n)];\n\n    case \"Slice\":\n      var u = getParamValue(\"begin\", e, t, a),\n          i = getParamValue(\"size\", e, t, a);\n      return [slice(getParamValue(\"x\", e, t, a), u, i)];\n\n    case \"StridedSlice\":\n      u = getParamValue(\"begin\", e, t, a);\n      var m = getParamValue(\"end\", e, t, a),\n          l = getParamValue(\"strides\", e, t, a),\n          c = getParamValue(\"beginMask\", e, t, a),\n          d = getParamValue(\"endMask\", e, t, a),\n          y = getParamValue(\"ellipsisMask\", e, t, a),\n          f = getParamValue(\"newAxisMask\", e, t, a),\n          g = getParamValue(\"shrinkAxisMask\", e, t, a),\n          h = getParamValue(\"x\", e, t, a);\n      if (1 === u.length && h.shape.length > 1) for (var N = 1; N < h.shape.length; N++) u.push(0), m.push(h.shape[N]), l.push(l[0]);\n      return [stridedSlice(h, u, m, l, c, d, y, f, g)];\n\n    case \"Pack\":\n      return tidy(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensors\", e, t, a),\n            s = n[0].shape,\n            o = n[0].squeeze().shape,\n            p = n.map(function (e) {\n          var t = util.arraysEqual(e.shape, s);\n          if (!t && !util.arraysEqual(e.squeeze().shape, o)) throw new Error(\"the input tensors shape does not match\");\n          return t ? e : e.reshape(s);\n        });\n        return [stack(p, r)];\n      });\n\n    case \"Unpack\":\n      return tidy(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensor\", e, t, a);\n        return unstack(n, r);\n      });\n\n    case \"Tile\":\n      var x = getParamValue(\"reps\", e, t, a);\n      return [tile(getParamValue(\"x\", e, t, a), x)];\n\n    case \"Split\":\n    case \"SplitV\":\n      n = getParamValue(\"axis\", e, t, a);\n      var V = getParamValue(\"numOrSizeSplits\", e, t, a);\n      return split(getParamValue(\"x\", e, t, a), V, n);\n\n    case \"ScatterNd\":\n      p = getParamValue(\"indices\", e, t, a);\n      var b = getParamValue(\"values\", e, t, a),\n          P = getParamValue(\"shape\", e, t, a);\n      return [scatterND(p, b, P)];\n\n    case \"GatherNd\":\n      var T = getParamValue(\"x\", e, t, a);\n      p = getParamValue(\"indices\", e, t, a);\n      return [gatherND(T, p)];\n\n    case \"SparseToDense\":\n      p = getParamValue(\"sparseIndices\", e, t, a), P = getParamValue(\"outputShape\", e, t, a);\n      var v = getParamValue(\"sparseValues\", e, t, a),\n          O = getParamValue(\"defaultValue\", e, t, a);\n      return [sparseToDense(p, v, P, v.dtype === O.dtype ? O : O.asType(v.dtype))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$14 = function (e, t, a) {\n  switch (e.op) {\n    case \"FFT\":\n      return [fft(getParamValue(\"x\", e, t, a))];\n\n    case \"IFFT\":\n      return [ifft(getParamValue(\"x\", e, t, a))];\n\n    case \"RFFT\":\n      return [rfft(getParamValue(\"x\", e, t, a))];\n\n    case \"IRFFT\":\n      return [irfft(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$15 = function (e, t, a) {\n  switch (e.op) {\n    case \"Cast\":\n      return [cast(getParamValue(\"x\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"ExpandDims\":\n      var r = getParamValue(\"axis\", e, t, a);\n      return [expandDims(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Squeeze\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [squeeze(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Reshape\":\n      return [reshape(getParamValue(\"x\", e, t, a), getParamValue(\"shape\", e, t, a))];\n\n    case \"PadV2\":\n    case \"Pad\":\n      return [pad(getParamValue(\"x\", e, t, a), split$1(getParamValue(\"padding\", e, t, a), 2), getParamValue(\"constantValue\", e, t, a))];\n\n    case \"SpaceToBatchND\":\n      var n = getParamValue(\"blockShape\", e, t, a),\n          s = split$1(getParamValue(\"paddings\", e, t, a), 2);\n      return [spaceToBatchND(getParamValue(\"x\", e, t, a), n, s)];\n\n    case \"BatchToSpaceND\":\n      n = getParamValue(\"blockShape\", e, t, a);\n      var o = split$1(getParamValue(\"crops\", e, t, a), 2);\n      return [batchToSpaceND(getParamValue(\"x\", e, t, a), n, o)];\n\n    case \"DepthToSpace\":\n      var p = getParamValue(\"blockSize\", e, t, a),\n          u = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [depthToSpace(getParamValue(\"x\", e, t, a), p, u)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n};\n\nfunction executeOp$16(e, t, a) {\n  var r = function (e, t, a) {\n    switch (e.category) {\n      case \"arithmetic\":\n        return tidy(function () {\n          return executeOp(e, t, a);\n        });\n\n      case \"basic_math\":\n        return tidy(function () {\n          return executeOp$1(e, t, a);\n        });\n\n      case \"control\":\n        return executeOp$2(e, t, a);\n\n      case \"convolution\":\n        return tidy(function () {\n          return executeOp$3(e, t, a);\n        });\n\n      case \"creation\":\n        return tidy(function () {\n          return executeOp$4(e, t, a);\n        });\n\n      case \"dynamic\":\n        return executeOp$5(e, t, a);\n\n      case \"evaluation\":\n        return tidy(function () {\n          return executeOp$6(e, t, a);\n        });\n\n      case \"image\":\n        return tidy(function () {\n          return executeOp$8(e, t, a);\n        });\n\n      case \"graph\":\n        return tidy(function () {\n          return executeOp$7(e, t, a);\n        });\n\n      case \"logical\":\n        return tidy(function () {\n          return executeOp$9(e, t, a);\n        });\n\n      case \"matrices\":\n        return tidy(function () {\n          return executeOp$10(e, t, a);\n        });\n\n      case \"normalization\":\n        return tidy(function () {\n          return executeOp$11(e, t, a);\n        });\n\n      case \"reduction\":\n        return tidy(function () {\n          return executeOp$12(e, t, a);\n        });\n\n      case \"slice_join\":\n        return tidy(function () {\n          return executeOp$13(e, t, a);\n        });\n\n      case \"spectral\":\n        return tidy(function () {\n          return executeOp$14(e, t, a);\n        });\n\n      case \"transformation\":\n        return tidy(function () {\n          return executeOp$15(e, t, a);\n        });\n\n      case \"custom\":\n        var r = getRegisteredOp(e.op);\n        if (r && r.customExecutor) return r.customExecutor(new NodeValueImpl(e, t, a));\n        throw TypeError(\"Custom op \" + e.op + \" is not registered.\");\n\n      default:\n        throw TypeError(\"Unknown op '\" + e.op + \"'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()\");\n    }\n  }(e, t, a);\n\n  return r instanceof Promise ? r.then(function (e) {\n    return [].concat(e);\n  }) : [].concat(r);\n}\n\nvar ExecutionContext = function () {\n  function e(e, t) {\n    this.weightMap = e, this.tensorArrayMap = t, this.rootContext = {\n      id: 0,\n      frameName: \"\",\n      iterationId: 0\n    }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();\n  }\n\n  return e.prototype.newFrame = function (e, t) {\n    return {\n      id: e,\n      frameName: t,\n      iterationId: 0\n    };\n  }, Object.defineProperty(e.prototype, \"currentContext\", {\n    get: function () {\n      return this.contexts;\n    },\n    set: function (e) {\n      this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextId\", {\n    get: function () {\n      return this._currentContextIds[0];\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextIds\", {\n    get: function () {\n      return this._currentContextIds;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.generateCurrentContextIds = function () {\n    for (var e = [], t = 0; t < this.contexts.length - 1; t++) {\n      var a = this.contexts.slice(0, this.contexts.length - t);\n      e.push(this.contextIdforContexts(a));\n    }\n\n    e.push(\"\"), this._currentContextIds = e;\n  }, e.prototype.contextIdforContexts = function (e) {\n    return e ? e.map(function (e) {\n      return 0 === e.id && 0 === e.iterationId ? \"\" : e.frameName + \"-\" + e.iterationId;\n    }).join(\"/\") : \"\";\n  }, e.prototype.enterFrame = function (e) {\n    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));\n  }, e.prototype.exitFrame = function () {\n    if (!(this.contexts && this.contexts.length > 1)) throw new Error(\"Cannot exit frame, the context is empty\");\n    this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();\n  }, e.prototype.nextIteration = function () {\n    if (!(this.contexts && this.contexts.length > 0)) throw new Error(\"Cannot increase frame iteration, the context is empty\");\n    this.contexts = this.contexts.slice(), this.lastId++;\n    var e = Object.assign({}, this.contexts[this.contexts.length - 1]);\n    e.iterationId += 1, e.id = this.lastId, this.contexts.splice(-1, 1, e), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));\n  }, e.prototype.getWeight = function (e) {\n    return this.weightMap[e];\n  }, e.prototype.addTensorArray = function (e) {\n    this.tensorArrayMap[e.id] = e;\n  }, e.prototype.getTensorArray = function (e) {\n    return this.tensorArrayMap[e];\n  }, e;\n}();\n\nfunction getExecutionSubgraph(e, t, a) {\n  for (var r = new Set(), n = [], s = null, o = null, p = new Set(), u = Object.keys(e).map(function (e) {\n    return parseNodeName(e)[0];\n  }), i = t.slice(); i.length > 0;) {\n    var m = i.pop();\n    (isControlFlow(m) || isDynamicShape(m)) && null == s && (o = (s = m).children.map(function (e) {\n      return e.name;\n    }).filter(function (e) {\n      return r.has(e);\n    })), r.add(m.name), null == a[m.name] && -1 === u.indexOf(m.name) && (0 !== m.inputs.length ? m.inputs.forEach(function (e) {\n      p.has(e.name) || (p.add(e.name), i.push(e));\n    }) : n.push(m.name));\n  }\n\n  return {\n    inputs: e,\n    outputs: t,\n    usedNodes: r,\n    missingInputs: n,\n    dynamicNode: s,\n    syncInputs: o\n  };\n}\n\nfunction getNodesInTopologicalOrder(e, t, a) {\n  var r = a.usedNodes,\n      n = a.inputs,\n      s = [];\n  Object.keys(n).map(function (e) {\n    return parseNodeName(e)[0];\n  }).map(function (t) {\n    return e.nodes[t];\n  }).forEach(function (e) {\n    r.has(e.name) && s.push(e);\n  }), e.weights.forEach(function (e) {\n    r.has(e.name) && s.push(e);\n  });\n\n  for (var o = new Set(), p = []; s.length > 0;) {\n    var u = s.pop();\n    o.add(u.name), t[u.name] || p.push(u), u.children.forEach(function (e) {\n      !o.has(e.name) && r.has(e.name) && e.inputs.every(function (e) {\n        return o.has(e.name);\n      }) && s.push(e);\n    });\n  }\n\n  return p;\n}\n\nvar CONTROL_FLOW_OPS = [\"Switch\", \"Merge\", \"Enter\", \"Exit\", \"NextIteration\"],\n    DYNAMIC_SHAPE_OPS = [\"NonMaxSuppressionV2\", \"NonMaxSuppressionV3\", \"NonMaxSuppressionV5\", \"Where\"];\n\nfunction isControlFlow(e) {\n  return CONTROL_FLOW_OPS.indexOf(e.op) >= 0;\n}\n\nfunction isDynamicShape(e) {\n  return DYNAMIC_SHAPE_OPS.indexOf(e.op) >= 0;\n}\n\nvar GraphExecutor = function () {\n  function e(e) {\n    this.graph = e, this.compiledMap = new Map(), this._weightMap = {}, this.SEPERATOR = \",\", this._outputs = e.outputs, this._inputs = e.inputs, this._signature = e.signature;\n  }\n\n  return Object.defineProperty(e.prototype, \"weightMap\", {\n    get: function () {\n      return this._weightMap;\n    },\n    set: function (e) {\n      var t = Object.keys(e).map(function (t) {\n        return e[t].map(function (e) {\n          return e.id;\n        });\n      });\n      this.weightIds = [].concat.apply([], t), this._weightMap = e;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function () {\n      return this._inputs.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,\n          dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function () {\n      return this._outputs.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,\n          dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function () {\n      return this._inputs.map(function (e) {\n        return e.signatureKey || e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function () {\n      return this._outputs.map(function (e) {\n        return e.signatureKey || e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.getCompilationKey = function (e, t) {\n    var a = e.map(function (e) {\n      return e.name;\n    }).sort(),\n        r = t.map(function (e) {\n      return e.name;\n    }).sort();\n    return a.join(this.SEPERATOR) + \"--\" + r.join(this.SEPERATOR);\n  }, e.prototype.compile = function (e, t) {\n    var a = getExecutionSubgraph(e, t, this.weightMap),\n        r = a.missingInputs,\n        n = a.dynamicNode,\n        s = a.syncInputs;\n    if (null != n) throw new Error(\"This execution contains the node '\" + n.name + \"', which has the dynamic op '\" + n.op + \"'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [\" + s + \"]\");\n\n    if (r.length > 0) {\n      var o = t.map(function (e) {\n        return e.name;\n      }),\n          p = Object.keys(e);\n      throw new Error(\"Cannot compute the outputs [\" + o + \"] from the provided inputs [\" + p + \"]. Missing the following inputs: [\" + r + \"]\");\n    }\n\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, a);\n  }, e.prototype.execute = function (e, t) {\n    var a = this;\n    e = this.mapInputs(e);\n    var r = Object.keys(e).sort();\n    this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t);\n    var n = r.map(function (e) {\n      return a.graph.nodes[parseNodeName(e)[0]];\n    }),\n        s = t.map(function (e) {\n      return a.graph.nodes[parseNodeName(e)[0]];\n    }),\n        o = this.getCompilationKey(n, s),\n        p = this.compiledMap.get(o);\n    null == p && (p = this.compile(e, s), this.compiledMap.set(o, p));\n    var u = {};\n    return tidy(function () {\n      var r = new ExecutionContext(a._weightMap, u),\n          n = __assign({}, a.weightMap);\n\n      Object.keys(e).forEach(function (t) {\n        var a = parseNodeName(t),\n            r = a[0],\n            s = [];\n        s[a[1]] = e[t], n[r] = s;\n      });\n\n      for (var s = a.getFrozenTensorIds(n), o = {}, i = 0; i < p.length; i++) {\n        var m = p[i];\n\n        if (!n[m.name]) {\n          var l = executeOp$16(m, n, r);\n          if (l instanceof Promise) throw new Error(\"The execution of the op '\" + m.op + \"' returned a promise. Please use model.executeAsync() instead.\");\n          n[m.name] = l, a.checkTensorForDisposal(m.name, m, n, r, s, t, o);\n        }\n      }\n\n      return t.map(function (e) {\n        return getTensor(e, n, r);\n      });\n    });\n  }, e.prototype.getFrozenTensorIds = function (e) {\n    var t = [].concat.apply([], Object.keys(e).map(function (t) {\n      return e[t];\n    }).map(function (e) {\n      return e.map(function (e) {\n        return e.id;\n      });\n    }));\n    return new Set(t);\n  }, e.prototype.checkTensorForDisposal = function (e, t, a, r, n, s, o) {\n    \"control\" !== t.category && -1 === s.indexOf(e) && (a[e].forEach(function (e) {\n      null != e && (o[e.id] = (o[e.id] || 0) + t.children.length);\n    }), t.inputs.forEach(function (e) {\n      if (\"control\" !== e.category) {\n        var t = getTensorsForCurrentContenxt(e.name, a, r);\n        null != t && t.forEach(function (e) {\n          if (e && !n.has(e.id)) {\n            var t = o[e.id];\n            1 === t ? (e.dispose(), delete o[e.id]) : null != t && o[e.id]--;\n          }\n        });\n      }\n    }));\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a,\n          r,\n          n,\n          s,\n          o,\n          p,\n          u = this;\n      return __generator(this, function (i) {\n        switch (i.label) {\n          case 0:\n            return e = this.mapInputs(e), this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t), a = {}, r = new ExecutionContext(this._weightMap, a), [4, this.executeWithControlFlow(e, r, t)];\n\n          case 1:\n            return n = i.sent(), s = t.map(function (e) {\n              return getTensor(e, n, r);\n            }), o = new Set(s.map(function (e) {\n              return e.id;\n            })), p = new Set(Object.keys(e).map(function (t) {\n              return e[t].id;\n            })), Object.keys(n).forEach(function (e) {\n              n[e].forEach(function (e) {\n                !e || e.isDisposed || o.has(e.id) || p.has(e.id) || -1 !== u.weightIds.indexOf(e.id) || e.dispose();\n              });\n            }), [2, s];\n        }\n      });\n    });\n  }, e.prototype.executeWithControlFlow = function (e, t, a) {\n    return __awaiter(this, void 0, void 0, function () {\n      var r,\n          n,\n          s,\n          o,\n          p,\n          u,\n          i,\n          m,\n          l,\n          c,\n          d,\n          y,\n          f,\n          g,\n          h,\n          N,\n          x = this;\n      return __generator(this, function (V) {\n        switch (V.label) {\n          case 0:\n            r = Object.keys(e), n = r.map(function (e) {\n              return x.graph.nodes[parseNodeName(e)[0]];\n            }), s = a.map(function (e) {\n              return x.graph.nodes[parseNodeName(e)[0]];\n            }), o = getExecutionSubgraph(e, s, this.weightMap), p = o.usedNodes, u = o.missingInputs, i = o.dynamicNode, m = o.syncInputs, l = n.concat(this.graph.weights).map(function (e) {\n              return {\n                node: e,\n                contexts: t.currentContext\n              };\n            }), c = __assign({}, this.weightMap), Object.keys(e).forEach(function (t) {\n              var a = parseNodeName(t),\n                  r = a[0],\n                  n = [];\n              n[a[1]] = e[t], c[r] = n;\n            }), d = {}, y = this.getFrozenTensorIds(c), f = {}, V.label = 1;\n\n          case 1:\n            return l.length > 0 ? (g = this.processStack(n, l, t, c, f, y, a, d, p), [4, Promise.all(g)]) : [3, 3];\n\n          case 2:\n            return V.sent(), [3, 1];\n\n          case 3:\n            if (null == i && console.warn(\"This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.\"), (h = s.filter(function (e) {\n              return !isControlFlow(e) && !getTensor(e.name, c, t);\n            }).map(function (e) {\n              return e.name;\n            })).length > 0) throw N = \"\", null != i && (N = \"Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [\" + m + \"]\"), new Error(\"Cannot compute the outputs [\" + h + \"] from the provided inputs [\" + r + \"]. Consider providing the following inputs: [\" + u + \"]. \" + N);\n            return [2, c];\n        }\n      });\n    });\n  }, e.prototype.processStack = function (e, t, a, r, n, s, o, p, u) {\n    for (var i = this, m = [], l = function () {\n      var l = t.pop();\n      a.currentContext = l.contexts;\n      var d = \"\";\n\n      if (\"Enter\" === l.node.op && getParamValue(\"isConstant\", l.node, r, a) && (d = getNodeNameAndIndex(l.node.name, a)[0]), -1 === e.indexOf(l.node)) {\n        var y = executeOp$16(l.node, r, a);\n        d || (d = getNodeNameAndIndex(l.node.name, a)[0]);\n        var f = a.currentContext;\n        y instanceof Promise ? m.push(y.then(function (e) {\n          return r[d] = e, a.currentContext = f, i.checkTensorForDisposal(d, l.node, r, a, s, o, p), i.processChildNodes(l.node, t, a, r, n, u), e;\n        })) : (r[d] = y, c.checkTensorForDisposal(d, l.node, r, a, s, o, p), c.processChildNodes(l.node, t, a, r, n, u));\n      } else c.processChildNodes(l.node, t, a, r, n, u);\n    }, c = this; t.length > 0;) l();\n\n    return m;\n  }, e.prototype.processChildNodes = function (e, t, a, r, n, s) {\n    e.children.forEach(function (e) {\n      var o = getNodeNameAndIndex(e.name, a)[0];\n      !n[o] && s.has(e.name) && (\"Merge\" === e.op ? e.inputNames.some(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })) : e.inputNames.every(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })));\n    });\n  }, e.prototype.dispose = function () {\n    var e = this;\n    Object.keys(this.weightMap).forEach(function (t) {\n      return e.weightMap[t].forEach(function (e) {\n        return e.dispose();\n      });\n    });\n  }, e.prototype.checkInputShapeAndType = function (e) {\n    var t = this;\n    Object.keys(e).forEach(function (a) {\n      var r = e[a],\n          n = parseNodeName(a)[0],\n          s = t.graph.nodes[n];\n\n      if (s.attrParams.shape && s.attrParams.shape.value) {\n        var o = s.attrParams.shape.value,\n            p = o.length === r.shape.length && r.shape.every(function (e, t) {\n          return -1 === o[t] || o[t] === e;\n        });\n        util.assert(p, function () {\n          return \"The shape of dict['\" + s.name + \"'] provided in model.execute(dict) must be [\" + o + \"], but was [\" + r.shape + \"]\";\n        });\n      }\n\n      s.attrParams.dtype && s.attrParams.dtype.value && util.assert(r.dtype === s.attrParams.dtype.value, function () {\n        return \"The dtype of dict['\" + s.name + \"'] provided in model.execute(dict) must be \" + s.attrParams.dtype.value + \", but was \" + r.dtype;\n      });\n    });\n  }, e.prototype.mapInputs = function (e) {\n    var t = {};\n\n    for (var a in e) {\n      if (null != this._signature && null != this._signature.inputs && null != this._signature.inputs[a]) t[this._signature.inputs[a].name] = e[a];else t[a] = e[a];\n    }\n\n    return t;\n  }, e.prototype.checkInputs = function (e) {\n    var t = this,\n        a = Object.keys(e).filter(function (e) {\n      var a = parseNodeName(e)[0];\n      return null == t.graph.nodes[a];\n    });\n    if (a.length > 0) throw new Error(\"The dict provided in model.execute(dict) has keys: [\" + a + \"] that are not part of graph\");\n  }, e.prototype.mapOutputs = function (e) {\n    var t = this;\n    return e.map(function (e) {\n      return null != t._signature && null != t._signature.outputs && null != t._signature.outputs[e] ? t._signature.outputs[e].name : e;\n    }, {});\n  }, e.prototype.checkOutputs = function (e) {\n    var t = this;\n    e.forEach(function (e) {\n      var a = parseNodeName(e)[0];\n      if (!t.graph.nodes[a]) throw new Error(\"The output '\" + e + \"' is not found in the graph\");\n    });\n  }, e;\n}(),\n    TFHUB_SEARCH_PARAM = \"?tfjs-format=file\",\n    DEFAULT_MODEL_NAME = \"model.json\",\n    GraphModel = function () {\n  function e(e, t) {\n    void 0 === t && (t = {}), this.modelUrl = e, this.loadOptions = t, this.version = \"n/a\", null == t && (this.loadOptions = {});\n  }\n\n  return Object.defineProperty(e.prototype, \"modelVersion\", {\n    get: function () {\n      return this.version;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function () {\n      return this.executor.inputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function () {\n      return this.executor.outputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function () {\n      return this.executor.inputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function () {\n      return this.executor.outputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"weights\", {\n    get: function () {\n      return this.executor.weightMap;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.findIOHandler = function () {\n    var e = this.modelUrl;\n    if (null != e.load) this.handler = e;else if (null != this.loadOptions.requestInit) this.handler = io.browserHTTPRequest(e, this.loadOptions);else {\n      var t = io.getLoadHandlers(e, this.loadOptions.onProgress);\n      if (0 === t.length) t.push(io.browserHTTPRequest(e, this.loadOptions));else if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") load handlers for URL '\" + [e] + \"'\");\n      this.handler = t[0];\n    }\n  }, e.prototype.load = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var e, t, a, r;\n      return __generator(this, function (n) {\n        switch (n.label) {\n          case 0:\n            if (this.findIOHandler(), null == this.handler.load) throw new Error(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n            return e = this, [4, this.handler.load()];\n\n          case 1:\n            return e.artifacts = n.sent(), t = this.artifacts.modelTopology, a = {}, null != this.artifacts.userDefinedMetadata && (a = this.artifacts.userDefinedMetadata.signature), this.version = t.versions.producer + \".\" + t.versions.minConsumer, r = io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs), this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(t, a)), this.executor.weightMap = this.convertTensorMapToTensorsMap(r), [2, !0];\n        }\n      });\n    });\n  }, e.prototype.save = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var t;\n      return __generator(this, function (a) {\n        if (\"string\" == typeof e) {\n          if (0 === (t = io.getSaveHandlers(e)).length) throw new Error(\"Cannot find any save handlers for URL '\" + e + \"'\");\n          if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") save handlers for URL '\" + e + \"'\");\n          e = t[0];\n        }\n\n        if (null == e.save) throw new Error(\"GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.\");\n        return [2, e.save(this.artifacts)];\n      });\n    });\n  }, e.prototype.predict = function (e, t) {\n    return this.execute(e, this.outputNodes);\n  }, e.prototype.normalizeInputs = function (e) {\n    if (!(e instanceof Tensor || Array.isArray(e))) return e;\n    if ((e = Array.isArray(e) ? e : [e]).length !== this.inputNodes.length) throw new Error(\"Input tensor count mismatch,the graph model has \" + this.inputNodes.length + \" placeholders, while there are \" + e.length + \" input tensors.\");\n    return this.inputNodes.reduce(function (t, a, r) {\n      return t[a] = e[r], t;\n    }, {});\n  }, e.prototype.normalizeOutputs = function (e) {\n    return e = e || this.outputNodes, Array.isArray(e) ? e : [e];\n  }, e.prototype.execute = function (e, t) {\n    e = this.normalizeInputs(e), t = this.normalizeOutputs(t);\n    var a = this.executor.execute(e, t);\n    return a.length > 1 ? a : a[0];\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a;\n      return __generator(this, function (r) {\n        switch (r.label) {\n          case 0:\n            return e = this.normalizeInputs(e), t = this.normalizeOutputs(t), [4, this.executor.executeAsync(e, t)];\n\n          case 1:\n            return [2, (a = r.sent()).length > 1 ? a : a[0]];\n        }\n      });\n    });\n  }, e.prototype.convertTensorMapToTensorsMap = function (e) {\n    return Object.keys(e).reduce(function (t, a) {\n      return t[a] = [e[a]], t;\n    }, {});\n  }, e.prototype.dispose = function () {\n    this.executor.dispose();\n  }, e;\n}();\n\nfunction loadGraphModel(e, t) {\n  return void 0 === t && (t = {}), __awaiter(this, void 0, void 0, function () {\n    var a;\n    return __generator(this, function (r) {\n      switch (r.label) {\n        case 0:\n          if (null == e) throw new Error(\"modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model\");\n          return null == t && (t = {}), t.fromTFHub && null == e.load && (e.endsWith(\"/\") || (e += \"/\"), e = \"\" + e + DEFAULT_MODEL_NAME + TFHUB_SEARCH_PARAM), [4, (a = new GraphModel(e, t)).load()];\n\n        case 1:\n          return r.sent(), [2, a];\n      }\n    });\n  });\n}\n\nvar version = \"1.7.4\";\nexport { GraphModel, loadGraphModel, deregisterOp, registerOp, version as version_converter };","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;IA8BYA;IAyRKC;IAAAA;EAAAA;IAAAA;;IAAAA;EAAAA;AAAAA;;AAAAA;EAAAA;IAAAA;MAAAA;QAAAA;MAAAA;QAAAA;MAAAA;IAAAA;;IAAAA;MAAAA;QAAAA;MAAAA;QAAAA;MAAAA;IAAAA;;IAAAA;MAAAA;QAAAA;MAAAA;IAAAA;;IAAAA;EAAAA;AAAAA;;AAAAA;EAAAA;EAAAA;EAAAA;EAAAA;EAAAA;IAAAA;IAAAA;MAAAA;MAAAA;IAAAA;IAAAA;IAAAA;EAAAA;EAAAA;IAAAA;IAAAA;IAAAA;EAAAA;IAAAA;EAAAA;;EAAAA;IAAAA;MAAAA;QAAAA;;QAAAA;UAAAA;;UAAAA;YAAAA;YAAAA;cAAAA;cAAAA;;YAAAA;cAAAA;gBAAAA;gBAAAA;cAAAA;;YAAAA;cAAAA;cAAAA;;YAAAA;cAAAA;cAAAA;;YAAAA;cAAAA;gBAAAA;gBAAAA;cAAAA;;cAAAA;gBAAAA;gBAAAA;cAAAA;;cAAAA;gBAAAA;gBAAAA;cAAAA;;cAAAA;gBAAAA;gBAAAA;cAAAA;;cAAAA;cAAAA;UAAAA;;UAAAA;QAAAA;UAAAA;QAAAA;UAAAA;QAAAA;;QAAAA;QAAAA;UAAAA;UAAAA;QAAAA;MAAAA;IAAAA;EAAAA;AAAAA;;AAAAA,CAzRjB,UAAYD,CAAZ,EAAYA;EACVA,oCACAA,8BADAA,EAEAA,gCAFAA,EAGAA,8BAHAA,EAIAA,8BAJAA,EAKAA,8BALAA,EAMAA,4BANAA,EAOAA,gCAPAA,EAQAA,sCARAA,EASAA,8BATAA,EAUAA,6BAVAA,EAWAA,+BAXAA,EAYAA,iCAZAA,EAaAA,iCAbAA,EAcAA,qCAdAA,EAeAA,wCAfAA,EAgBAA,0CAhBAA,EAiBAA,wCAjBAA,EAkBAA,wCAlBAA,EAmBAA,wCAnBAA,EAoBAA,sCApBAA,EAqBAA,0CArBAA,EAsBAA,gDAtBAA,EAuBAA,wCAvBAA,EAwBAA,sCAxBAA,EAyBAA,wCAzBAA,EA0BAA,0CA1BAA,EA2BAA,0CA3BAA,EA4BAA,8CA5BAA;AADF,EAAYA,2BAAZ,CAyRiBC,EAAjB,UAAiBA,CAAjB,EAAiBA;EAAAA,CAEf,UAAYC,CAAZ,EAAYA;IAAyBA,4BAAcA,kBAAdA,EAAwBA,kBAAxBA;EAArC,EAAYD,6DAAZ,CAFeA;AAAjB,EAAiBA,2BAAjB,CAAiBA;ACnSjB,IAAME,eAAN;;AA0BA,SAAgBC,UAAhB,CAA2BC,CAA3B,EAAyCC,CAAzC,EAAyCA;EACvC,IAAMC;IACJC,UAAUH,CADNE;IAEJE,UAAU,QAFNF;IAGJG,UAHIH;IAIJI,SAJIJ;IAKJK,gBAAgBN;EALZC,CAAN;EAQAJ,WAAWE,CAAXF,IAAmBI,CAAnBJ;AAUF;;AAAA,SAAgBU,eAAhB,CAAgCR,CAAhC,EAAgCA;EAC9B,OAAOF,WAAWE,CAAXF,CAAP;AASF;;AAAA,SAAgBW,YAAhB,CAA6BT,CAA7B,EAA6BA;EAAAA,OACpBF,WAAWE,CAAXF,CADoBE;ACpD7B;;AAAA,SAAgBU,aAAhB,CACIC,CADJ,EACuBC,CADvB,EACmCC,CADnC,EAEIC,CAFJ,EAEIA;EACF,IAAMC,IAAaH,EAAKI,WAALJ,CAAiBD,CAAjBC,CAAnB;;EACA,IAAIG,UAA6CE,CAA7CF,KAAcA,EAAWG,eAA7B,EAA4D;IAC1D,IAAMC,IAAQJ,EAAWG,eAAzB;IAAA,IACME,IAAmC,MAA7BL,EAAWM,aAAkB,GAAlBA,KACnBJ,CADqC,GACrCA,KAC8BA,CAD9BA,KACCF,EAAWM,aADZJ,GAC0CE,IAAQ,CADlDF,GAE0CF,EAAWM,aAJzD;IAKA,IAAwB,aAApBN,EAAWO,IAAf,EACE,OAAOC,UACHX,EAAKY,UAALZ,CAAgBG,EAAWG,eAA3BN,CADGW,EAC0CV,CAD1CU,EACqDT,CADrDS,CAAP;IAGF,IAAwB,cAApBR,EAAWO,IAAf,EAGE,OAFeV,EAAKY,UAALZ,CAAgBa,KAAhBb,CAAsBO,CAAtBP,EAA6BQ,CAA7BR,EAEDc,GAFCd,CAEG;MAAQ,iBAAUZ,CAAVuB,EAAgBV,CAAhBU,EAA2BT,CAA3BS;IAA2BT,CAFtCF,CAEf;IAEF,IAAMe,IAAOC,MAAMC,SAAND,CAAgBH,KAAhBG,CAAsBE,IAAtBF,CACTL,UAAUX,EAAKY,UAALZ,CAAgBa,KAAhBb,CAAsBO,CAAtBP,EAA6B,CAA7BA,CAAVW,EAA2CV,CAA3CU,EAAsDT,CAAtDS,EACKQ,QADLR,EADSK,CAAb;IAGA,OAA2B,aAApBb,EAAWO,IAAS,GAAWK,EAAK,CAALA,CAAX,GAAqBA,CAAhD;EAEF;;EAAA,IAAMK,IAAYpB,EAAKqB,UAALrB,CAAgBD,CAAhBC,CAAlB;EACA,OAAOoB,KAAaA,EAAUE,KAA9B;AASF;;AAAA,SAAgBX,SAAhB,CACIvB,CADJ,EACkBmC,CADlB,EAEIrB,CAFJ,EAEIA;EACI;EAAA,IAACsB,QAAD;EAAA,IAAWC,QAAX;EAAA,IACAC,IAAYxB,EAAQyB,iBAARzB,CAA0B0B,IAA1B1B,CAA+B;IAC/C,SAASqB,EAAWM,yBAAyBL,CAAzBK,EAAmCH,CAAnCG,CAAXN,CAAT;EAAuDG,CADvCxB,CADZ;EAKN,YAAqBG,CAArB,KAAOqB,CAAP,GACIH,EAAWM,yBAAyBL,CAAzBK,EAAmCH,CAAnCG,CAAXN,EAA0DE,CAA1DF,CADJ,GAC8DE,KAC1DpB,CAFJ;AAUF;;AAAA,SAAgByB,4BAAhB,CACI1C,CADJ,EACkBmC,CADlB,EAEIrB,CAFJ,EAEIA;EACF,OAAOqB,EAAWM,yBAAyBzC,CAAzByC,EAA+B3B,EAAQ6B,gBAAvCF,CAAXN,CAAP;AASF;;AAAA,SAAgBS,mBAAhB,CACIC,CADJ,EACuB/B,CADvB,EACuBA;EACf;EAAA,IAACsB,QAAD;EAAA,IAAWC,QAAX;EAEN,QACEI,yBAAyBL,CAAzBK,EAAmC3B,KAAWA,EAAQ6B,gBAAtDF,CADF,EAEEJ,CAFF;AAMF;;AAAA,SAASI,wBAAT,CAAkCzC,CAAlC,EAAgDsC,CAAhD,EAAgDA;EAC9C,OAASA,IAAetC,UAAQsC,CAAvBA,GAAqCtC,CAA9C;AAGF;;AAAA,SAAgB8C,aAAhB,CAA8B9C,CAA9B,EAA8BA;EAC5B,IAAMqC,IAAQrC,EAAK+C,WAAL/C,CAAiB,GAAjBA,CAAd;EACA,QAAe,CAAf,KAAIqC,CAAJ,GAAIA,CACMrC,CADNqC,EACY,CADZA,CAAJ,GACgB,CAGCrC,EAAKgD,SAALhD,CAAe,CAAfA,EAAkBqC,CAAlBrC,CAHD,EAIEiD,OAAOjD,EAAKgD,SAALhD,CAAeqC,IAAQ,CAAvBrC,CAAPiD,CAJF,CADhB;AAQF;;AAAA,SAAgBC,OAAhB,CAAsBC,CAAtB,EAAqCC,CAArC,EAAqCA;EAEnC,KADA,IAAMC,MAAN,EACSC,IAAI,CAAb,EAAgBA,IAAIH,EAAII,MAAxB,EAAgCD,KAAKF,CAArC,EACEC,EAAIG,IAAJH,CAASF,EAAI1B,KAAJ0B,CAAUG,CAAVH,EAAaG,IAAIF,CAAjBD,CAATE;;EAEF,OAAOA,CAAP;ACjGF;;AAAA,IAAaI;EAETtD,UAAY,KAFHsD;EAGTrD,UAAY,YAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CAJSoD;EAQTnD;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AARSmD,GAS2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAT3DmD,EAoB2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IAAYc,OAAS,CAArBd;IAAwBe,KAAO,CAA/Bf;IAAkCL,MAAQ,SAA1CK;IAAqDiB,MAAQ;EAA7DjB;AANoE,CApB3DoD,EA0BoD;EAG7DtD,UAAY,SAHiD;EAI7DC,UAAY,YAJiD;EAK7DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CAL6D;EAS7DC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAT6D,CA1BpDmD,EAoC2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CApC3DmD,EA+C2D;EAIpEtD,UAAY,SAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA/C3DmD,EA0D2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA1D3DmD,EAqE2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CArE3DmD,EAgF2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAhF3DmD,EA2F2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA3F3DmD,EAsG2D;EAIpEtD,UAAY,SAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB;AANoE,CAtG3DoD,EA8G2B;EAIpCtD,UAAY,SAJwB;EAKpCC,UAAY,YALwB;EAMpCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB;AANoC,CA9G3BoD,EAsH2B;EAIpCtD,UAAY,KAJwB;EAKpCC,UAAY,YALwB;EAMpCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoC;EAUpCC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoC,CAtH3BmD,EAiI2D;EAIpEtD,UAAY,mBAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAjI3DmD,EA4I2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA5I3DmD,EAuJ2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAvJ3DmD,CAAb;AAAA,IAkKwEG;EAAAH;AAAA,EAlKxE;AAAA,ICAaA;EAETtD,UAAY,KAFHsD;EAGTrD,UAAY,YAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAJSoD;EAOTnD;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAPSmD,GAQ2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAR3DmD,EAkB2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAlB3DmD,EA4B2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA5B3DmD,EAsC2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAtC3DmD,EAiD2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAjD3DmD,EA2D2D;EAIpEtD,UAAY,aAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,gBADbpD;IAC+BN,MAAQ,cADvCM;IACuDgB,MAAQ;EAD/DhB,GAC+D;IAC5DoD,QAAU,gBADkD;IAChC1D,MAAQ,cADwB;IACRsB,MAAQ;EADA,CAD/DhB;AAToE,CA3D3DmD,EAsEsD;EAI/DtD,UAAY,SAJmD;EAK/DC,UAAY,YALmD;EAM/DC;IACGc,OAAS,CADZd;IACeL,MAAQ,MADvBK;IAC+BiB,MAAQ;EADvCjB,GACuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,MADgB;IACRsB,MAAQ;EADA,CADvCjB,CAN+D;EAU/DC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAV+D,CAtEtDmD,EAiF2D;EAIpEtD,UAAY,YAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAjF3DmD,EA2F2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA3F3DmD,EAqG2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CArG3DmD,EA+G2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA/G3DmD,EAyH2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAzH3DmD,EAmI2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAnI3DmD,EA6I2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA7I3DmD,EAuJ2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD,GACoE;IAChEoD,QAAU,MADsD;IAEhE1D,MAAQ,YAFwD;IAGhEsB,MAAQ,OAHwD;IAIhEqC,eAAgB;EAJgD,CADpErD;AAToE,CAvJ3DmD,EAqKW;EAKpBtD,UAAY,KALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAPoB;EAUpBC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoB,CArKXmD,EAgL2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD,GACoE;IAChEoD,QAAU,MADsD;IAEhE1D,MAAQ,YAFwD;IAGhEsB,MAAQ,OAHwD;IAIhEqC,eAAgB;EAJgD,CADpErD;AAToE,CAhL3DmD,EA8LW;EAKpBtD,UAAY,OALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,CAPoB;EAWpBC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAXoB,CA9LXmD,EA0M2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA1M3DmD,EAoN2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD,GACoE;IAChEoD,QAAU,cADsD;IAEhE1D,MAAQ,cAFwD;IAGhEsB,MAAQ,QAHwD;IAIhEuC,cAAgB;EAJgD,CADpEvD,EAKoB;IAGhBoD,QAAU,cAHM;IAIhB1D,MAAQ,cAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CALpBvD;AAToE,CApN3DmD,EAwOW;EAKpBtD,UAAY,MALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAPoB;EAUpBC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoB,CAxOXmD,EAmP2D;EAIpEtD,UAAY,SAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAnP3DmD,EA6P2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA7P3DmD,EAuQ2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAvQ3DmD,EAiR2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAjR3DmD,EA2R2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA3R3DmD,EAqS2D;EAIpEtD,UAAY,QAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CArS3DmD,EA+S2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA/S3DmD,EAyT2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAzT3DmD,EAmU2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAnU3DmD,EA6U2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA7U3DmD,EAuV2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAvV3DmD,EAiW2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAjW3DmD,EA2W2D;EAIpEtD,UAAY,YAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA3W3DmD,EAqX2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CArX3DmD,EA+X2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA/X3DmD,EAyY2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAzY3DmD,EAmZ2D;EAIpEtD,UAAY,OAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAnZ3DmD,EA6Z2D;EAIpEtD,UAAY,KAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA7Z3DmD,EAua2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CANoE;EAUpEC;IAEIoD,QAAU,WAFdpD;IAGIN,MAAQ,UAHZM;IAIIgB,MAAQ,MAJZhB;IAKIqD,eAAgB;EALpBrD,GAKoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CALpBrD;AAVoE,CAva3DmD,EAwb2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,YALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IAEIoD,QAAU,OAFdpD;IAGIN,MAAQ,OAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,GAHM;IAIhB1D,MAAQ,OAJQ;IAKhBsB,MAAQ,OALQ;IAMhBqC,eAAgB;EANA,CALpBrD;AAToE,CAxb3DmD,CDAb;AAAA,IC4cwBK;EAAAL;AAAA,ED5cxB;AAAA,IEAaA;EAETtD,UAAY,UAFHsD;EAGTrD,UAAY,SAHHqD;EAITpD;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,MAAhCK;IAAwCiB,MAAQ;EAAhDjB;AAJSoD,GAIuC;EAGhDtD,UAAY,QAHoC;EAIhDC,UAAY,SAJoC;EAKhDC;IACGc,OAAS,CADZd;IACeL,MAAQ,MADvBK;IAC+BiB,MAAQ;EADvCjB,GACuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,MADgB;IACRsB,MAAQ;EADA,CADvCjB;AALgD,CAJvCoD,EAW8B;EAIvCtD,UAAY,OAJ2B;EAKvCC,UAAY,SAL2B;EAMvCC;IACMc,OAAS,CADfd;IACkBe,KAAO,CADzBf;IAC4BL,MAAQ,SADpCK;IAC+CiB,MAAQ;EADvDjB;AANuC,CAX9BoD,EAkB8C;EAGvDtD,UAAY,OAH2C;EAIvDC,UAAY,SAJ2C;EAKvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,EALuD;EAQvDC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD,GACoE;IACjEoD,QAAU,YADuD;IACzC1D,MAAQ,WADiC;IACpBsB,MAAQ;EADY,CADpEhB,EAEwD;IACrDoD,QAAU,aAD2C;IAC5B1D,MAAQ,YADoB;IACNsB,MAAQ;EADF,CAFxDhB;AARuD,CAlB9CmD,EA6BiD;EAI1DtD,UAAY,MAJ8C;EAK1DC,UAAY,SAL8C;EAM1DC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,EAN0D;EAS1DC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAT0D,CA7BjDmD,EAuC2D;EAIpEtD,UAAY,eAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CAvC3DmD,EAiD2D;EAIpEtD,UAAY,eAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,MADvBK;IAC+BiB,MAAQ;EADvCjB,EANoE;EASpEC;IACGoD,QAAU,OADbpD;IACsBN,MAAQ,OAD9BM;IACuCgB,MAAQ;EAD/ChB,GAC+C;IAC5CoD,QAAU,eADkC;IACjB1D,MAAQ,cADS;IACOsB,MAAQ;EADf,CAD/ChB,EAE8D;IAC3DoD,QAAU,cADiD;IACjC1D,MAAQ,aADyB;IACVsB,MAAQ;EADE,CAF9DhB,EAG4D;IACzDoD,QAAU,kBAD+C;IAC3B1D,MAAQ,gBADmB;IACDsB,MAAQ;EADP,CAH5DhB,EAImE;IAE/DoD,QAAU,0BAFqD;IAG/D1D,MAAQ,wBAHuD;IAI/DsB,MAAQ;EAJuD,CAJnEhB,EAQY;IAEToD,QAAU,mBAFD;IAEsB1D,MAAQ,MAF9B;IAEsCsB,MAAQ;EAF9C,CARZhB;AAToE,CAjD3DmD,EAoEiD;EAI1DtD,UAAY,oBAJ8C;EAK1DC,UAAY,SAL8C;EAM1DC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,OADyB;IAChBsB,MAAQ;EADQ,CADhDjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,QADkB;IACRsB,MAAQ;EADA,CAHzCjB,CAN0D;EAY1DC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAZ0D,CApEjDmD,EAiF2D;EAIpEtD,UAAY,mBAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,OADyB;IAChBsB,MAAQ;EADQ,CADhDjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,CANoE;EAWpEC;IACEoD,QAAU,OADZpD;IAEEN,MAAQ,OAFVM;IAGEgB,MAAQ,OAHVhB;IAIEqD,eAAgB;EAJlBrD;AAXoE,CAjF3DmD,EAgGS;EAIlBtD,UAAY,qBAJM;EAKlBC,UAAY,SALM;EAMlBC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,SADyB;IACdsB,MAAQ;EADM,CADhDjB,EAE0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,QADmB;IACTsB,MAAQ;EADC,CAF1CjB,CANkB;EAWlBC;IACGoD,QAAU,OADbpD;IACsBN,MAAQ,OAD9BM;IACuCgB,MAAQ;EAD/ChB,GAC+C;IAC5CoD,QAAU,eADkC;IACjB1D,MAAQ,cADS;IACOsB,MAAQ;EADf,CAD/ChB;AAXkB,CAhGTmD,EA6GqD;EAI9DtD,UAAY,sBAJkD;EAK9DC,UAAY,SALkD;EAM9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,SADyB;IACdsB,MAAQ;EADM,CADhDjB,EAE0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,QADmB;IACTsB,MAAQ;EADC,CAF1CjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,QADkB;IACRsB,MAAQ;EADA,CAHzCjB,CAN8D;EAY9DC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AAZ8D,CA7GrDmD,EAyH0C;EAGnDtD,UAAY,qBAHuC;EAInDC,UAAY,SAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,QADyB;IACfsB,MAAQ;EADO,CADhDjB,CALmD;EASnDC;IACGoD,QAAU,OADbpD;IACsBN,MAAQ,OAD9BM;IACuCgB,MAAQ;EAD/ChB,GAC+C;IAC3CoD,QAAU,uBADiC;IAE3C1D,MAAQ,qBAFmC;IAG3CsB,MAAQ,OAHmC;IAI3CqC,eAAgB;EAJ2B,CAD/CrD;AATmD,CAzH1CmD,EAuIW;EAKpBtD,UAAY,oBALQ;EAMpBC,UAAY,SANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,QADyB;IACfsB,MAAQ;EADO,CADhDjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,SADkB;IACPsB,MAAQ;EADD,CAFzCjB,EAG0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,QADmB;IACTsB,MAAQ;EADC,CAH1CjB,CAPoB;EAapBC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AAboB,CAvIXmD,EAoJ0C;EAGnDtD,UAAY,mBAHuC;EAInDC,UAAY,SAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,QADyB;IACfsB,MAAQ;EADO,CADhDjB;AALmD,CApJ1CoD,EA2JgC;EAIzCtD,UAAY,oBAJ6B;EAKzCC,UAAY,SAL6B;EAMzCC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,eAAhCK;IAAiDiB,MAAQ;EAAzDjB;AANyC,CA3JhCoD,CFAb;AAAA,IEiK6DM;EAAAN;AAAA,EFjK7D;AAAA,IGAaA;EAETtD,UAAY,SAFHsD;EAGTrD,UAAY,aAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAJSoD;EAOTnD;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CqC,eAAgB;EAJ2B,CAF/CrD,EAMoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,YAFV;IAEwBsB,MAAQ;EAFhC,CANpBhB,EAQoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CARpDrD;AAPSmD,GAgB2D;EAIpEtD,UAAY,SAJwD;EAKpEC,UAAY,aALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CqC,eAAgB;EAJ2B,CAF/CrD,EAMoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,YAFV;IAEwBsB,MAAQ;EAFhC,CANpBhB,EAQoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CARpDrD;AAToE,CAhB3DmD,EAkC2D;EAIpEtD,UAAY,mBAJwD;EAKpEC,UAAY,aALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC5CoD,QAAU,OADkC;IACzB1D,MAAQ,YADiB;IACHsB,MAAQ;EADL,CAF/ChB,EAGoD;IAChDoD,QAAU,wBADsC;IAEhD1D,MAAQ,qBAFwC;IAGhDsB,MAAQ;EAHwC,CAHpDhB,EAMY;IAEToD,QAAU,GAFD;IAEM1D,MAAQ,OAFd;IAEuBsB,MAAQ,OAF/B;IAEwCqC,eAAgB;EAFxD,CANZrD;AAToE,CAlC3DmD,EAmD2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,aALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CqC,eAAgB;EAJ2B,CAF/CrD,EAMoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,YAFV;IAEwBsB,MAAQ;EAFhC,CANpBhB,EAQoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CARpDrD;AAToE,CAnD3DmD,EAqE2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,aALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CqC,eAAgB;EAJ2B,CAF/CrD,EAMoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,YAFV;IAEwBsB,MAAQ;EAFhC,CANpBhB,EAQoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CARpDrD;AAToE,CArE3DmD,EAuF2D;EAIpEtD,UAAY,QAJwD;EAKpEC,UAAY,aALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,QADbpD;IACuBN,MAAQ,QAD/BM;IACyCgB,MAAQ;EADjDhB,GACiD;IAC9CoD,QAAU,SADoC;IACzB1D,MAAQ,KADiB;IACVsB,MAAQ;EADE,CADjDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CuC,cAAgB;EAJ2B,CAF/CvD,EAMoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CANpBrD,EAQoE;IAChEoD,QAAU,UADsD;IAEhE1D,MAAQ,UAFwD;IAGhEsB,MAAQ,QAHwD;IAIhEuC,cAAgB;EAJgD,CARpEvD;AAVoE,CAvF3DmD,EA6GW;EAKpBtD,UAAY,QALQ;EAMpBC,UAAY,aANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,CAPoB;EAWpBC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD,GACoE;IACjEoD,QAAU,SADuD;IAC5C1D,MAAQ,SADoC;IACzBsB,MAAQ;EADiB,CADpEhB,EAEmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CAFnDhB,EAG+C;IAC5CoD,QAAU,eADkC;IACjB1D,MAAQ,eADS;IACQsB,MAAQ;EADhB,CAH/ChB,EAI+D;IAC3DoD,QAAU,aADiD;IAE3D1D,MAAQ,YAFmD;IAG3DsB,MAAQ,QAHmD;IAI3DuC,cAAgB;EAJ2C,CAJ/DvD,EAQoB;IAEjBoD,QAAU,WAFO;IAEM1D,MAAQ,WAFd;IAE2BsB,MAAQ;EAFnC,CARpBhB;AAXoB,CA7GXmD,EAkI8C;EAIvDtD,UAAY,cAJ2C;EAKvDC,UAAY,aAL2C;EAMvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BC,KAAK,CADqB;IAClBpB,MAAQ,MADU;IACFsB,MAAQ;EADN,CAFzCjB,CANuD;EAWvDC;IACGoD,QAAU,UADbpD;IACyBN,MAAQ,SADjCM;IAC4CgB,MAAQ;EADpDhB,GACoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CADpDrD,EAEoE;IACjEoD,QAAU,SADuD;IAC5C1D,MAAQ,SADoC;IACzBsB,MAAQ;EADiB,CAFpEhB,EAGmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CAHnDhB,EAI+C;IAE3CoD,QAAU,mBAFiC;IAG3C1D,MAAQ,kBAHmC;IAI3CsB,MAAQ,UAJmC;IAK3CuC;EAL2C,CAJ/CvD,EASIuD;IAGAH,QAAU,kBAHVG;IAIA7D,MAAQ,eAJR6D;IAKAvC,MAAQ,MALRuC;IAMAA,eAAgB;EANhBA,CATJvD,EAeoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CAfpBvD,EAqBoB;IAGhBoD,QAAU,WAHM;IAIhB1D,MAAQ,WAJQ;IAKhBsB,MAAQ,UALQ;IAMhBuC,eAAiB,CAAjBA,EAAoB,CAApBA,EAAuB,CAAvBA,EAA0B,CAA1BA;EANgB,CArBpBvD,EA2B8B;IAG1BoD,QAAU,WAHgB;IAI1B1D,MAAQ,UAJkB;IAK1BsB,MAAQ,UALkB;IAM1BuC;EAN0B,CA3B9BvD,EAiCIuD;IAGAH,QAAU,SAHVG;IAIA7D,MAAQ,SAJR6D;IAKAvC,MAAQ,QALRuC;IAMAA,cAAgB;EANhBA,CAjCJvD;AAXuD,CAlI9CmD,EAoLW;EAKpBtD,UAAY,qBALQ;EAMpBC,UAAY,aANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,aADkB;IACHsB,MAAQ;EADL,CAFzCjB,CAPoB;EAYpBC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CqC,eAAgB;EAJ2B,CAF/CrD;AAZoB,CApLXmD,EAsMW;EAKpBtD,UAAY,iBALQ;EAMpBC,UAAY,aANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CADxCjB,CAPoB;EAWpBC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CuC,cAAgB;EAJ2B,CAF/CvD,EAMoB;IAEjBoD,QAAU,WAFO;IAEM1D,MAAQ,WAFd;IAE2BsB,MAAQ;EAFnC,CANpBhB;AAXoB,CAtMXmD,EAyN8C;EAIvDtD,UAAY,uBAJ2C;EAKvDC,UAAY,aAL2C;EAMvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CADxCjB,CANuD;EAUvDC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CuC,cAAgB;EAJ2B,CAF/CvD,EAMoB;IAEjBoD,QAAU,WAFO;IAEM1D,MAAQ,WAFd;IAE2BsB,MAAQ;EAFnC,CANpBhB;AAVuD,CAzN9CmD,EA2O8C;EAIvDtD,UAAY,4BAJ2C;EAKvDC,UAAY,aAL2C;EAMvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BC,KAAK,CADqB;IAClBpB,MAAQ,MADU;IACFsB,MAAQ;EADN,CAFzCjB,CANuD;EAWvDC;IACGoD,QAAU,UADbpD;IACyBN,MAAQ,SADjCM;IAC4CgB,MAAQ;EADpDhB,GACoD;IACjDoD,QAAU,GADuC;IAClC1D,MAAQ,OAD0B;IACjBsB,MAAQ,OADS;IACAqC,eAAgB;EADhB,CADpDrD,EAEoE;IACjEoD,QAAU,SADuD;IAC5C1D,MAAQ,SADoC;IACzBsB,MAAQ;EADiB,CAFpEhB,EAGmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CAHnDhB,EAI+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CuC,cAAgB;EAJ2B,CAJ/CvD,EAQoB;IAGhBoD,QAAU,WAHM;IAIhB1D,MAAQ,WAJQ;IAKhBsB,MAAQ,UALQ;IAMhBuC,eAAiB,CAAjBA,EAAoB,CAApBA,EAAuB,CAAvBA,EAA0B,CAA1BA;EANgB,CARpBvD,EAc8B;IAG1BoD,QAAU,WAHgB;IAI1B1D,MAAQ,UAJkB;IAK1BsB,MAAQ,UALkB;IAM1BuC;EAN0B,CAd9BvD;AAXuD,CA3O9CmD,EA0QLI;EAKJ1D,UAAY,QALR0D;EAMJzD,UAAY,aANRyD;EAOJxD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,QADa;IACHsB,MAAQ;EADL,CADpCjB,CAPIwD;EAWJvD;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAChDoD,QAAU,SADsC;IAC3B1D,MAAQ,KADmB;IACZsB,MAAQ;EADI,CADnDhB,EAE+C;IAC3CoD,QAAU,aADiC;IAE3C1D,MAAQ,YAFmC;IAG3CsB,MAAQ,QAHmC;IAI3CuC,cAAgB;EAJ2B,CAF/CvD,EAMoB;IAEjBoD,QAAU,WAFO;IAEM1D,MAAQ,WAFd;IAE2BsB,MAAQ;EAFnC,CANpBhB;AAXIuD,CA1QKJ,CHAb;AAAA,IG6R2DO;EAAAP;AAAA,EH7R3D;AAAA,IIAaA;EAETtD,UAAY,MAFHsD;EAGTrD,UAAY,UAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,OADiB;IACRsB,MAAQ;EADA,CADxCjB,CAJSoD;EAQTnD;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AARSmD,GAQ0C;EAGnDtD,UAAY,UAHuC;EAInDC,UAAY,UAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,MADiB;IACTsB,MAAQ;EADC,CADxCjB,EAEuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,KADgB;IACTsB,MAAQ;EADC,CAFvCjB,CALmD;EAUnDC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVmD,CAR1CmD,EAmB2D;EAIpEtD,UAAY,QAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,SADvBK;IACkCiB,MAAQ;EAD1CjB,GAC0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,OADmB;IACVsB,MAAQ;EADE,CAD1CjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,SADiB;IACNsB,MAAQ,QADF;IACYuC,cAAgB;EAD5B,CAFxCxD,EAGoE;IACjEc,OAAS,CADwD;IACrDnB,MAAQ,UAD6C;IACjCsB,MAAQ,QADyB;IACfuC,cAAgB;EADD,CAHpExD,CANoE;EAYpEC;IAEIoD,QAAU,MAFdpD;IAGIN,MAAQ,MAHZM;IAIIgB,MAAQ,QAJZhB;IAKIqD,eAAgB;EALpBrD,GAKoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CALpBrD;AAZoE,CAnB3DmD,EAsC2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,EANoE;EASpEC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AAToE,CAtC3DmD,EA+C0C;EAGnDtD,UAAY,UAHuC;EAInDC,UAAY,UAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EALmD;EAQnDC;IAAWoD,QAAU,OAArBpD;IAA8BN,MAAQ,OAAtCM;IAA+CgB,MAAQ;EAAvDhB;AARmD,CA/C1CmD,EAuD8C;EAGvDtD,UAAY,eAH2C;EAIvDC,UAAY,UAJ2C;EAKvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,EALuD;EAQvDC;IAEIoD,QAAU,QAFdpD;IAGIN,MAAQ,QAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,QAHM;IAIhB1D,MAAQ,QAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CALpBvD,EAWoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,OAFV;IAEmBsB,MAAQ;EAF3B,CAXpBhB,EAa+C;IAC5CoD,QAAU,MADkC;IAC1B1D,MAAQ,MADkB;IACVsB,MAAQ,QADE;IACQuC,cAAgB;EADxB,CAb/CvD,EAcuE;IACnEoD,QAAU,OADyD;IAEnE1D,MAAQ,OAF2D;IAGnEsB,MAAQ,QAH2D;IAInEuC,cAAgB,CAJmD;IAKnEF,eAAgB;EALmD,CAdvErD,EAmBoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,GAFN;IAEWsB,MAAQ,QAFnB;IAE6BqC,eAAgB;EAF7C,CAnBpBrD;AARuD,CAvD9CmD,EAoFwD;EAIjEtD,UAAY,OAJqD;EAKjEC,UAAY,UALqD;EAMjEC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,MADiB;IACTsB,MAAQ;EADC,CADxCjB,EAEuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,MADgB;IACRsB,MAAQ,QADA;IACUuC,cAAgB;EAD1B,CAFvCxD,CANiE;EAWjEC;IAAWoD,QAAU,MAArBpD;IAA6BN,MAAQ,OAArCM;IAA8CgB,MAAQ;EAAtDhB;AAXiE,CApFxDmD,EA+F6C;EAGtDtD,UAAY,iBAH0C;EAItDC,UAAY,UAJ0C;EAKtDC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,EALsD;EAQtDC;IAEIoD,QAAU,OAFdpD;IAGIN,MAAQ,MAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,QAHM;IAIhB1D,MAAQ,QAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CALpBvD,EAWoB;IAEjBoD,QAAU,MAFO;IAEC1D,MAAQ,MAFT;IAEiBsB,MAAQ;EAFzB,CAXpBhB,EAa6C;IACzCoD,QAAU,OAD+B;IAEzC1D,MAAQ,OAFiC;IAGzCsB,MAAQ,QAHiC;IAIzCuC,cAAgB,CAJyB;IAKzCF,eAAgB;EALyB,CAb7CrD,EAkBoB;IAEjBoD,QAAU,OAFO;IAEE1D,MAAQ,OAFV;IAEmBsB,MAAQ;EAF3B,CAlBpBhB,EAoB+C;IAC5CoD,QAAU,GADkC;IAC7B1D,MAAQ,GADqB;IAChBsB,MAAQ,QADQ;IACEqC,eAAgB;EADlB,CApB/CrD;AARsD,CA/F7CmD,EA4HwD;EAIjEtD,UAAY,OAJqD;EAKjEC,UAAY,UALqD;EAMjEC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,EANiE;EASjEC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AATiE,CA5HxDmD,EAqI0C;EAGnDtD,UAAY,WAHuC;EAInDC,UAAY,UAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EALmD;EAQnDC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,OAAlCM;IAA2CgB,MAAQ;EAAnDhB;AARmD,CArI1CmD,EA6I0C;EAGnDtD,UAAY,aAHuC;EAInDC,UAAY,UAJuC;EAKnDC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,GACyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,YADkB;IACJsB,MAAQ;EADJ,CADzCjB,CALmD;EASnDC;IACGoD,QAAU,MADbpD;IACqBN,MAAQ,MAD7BM;IACqCgB,MAAQ;EAD7ChB,GAC6C;IAC1CoD,QAAU,OADgC;IACvB1D,MAAQ,OADe;IACNsB,MAAQ;EADF,CAD7ChB,EAE+C;IAC5CoD,QAAU,GADkC;IAC7B1D,MAAQ,OADqB;IACZsB,MAAQ;EADI,CAF/ChB,EAG2C;IACxCoD,QAAU,cAD8B;IACd1D,MAAQ,cADM;IACUsB,MAAQ;EADlB,CAH3ChB;AATmD,CA7I1CmD,CJAb;AAAA,II0JiEQ;EAAAR;AAAA,EJ1JjE;AAAA,IKAaA;EAETtD,UAAY,qBAFHsD;EAGTrD,UAAY,SAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CADxCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,eADkB;IACDsB,MAAQ;EADP,CAFzCjB,EAGgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,cADyB;IACTsB,MAAQ;EADC,CAHhDjB;AAJSoD,GAQsC;EAI/CtD,UAAY,qBAJmC;EAK/CC,UAAY,SALmC;EAM/CC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CADxCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,eADkB;IACDsB,MAAQ;EADP,CAFzCjB,EAGgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,cADyB;IACTsB,MAAQ;EADC,CAHhDjB,EAI+C;IAC5Cc,OAAS,CADmC;IAChCnB,MAAQ,gBADwB;IACNsB,MAAQ;EADF,CAJ/CjB;AAN+C,CARtCoD,EAmBwC;EAIjDtD,UAAY,qBAJqC;EAKjDC,UAAY,SALqC;EAMjDC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CADxCjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,eADkB;IACDsB,MAAQ;EADP,CAFzCjB,EAGgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,cADyB;IACTsB,MAAQ;EADC,CAHhDjB,EAI+C;IAC5Cc,OAAS,CADmC;IAChCnB,MAAQ,gBADwB;IACNsB,MAAQ;EADF,CAJ/CjB,EAKiD;IAC9Cc,OAAS,CADqC;IAClCnB,MAAQ,cAD0B;IACVsB,MAAQ;EADE,CALjDjB;AANiD,CAnBxCoD,EA+BsC;EAI/CtD,UAAY,OAJmC;EAK/CC,UAAY,SALmC;EAM/CC;IACGc,OAAS,CADZd;IACeL,MAAQ,WADvBK;IACoCiB,MAAQ;EAD5CjB,EAN+C;EAS/CC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAT+C,CA/BtCmD,EAyC2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACEoD,QAAU,GADZpD;IAEEN,MAAQ,OAFVM;IAGEgB,MAAQ,OAHVhB;IAIEqD,eAAgB;EAJlBrD;AAVoE,CAzC3DmD,CLAb;AAAA,IKuDsBS;EAAAT;AAAA,ELvDtB;AAAA,IMAaA;EACXtD,UAAY,QADDsD;EAEXrD,UAAY,YAFDqD;EAGXpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CAHWoD;EAOXnD;IAAWoD,QAAU,QAArBpD;IAA+BN,MAAQ,QAAvCM;IAAiDgB,MAAQ;EAAzDhB;AAPWmD,ENAb;AAAA,IMO2DU;EAAAV;AAAA,ENP3D;AAAA,IOAaA;EAETtD,UAAY,wBAFHsD;EAGTrD,UAAY,OAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,SADvBK;IACkCiB,MAAQ;EAD1CjB,EAJSoD;EAOTnD;IACGoD,QAAU,OADbpD;IACsBN,MAAQ,OAD9BM;IACuCgB,MAAQ;EAD/ChB,GAC+C;IAC5CoD,QAAU,OADkC;IACzB1D,MAAQ,OADiB;IACRsB,MAAQ;EADA,CAD/ChB;AAPSmD,GASsC;EAI/CtD,UAAY,aAJmC;EAK/CC,UAAY,OALmC;EAM/CE;IACGoD,QAAU,OADbpD;IACsBN,MAAQ,OAD9BM;IACuCgB,MAAQ;EAD/ChB,GAC+C;IAC5CoD,QAAU,OADkC;IACzB1D,MAAQ,OADiB;IACRsB,MAAQ;EADA,CAD/ChB;AAN+C,CATtCmD,EAiBsC;EAGhDtD,UAAY,OAHoC;EAG3BC,UAAY;AAHe,CAjBtCqD,EAoBuB;EAChCtD,UAAY,UADoB;EAEhCC,UAAY,OAFoB;EAGhCC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAHgC,CApBvBoD,EAuBoC;EAG7CtD,UAAY,WAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBe,KAAO,CAA/Bf;IAAkCL,MAAQ,GAA1CK;IAA+CiB,MAAQ;EAAvDjB;AAL6C,CAvBpCoD,EA4B8C;EAGvDtD,UAAY,UAH2C;EAIvDC,UAAY,OAJ2C;EAKvDC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AALuD,CA5B9CoD,EAiCoC;EAG7CtD,UAAY,MAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAL6C,CAjCpCoD,EAsCoC;EAG7CtD,UAAY,MAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAL6C,CAtCpCoD,EA2CoC;EAG7CtD,UAAY,OAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAL6C,CA3CpCoD,EAgDoC;EAG7CtD,UAAY,QAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBe,KAAO,CAA/Bf;IAAkCL,MAAQ,GAA1CK;IAA+CiB,MAAQ;EAAvDjB;AAL6C,CAhDpCoD,EAqD8C;EAGvDtD,UAAY,OAH2C;EAIvDC,UAAY,OAJ2C;EAKvDC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CALuD;EASvDC;IACGoD,QAAU,SADbpD;IACwBN,MAAQ,SADhCM;IAC2CgB,MAAQ;EADnDhB,GACmD;IAC/CoD,QAAU,SADqC;IAE/C1D,MAAQ,QAFuC;IAG/CsB,MAAQ,QAHuC;IAI/CqC,eAAgB;EAJ+B,CADnDrD,EAKoB;IAGhBoD,QAAU,WAHM;IAIhB1D,MAAQ,WAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CALpBvD;AATuD,CArD9CmD,EAyEW;EAIrBtD,UAAY,MAJS;EAIDC,UAAY,OAJX;EAIoBC;AAJpB,CAzEXoD,EA6E+BpD;EACxCF,UAAY,cAD4BE;EAExCD,UAAY,OAF4BC;EAGxCA;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAHwCA,CA7E/BoD,EAgFoC;EAG7CtD,UAAY,yBAHiC;EAI7CC,UAAY,OAJiC;EAK7CC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAL6C;EAQ7CC;IACGoD,QAAU,KADbpD;IACoBN,MAAQ,KAD5BM;IACmCgB,MAAQ;EAD3ChB,GAC2C;IACxCoD,QAAU,KAD8B;IACvB1D,MAAQ,KADe;IACRsB,MAAQ;EADA,CAD3ChB;AAR6C,CAhFpCmD,CPAb;AAAA,IO0F+CW;EAAAX;AAAA,EP1F/C;AAAA,IQAaA;EAETtD,UAAY,gBAFHsD;EAGTrD,UAAY,OAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,GACyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,MADkB;IACVsB,MAAQ;EADE,CADzCjB,CAJSoD;EAQTnD;IACGoD,QAAU,eADbpD;IAC8BN,MAAQ,cADtCM;IACsDgB,MAAQ;EAD9DhB,GAC8D;IAC3DoD,QAAU,GADiD;IAC5C1D,MAAQ,OADoC;IAC3BsB,MAAQ,OADmB;IACVqC,eAAgB;EADN,CAD9DrD;AARSmD,GAU2D;EAIpEtD,UAAY,uBAJwD;EAKpEC,UAAY,OALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,GACyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,MADkB;IACVsB,MAAQ;EADE,CADzCjB,CANoE;EAUpEC;IACGoD,QAAU,eADbpD;IAC8BN,MAAQ,cADtCM;IACsDgB,MAAQ;EAD9DhB,GAC8D;IAC3DoD,QAAU,GADiD;IAC5C1D,MAAQ,OADoC;IAC3BsB,MAAQ,OADmB;IACVqC,eAAgB;EADN,CAD9DrD;AAVoE,CAV3DmD,EAsB2D;EAIpEtD,UAAY,eAJwD;EAKpEC,UAAY,OALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,OADvBK;IACgCiB,MAAQ;EADxCjB,GACwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,OADiB;IACRsB,MAAQ;EADA,CADxCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,UADkB;IACNsB,MAAQ;EADF,CAHzCjB,CANoE;EAYpEC;IACGoD,QAAU,QADbpD;IACuBN,MAAQ,QAD/BM;IACyCgB,MAAQ;EADjDhB,GACiD;IAC7CoD,QAAU,qBADmC;IAE7C1D,MAAQ,oBAFqC;IAG7CsB,MAAQ;EAHqC,CADjDhB;AAZoE,CAtB3DmD,CRAb;AAAA,IQsCgBY;EAAAZ;AAAA,ERtChB;AAAA,ISAaA;EAETtD,UAAY,OAFHsD;EAGTrD,UAAY,SAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CAJSoD;EAQTnD;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AARSmD,GAS2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAT3DmD,EAoB2D;EAIpEtD,UAAY,SAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CApB3DmD,EA+B2D;EAIpEtD,UAAY,cAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA/B3DmD,EA0C2D;EAIpEtD,UAAY,MAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CA1C3DmD,EAqD2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CArD3DmD,EAgE2D;EAIpEtD,UAAY,YAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CAhE3DmD,EA2E2D;EAIpEtD,UAAY,YAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANoE;EASpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAToE,CA3E3DmD,EAqF2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAVoE,CArF3DmD,EAgG2D;EAIpEtD,UAAY,QAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,WADvBK;IACoCiB,MAAQ;EAD5CjB,GAC4C;IACzCc,OAAS,CADgC;IAC7BnB,MAAQ,GADqB;IAChBsB,MAAQ;EADQ,CAD5CjB,EAEoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CAFpCjB,CANoE;EAWpEC;IACGoD,QAAU,GADbpD;IACkBN,MAAQ,OAD1BM;IACmCgB,MAAQ,OAD3ChB;IACoDqD,eAAgB;EADpErD;AAXoE,CAhG3DmD,EA4G2D;EAIpEtD,UAAY,UAJwD;EAKpEC,UAAY,SALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,WADvBK;IACoCiB,MAAQ;EAD5CjB,GAC4C;IACzCc,OAAS,CADgC;IAC7BnB,MAAQ,GADqB;IAChBsB,MAAQ;EADQ,CAD5CjB,EAEoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CAFpCjB,CANoE;EAWpEC;IACEoD,QAAU,GADZpD;IAEEN,MAAQ,OAFVM;IAGEgB,MAAQ,OAHVhB;IAIEqD,eAAgB;EAJlBrD;AAXoE,CA5G3DmD,CTAb;AAAA,IS2HsBa;EAAAb;AAAA,ET3HtB;AAAA,IUAaA;EAETtD,UAAY,cAFHsD;EAGTrD,UAAY,UAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,EAEoC;IACjCc,OAAS,CADwB;IACrBC,KAAK,CADgB;IACbpB,MAAQ,MADK;IACGsB,MAAQ;EADX,CAFpCjB,CAJSoD;EASTnD;IACGoD,QAAU,UADbpD;IACyBN,MAAQ,SADjCM;IAC4CgB,MAAQ;EADpDhB,GACoD;IAChDoD,QAAU,WADsC;IAEhD1D,MAAQ,UAFwC;IAGhDsB,MAAQ,UAHwC;IAIhDuC;EAJgD,CADpDvD,EAKIuD;IAGAH,QAAU,SAHVG;IAIA7D,MAAQ,SAJR6D;IAKAvC,MAAQ,QALRuC;IAMAA,cAAgB;EANhBA,CALJvD,EAWoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,MALQ;IAMhBuC,eAAgB;EANA,CAXpBvD,EAiBoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,MALQ;IAMhBuC,eAAgB;EANA,CAjBpBvD,EAuBoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CAvBpBrD;AATSmD,GAkC2D;EAIpEtD,UAAY,QAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IAEIoD,QAAU,aAFdpD;IAGIN,MAAQ,YAHZM;IAIIgB,MAAQ,MAJZhB;IAKIuD,eAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,MALQ;IAMhBuC,eAAgB;EANA,CALpBvD,EAWoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CAXpBrD;AAVoE,CAlC3DmD,EAyD2D;EAIpEtD,UAAY,aAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IAEIoD,QAAU,OAFdpD;IAGIN,MAAQ,YAHZM;IAIIgB,MAAQ,MAJZhB;IAKIuD,eAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,OAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,MALQ;IAMhBuC,eAAgB;EANA,CALpBvD,EAWoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CAXpBrD;AAVoE,CAzD3DmD,EAgF2D;EAIpEtD,UAAY,eAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,GADa;IACRsB,MAAQ;EADA,CADpCjB,CANoE;EAUpEC;IAEIoD,QAAU,OAFdpD;IAGIN,MAAQ,YAHZM;IAIIgB,MAAQ,MAJZhB;IAKIuD,eAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,OAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,MALQ;IAMhBuC,eAAgB;EANA,CALpBvD,EAWoB;IAEjBoD,QAAU,GAFO;IAEF1D,MAAQ,OAFN;IAEesB,MAAQ,OAFvB;IAEgCqC,eAAgB;EAFhD,CAXpBrD;AAVoE,CAhF3DmD,EAuG2D;EAIpEtD,UAAY,WAJwD;EAKpEC,UAAY,UALwD;EAMpEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CANoE;EAUpEC;IACEoD,QAAU,GADZpD;IAEEN,MAAQ,OAFVM;IAGEgB,MAAQ,OAHVhB;IAIEqD,eAAgB;EAJlBrD;AAVoE,CAvG3DmD,CVAb;AAAA,IUqHsBc;EAAAd;AAAA,EVrHtB;AAAA,IWAaA;EAETtD,UAAY,gBAFHsD;EAGTrD,UAAY,eAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,MADkB;IACVsB,MAAQ;EADE,CAHzCjB,EAIuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,UADgB;IACJsB,MAAQ;EADJ,CAJvCjB,CAJSoD;EAWTnD;IAEIoD,QAAU,SAFdpD;IAGIN,MAAQ,SAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,QALQ;IAMhBqC,eAAgB;EANA,CALpBrD;AAXSmD,GAsBW;EAKpBtD,UAAY,kBALQ;EAMpBC,UAAY,eANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,MADkB;IACVsB,MAAQ;EADE,CAHzCjB,EAIuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,UADgB;IACJsB,MAAQ;EADJ,CAJvCjB,CAPoB;EAcpBC;IAEIoD,QAAU,SAFdpD;IAGIN,MAAQ,SAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,QALQ;IAMhBqC,eAAgB;EANA,CALpBrD;AAdoB,CAtBXmD,EA+CW;EAKpBtD,UAAY,kBALQ;EAMpBC,UAAY,eANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,QADiB;IACPsB,MAAQ;EADD,CAFxCjB,EAGyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,MADkB;IACVsB,MAAQ;EADE,CAHzCjB,EAIuC;IACpCc,OAAS,CAD2B;IACxBnB,MAAQ,UADgB;IACJsB,MAAQ;EADJ,CAJvCjB,CAPoB;EAcpBC;IAEIoD,QAAU,SAFdpD;IAGIN,MAAQ,SAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,aAHM;IAIhB1D,MAAQ,YAJQ;IAKhBsB,MAAQ,QALQ;IAMhBqC,eAAgB;EANA,CALpBrD;AAdoB,CA/CXmD,EAwEW;EAKpBtD,UAAY,KALQ;EAMpBC,UAAY,eANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAPoB;EAUpBC;IAEIoD,QAAU,cAFdpD;IAGIN,MAAQ,QAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAEjBoD,QAAU,MAFO;IAEC1D,MAAQ,MAFT;IAEiBsB,MAAQ,QAFzB;IAEmCuC,cAAgB;EAFnD,CALpBvD,EAOuE;IAEnEoD,QAAU,OAFyD;IAGnE1D,MAAQ,OAH2D;IAInEsB,MAAQ,QAJ2D;IAKnEuC,cAAgB;EALmD,CAPvEvD,EAYoB;IAGhBoD,QAAU,MAHM;IAIhB1D,MAAQ,MAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CAZpBvD;AAVoB,CAxEXmD,EAoGW;EAKpBtD,UAAY,SALQ;EAMpBC,UAAY,eANQ;EAOpBC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAPoB,CApGXoD,EA2GoC;EAG7CtD,UAAY,YAHiC;EAI7CC,UAAY,eAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAL6C,CA3GpCoD,EAgHoC;EAG7CtD,UAAY,eAHiC;EAI7CC,UAAY,eAJiC;EAK7CC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,aADyB;IACVsB,MAAQ;EADE,CADhDjB,EAE8C;IAC3Cc,OAAS,CADkC;IAC/BnB,MAAQ,cADuB;IACPsB,MAAQ;EADD,CAF9CjB,EAG+C;IAC5Cc,OAAS,CADmC;IAChCnB,MAAQ,cADwB;IACRsB,MAAQ;EADA,CAH/CjB,CAL6C;EAW7CC;IACEoD,QAAU,kBADZpD;IAEEN,MAAQ,iBAFVM;IAGEgB,MAAQ,MAHVhB;IAIEuD,eAAgB,CAJlBvD;IAKEqD,eAAgB;EALlBrD;AAX6C,CAhHpCmD,CXAb;AAAA,IWgIsBe;EAAAf;AAAA,EXhItB;AAAA,IYAaA;EAETtD,UAAY,KAFHsD;EAGTrD,UAAY,WAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAJSoD;EAQTnD;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AARSmD,GAQqD;EAG9DtD,UAAY,MAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAL8D;EAS9DC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAT8D,CARrDmD,EAiBqD;EAG9DtD,UAAY,KAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAL8D;EAS9DC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAT8D,CAjBrDmD,EA0BqD;EAG9DtD,UAAY,KAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAL8D;EAS9DC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAT8D,CA1BrDmD,EAmCqD;EAG9DtD,UAAY,KAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAL8D;EAS9DC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAT8D,CAnCrDmD,EA4CqD;EAG9DtD,UAAY,KAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CAL8D;EAS9DC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAT8D,CA5CrDmD,EAqDqD;EAG9DtD,UAAY,QAHkD;EAI9DC,UAAY,WAJkD;EAK9DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB;AAL8D,CArDrDoD,EA4D8B;EAIvCtD,UAAY,QAJ2B;EAKvCC,UAAY,WAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB;AANuC,CA5D9BoD,EAoE8B;EAIvCtD,UAAY,MAJ2B;EAKvCC,UAAY,WAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB,CANuC;EAUvCC;IAAWoD,QAAU,WAArBpD;IAAkCN,MAAQ,UAA1CM;IAAsDgB,MAAQ;EAA9DhB;AAVuC,CApE9BmD,CZAb;AAAA,IY8EkEgB;EAAAhB;AAAA,EZ9ElE;AAAA,IaAaA;EAETtD,UAAY,UAFHsD;EAGTrD,UAAY,YAHHqD;EAITpD;IACGc,OAAS,CADZd;IACee,MAAQ,CADvBf;IAC0BL,MAAQ,SADlCK;IAC6CiB,MAAQ;EADrDjB,GACqD;IAClDc,QAAU,CADwC;IACrCnB,MAAQ,MAD6B;IACrBsB,MAAQ;EADa,CADrDjB,CAJSoD;EAQTnD;IACMoD,QAAU,GADhBpD;IACqBN,MAAQ,GAD7BM;IACkCgB,MAAQ,QAD1ChB;IACoDuD,cAAgB;EADpEvD;AARSmD,GAS2D;EAGpEtD,UAAY,QAHwD;EAIpEC,UAAY,YAJwD;EAKpEC;IACGc,OAAS,CADZd;IACee,KAAO,CADtBf;IACyBL,MAAQ,SADjCK;IAC4CiB,MAAQ;EADpDjB,GACoD;IACjDc,OAAS,CADwC;IACrCnB,MAAQ,MAD6B;IACrBsB,MAAQ;EADa,CADpDjB,CALoE;EASpEC;IAAWoD,QAAU,GAArBpD;IAA0BN,MAAQ,GAAlCM;IAAuCgB,MAAQ,QAA/ChB;IAAyDuD,cAAgB;EAAzEvD;AAToE,CAT3DmD,EAkBgE;EAIzEtD,UAAY,UAJ6D;EAKzEC,UAAY,YAL6D;EAMzEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,SADa;IACFsB,MAAQ;EADN,CADpCjB,EAE0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,MADmB;IACXsB,MAAQ,QADG;IACOuC,cAAgB;EADvB,CAF1CxD;AANyE,CAlBhEoD,EA2BwD;EAIjEtD,UAAY,QAJqD;EAKjEC,UAAY,YALqD;EAMjEC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,SADa;IACFsB,MAAQ;EADN,CADpCjB,CANiE;EAUjEC;IACGoD,QAAU,MADbpD;IACqBN,MAAQ,MAD7BM;IACqCgB,MAAQ,QAD7ChB;IACuDuD,cAAgB;EADvEvD,GACuE;IACnEoD,QAAU,kBADyD;IAEnE1D,MAAQ,iBAF2D;IAGnEsB,MAAQ,MAH2D;IAInEqC,eAAgB;EAJmD,CADvErD;AAViE,CA3BxDmD,EA0CW;EAKpBtD,UAAY,SALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ,MADH;IACWqC,eAAgB;EAD3B,CADpCtD;AAPoB,CA1CXoD,EAmDsD;EAI/DtD,UAAY,WAJmD;EAK/DC,UAAY,YALmD;EAM/DC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB;AAN+D,CAnDtDoD,EA2D8B;EAIvCtD,UAAY,OAJ2B;EAKvCC,UAAY,YAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,MADiB;IACTsB,MAAQ;EADC,CAFxCjB;AANuC,CA3D9BoD,EAoE8B;EAIvCtD,UAAY,cAJ2B;EAKvCC,UAAY,YAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB,EAEwC;IACrCc,OAAS,CAD4B;IACzBnB,MAAQ,KADiB;IACVsB,MAAQ;EADE,CAFxCjB,EAGsC;IACnCc,OAAS,CAD0B;IACvBnB,MAAQ,SADe;IACJsB,MAAQ;EADJ,CAHtCjB,CANuC;EAYvCC;IAEIoD,QAAU,YAFdpD;IAGIN,MAAQ,WAHZM;IAIIgB,MAAQ,QAJZhB;IAKIuD,cAAgB;EALpBvD,GAKoB;IAGhBoD,QAAU,UAHM;IAIhB1D,MAAQ,SAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CALpBvD,EAWoB;IAGhBoD,QAAU,eAHM;IAIhB1D,MAAQ,aAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CAXpBvD,EAiBoB;IAGhBoD,QAAU,eAHM;IAIhB1D,MAAQ,cAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CAjBpBvD,EAuBoB;IAGhBoD,QAAU,kBAHM;IAIhB1D,MAAQ,gBAJQ;IAKhBsB,MAAQ,QALQ;IAMhBuC,cAAgB;EANA,CAvBpBvD;AAZuC,CApE9BmD,EA6GW;EAKpBtD,UAAY,MALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACee,KAAO,CADtBf;IACyBL,MAAQ,SADjCK;IAC4CiB,MAAQ;EADpDjB,EAPoB;EAUpBC;IACGoD,QAAU,MADbpD;IACqBN,MAAQ,MAD7BM;IACqCgB,MAAQ,QAD7ChB;IACuDuD,cAAgB;EADvEvD;AAVoB,CA7GXmD,EAwH8D;EAIvEtD,UAAY,QAJ2D;EAKvEC,UAAY,YAL2D;EAMvEC;IACGc,OAAS,CADZd;IACeL,MAAQ,QADvBK;IACiCiB,MAAQ;EADzCjB,EANuE;EASvEC;IACGoD,QAAU,MADbpD;IACqBN,MAAQ,MAD7BM;IACqCgB,MAAQ,QAD7ChB;IACuDuD,cAAgB;EADvEvD,GACuE;IACnEoD,QAAU,KADyD;IAEnE1D,MAAQ,KAF2D;IAGnEsB,MAAQ,QAH2D;IAInEuC,cAAgB,CAJmD;IAKnEF,eAAgB;EALmD,CADvErD;AATuE,CAxH9DmD,EAuIW;EAKpBtD,UAAY,MALQ;EAMpBC,UAAY,YANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB;AAPoB,CAvIXoD,EAgJ8B;EAIvCtD,UAAY,OAJ2B;EAKvCC,UAAY,YAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,MADvBK;IAC+BiB,MAAQ,QADvCjB;IACiDwD,cAAgB;EADjExD,GACiE;IAC9Dc,OAAS,CADqD;IAClDnB,MAAQ,GAD0C;IACrCsB,MAAQ;EAD6B,CADjEjB,CANuC;EAUvCC;IACEoD,QAAU,WADZpD;IAEEN,MAAQ,iBAFVM;IAGEgB,MAAQ,QAHVhB;IAIEuD,cAAgB;EAJlBvD;AAVuC,CAhJ9BmD,EA8JS;EAIlBtD,UAAY,QAJM;EAKlBC,UAAY,YALM;EAMlBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,iBADa;IACMsB,MAAQ;EADd,CADpCjB,EAEkD;IAC/Cc,OAAS,CADsC;IACnCnB,MAAQ,MAD2B;IACnBsB,MAAQ,QADW;IACDuC,cAAgB;EADf,CAFlDxD;AANkB,CA9JToD,EAuKwD;EAIjEtD,UAAY,WAJqD;EAKjEC,UAAY,YALqD;EAMjEC;IACGc,OAAS,CADZd;IACeL,MAAQ,SADvBK;IACkCiB,MAAQ;EAD1CjB,GAC0C;IACvCc,OAAS,CAD8B;IAC3BnB,MAAQ,QADmB;IACTsB,MAAQ;EADC,CAD1CjB,EAEyC;IACtCc,OAAS,CAD6B;IAC1BnB,MAAQ,OADkB;IACTsB,MAAQ;EADC,CAFzCjB;AANiE,CAvKxDoD,EAgL+B;EAIxCtD,UAAY,UAJ4B;EAKxCC,UAAY,YAL4B;EAMxCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,SADa;IACFsB,MAAQ;EADN,CADpCjB;AANwC,CAhL/BoD,EAwLiC;EAI1CtD,UAAY,eAJ8B;EAK1CC,UAAY,YAL8B;EAM1CC;IACGc,OAAS,CADZd;IACeL,MAAQ,eADvBK;IACwCiB,MAAQ;EADhDjB,GACgD;IAC7Cc,OAAS,CADoC;IACjCnB,MAAQ,aADyB;IACVsB,MAAQ;EADE,CADhDjB,EAE8C;IAC3Cc,OAAS,CADkC;IAC/BnB,MAAQ,cADuB;IACPsB,MAAQ;EADD,CAF9CjB,EAG+C;IAC5Cc,OAAS,CADmC;IAChCnB,MAAQ,cADwB;IACRsB,MAAQ;EADA,CAH/CjB,CAN0C;EAY1CC;IACEoD,QAAU,kBADZpD;IAEEN,MAAQ,iBAFVM;IAGEgB,MAAQ,MAHVhB;IAIEuD,eAAgB,CAJlBvD;IAKEqD,eAAgB;EALlBrD;AAZ0C,CAxLjCmD,CbAb;AAAA,IayMsBiB;EAAAjB;AAAA,EbzMtB;AAAA,IcAaA;EAETtD,UAAY,KAFHsD;EAGTrD,UAAY,UAHHqD;EAITpD;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAJSoD,GAIoC;EAG7CtD,UAAY,MAHiC;EAI7CC,UAAY,UAJiC;EAK7CC;IAAYc,OAAS,CAArBd;IAAwBL,MAAQ,GAAhCK;IAAqCiB,MAAQ;EAA7CjB;AAL6C,CAJpCoD,EASoC;EAG7CtD,UAAY,MAHiC;EAI7CC,UAAY,UAJiC;EAK7CC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IAChCc,OAAS,CADuB;IAEhCnB,MAAQ,YAFwB;IAGhCsB,MAAQ,QAHwB;IAIhCqC,eAAgB;EAJgB,CADpCtD;AAL6C,CATpCoD,EAmBW;EAKpBtD,UAAY,OALQ;EAMpBC,UAAY,UANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IAChCc,OAAS,CADuB;IAEhCnB,MAAQ,YAFwB;IAGhCsB,MAAQ,QAHwB;IAIhCqC,eAAgB;EAJgB,CADpCtD;AAPoB,CAnBXoD,CdAb;AAAA,Ic+BwBkB;EAAAlB;AAAA,Ed/BxB;AAAA,IeAaA;EAETtD,UAAY,MAFHsD;EAGTrD,UAAY,gBAHHqD;EAITpD;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EAJSoD;EAOTnD;IAEIoD,QAAU,MAFdpD;IAGIN,MAAQ,QAHZM;IAIIgB,MAAQ,OAJZhB;IAKIqD,eAAgB;EALpBrD,GAKoB;IAEjBoD,QAAU,MAFO;IAEC1D,MAAQ,OAFT;IAEkBsB,MAAQ;EAF1B,CALpBhB;AAPSmD,GAcqC;EAI9CtD,UAAY,YAJkC;EAK9CC,UAAY,gBALkC;EAM9CC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,MADa;IACLsB,MAAQ;EADH,CADpCjB;AAN8C,CAdrCoD,EAsB8B;EAIvCtD,UAAY,KAJ2B;EAKvCC,UAAY,gBAL2B;EAMvCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,SADa;IACFsB,MAAQ;EADN,CADpCjB,CANuC;EAUvCC;IACEoD,QAAU,gBADZpD;IAEEN,MAAQ,eAFVM;IAGEgB,MAAQ,QAHVhB;IAIEuD,cAAgB;EAJlBvD;AAVuC,CAtB9BmD,EAoCS;EAIlBtD,UAAY,OAJM;EAKlBC,UAAY,gBALM;EAMlBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,SADa;IACFsB,MAAQ;EADN,CADpCjB,EAE0C;IACtCc,OAAS,CAD6B;IAEtCnB,MAAQ,eAF8B;IAGtCsB,MAAQ,QAH8B;IAItCuC,cAAgB;EAJsB,CAF1CxD;AANkB,CApCToD,EAgDW;EAKpBtD,UAAY,SALQ;EAMpBC,UAAY,gBANQ;EAOpBC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,OADa;IACJsB,MAAQ;EADJ,CADpCjB;AAPoB,CAhDXoD,EAyD+B;EAIxCtD,UAAY,SAJ4B;EAKxCC,UAAY,gBAL4B;EAMxCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANwC;EASxCC;IACEoD,QAAU,MADZpD;IAEEsE,kBAAoB,cAFtBtE;IAGEN,MAAQ,MAHVM;IAIEgB,MAAQ;EAJVhB;AATwC,CAzD/BmD,EAsEC;EAIVtD,UAAY,gBAJF;EAKVC,UAAY,gBALF;EAMVC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,YADa;IACCsB,MAAQ;EADT,CADpCjB,EAE6C;IAC1Cc,OAAS,CADiC;IAC9BnB,MAAQ,UADsB;IACVsB,MAAQ;EADE,CAF7CjB;AANU,CAtEDoD,EA+EkC;EAI3CtD,UAAY,gBAJ+B;EAK3CC,UAAY,gBAL+B;EAM3CC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,GACoC;IACjCc,OAAS,CADwB;IACrBnB,MAAQ,YADa;IACCsB,MAAQ;EADT,CADpCjB,EAE6C;IAC1Cc,OAAS,CADiC;IAC9BnB,MAAQ,OADsB;IACbsB,MAAQ;EADK,CAF7CjB;AAN2C,CA/ElCoD,EAwF+B;EAIxCtD,UAAY,cAJ4B;EAKxCC,UAAY,gBAL4B;EAMxCC;IACGc,OAAS,CADZd;IACeL,MAAQ,GADvBK;IAC4BiB,MAAQ;EADpCjB,EANwC;EASxCC;IACGoD,QAAU,YADbpD;IAC2BN,MAAQ,WADnCM;IACgDgB,MAAQ;EADxDhB,GACwD;IACrDoD,QAAU,aAD2C;IAC5B1D,MAAQ,YADoB;IACNsB,MAAQ;EADF,CADxDhB;AATwC,CAxF/BmD,CfAb;AAAA,IemG8DoB;EAAApB;AAAA,EfnG9D;AAAA,IemG8DqB;EClE5D;IACE,IAAMC,KACJnB,UADImB,EACQjB,SADRiB,EACmBhB,OADnBgB,EAC4Bf,WAD5Be,EACyCd,QADzCc,EACmDb,OADnDa,EAEJZ,UAFIY,EAEQT,OAFRS,EAEiBC,OAFjBD,EAEwBX,KAFxBW,EAE+BR,QAF/BQ,EAEyCP,aAFzCO,EAEwDN,SAFxDM,EAGJL,SAHIK,EAGOJ,QAHPI,EAGiBF,cAHjBE,CAAN;IAAA,IAKME,OAA6BC,MAA7BD,CAA6BC,KAA7BD,CAA6BC,EAA7BD,EAAuCF,EAAIrD,GAAJqD,CAAQ;MAAM,SAAGtB,IAAH;IAAGA,CAAjBsB,CAAvCE,CALN;IAOAE,KAAKC,SAALD,GAAiBF,EAAYI,MAAZJ,CACb,UAACvD,CAAD,EAAM4D,CAAN,EAAMA;MAEJ,OADA5D,EAAI4D,EAAOnF,QAAXuB,IAAuB4D,CAAvB5D,EACOA,CAAP;IAAOA,CAHIuD,EAGJvD,EAHIuD,CAAjBE;EA6OJ;;EAAA,OA1PEI,sBAAkBT,CAAlBS,EAAkBT,UAAlBS,EAAkBT;IAAAA,KAAlB;MACE,OAAOK,KAAKK,SAALL,KAAmBA,KAAKK,SAALL,GAAiB,IAAIA,IAAJ,EAApCA,CAAP;IAA+CA,CAD/BL;IAC+BK,cAD/BL;IAC+BK;EAD/BL,CAAlBS,GAuBAT,uCACIV,CADJ,EAEIqB,CAFJ,EAEIA;IAFJ;IAAA,iBAEIA,MAFJ;IAGE,IACMC,MADN;IAAA,IAEMC,MAFN;IAAA,IAGMC,IAHUxB,EAAMxD,IAANwD,CAGMiB,MAHNjB,CAGoC,UAAC1C,CAAD,EAAMd,CAAN,EAAMA;MAQxD,OAPAc,EAAId,EAAKZ,IAAT0B,IAAiBmE,EAAKC,OAALD,CAAajF,CAAbiF,CAAjBnE,EACId,EAAKmF,EAALnF,CAAQoF,UAARpF,CAAmB,aAAnBA,KACF8E,EAAalC,IAAbkC,CAAkBhE,EAAId,EAAKZ,IAAT0B,CAAlBgE,CAFFhE,EAIgB,YAAZd,EAAKmF,EAAO,IACdJ,EAAQnC,IAARmC,CAAajE,EAAId,EAAKZ,IAAT0B,CAAbiE,CALFjE,EAOOA,CAAP;IAAOA,CAXO0C,EAWP1C,EAXO0C,CAAhB;IAAA,IAcI/D,MAdJ;IAAA,IAeM4F,MAfN;IAAA,IAgBIC,MAhBJ;IAAA,IAiBIC,MAjBJ;IAkBiB,QAAbV,CAAa,KACfS,IAAqBf,KAAKiB,mBAALjB,CAAyBM,EAAUpF,MAAnC8E,CAArBe,EACAC,IAAsBhB,KAAKiB,mBAALjB,CAAyBM,EAAUQ,OAAnCd,CAFP;IAIjB,IAAMkB,IAAWd,OAAOe,IAAPf,CAAYK,CAAZL,CAAjB;IA2CA,OA1CAc,EAASE,OAATF,CAAiB;MACf,IAAMzF,IAAOgF,EAAMY,CAANZ,CAAb;MACAhF,EAAKY,UAALZ,CAAgB2F,OAAhB3F,CAAwB;QACf;QACPA,EAAKP,MAALO,CAAY4C,IAAZ5C,CAAiBgF,EAAMxD,CAANwD,CAAjBhF,GACAgF,EAAMxD,CAANwD,EAAgBa,QAAhBb,CAAyBpC,IAAzBoC,CAA8BhF,CAA9BgF,CADAhF;MAC8BA,CAHhCA;IAGgCA,CALlCyF,GAWgD,MAA5Cd,OAAOe,IAAPf,CAAYY,CAAZZ,EAAiChC,MAAW,GAC9C8C,EAASE,OAATF,CAAiB;MACf,IAAMzF,IAAOgF,EAAMY,CAANZ,CAAb;MAC6B,MAAzBhF,EAAK6F,QAAL7F,CAAc2C,MAAW,IAC3B0C,EAAQzC,IAARyC,CAAarF,CAAbqF,CAD2B;IACdrF,CAHjByF,CAD8C,GAQ9Cd,OAAOe,IAAPf,CAAYY,CAAZZ,EAAiCgB,OAAjChB,CAAyC;MAChC;MAAA,IACD3E,IAAOgF,EAAMxD,CAANwD,CADN;MAEK,QAARhF,CAAQ,KACVA,EAAK8F,YAAL9F,GAAoBuF,EAAoBnG,CAApBmG,CAApBvF,EACAqF,EAAQzC,IAARyC,CAAarF,CAAbqF,CAFU;IAEGrF,CALjB2E,CAnBFc,EA6BId,OAAOe,IAAPf,CAAYW,CAAZX,EAAgChC,MAAhCgC,GAAyC,CAAzCA,GACFA,OAAOe,IAAPf,CAAYW,CAAZX,EAAgCgB,OAAhChB,CAAwC;MAC/B;MAAA,IACD3E,IAAOgF,EAAMxD,CAANwD,CADN;MAEHhF,MACFA,EAAK8F,YAAL9F,GAAoBsF,EAAmBlG,CAAnBkG,CAApBtF,EACAP,EAAOmD,IAAPnD,CAAYO,CAAZP,CAFEO;IAEUA,CALhB2E,CADEA,GAUFlF,IAASqF,CAvCXW,EAuCWX;MAGHE,QAHGF;MAGIrF,SAHJqF;MAGYO,UAHZP;MAGqBC,UAHrBD;MAG8BA,eAH9BA;MAG4CD;IAH5CC,CAGX;EAAuDD,CA3FzDF,EA8FQT,kCAAR,UAA4B6B,CAA5B,EAA4BA;IAC1B,OAAOpB,OAAOe,IAAPf,CAAYoB,OAAZpB,EACFF,MADEE,CAC8B,UAACqB,CAAD,EAAOC,CAAP,EAAOA;MAEtC,OADAD,EAAKD,EAAQE,CAARF,EAAc3G,IAAnB4G,IAA2BC,CAA3BD,EACOA,CAAP;IAAOA,CAHNrB,EAGMqB,EAHNrB,CAAP;EAGaqB,CAlGfrB,EAsGQT,sBAAR,UAAgBlE,CAAhB,EAAgBA;IAGd,IAAM0E,IACF9E,gBAAgBI,EAAKmF,EAArBvF,KAA4B2E,KAAKC,SAALD,CAAevE,EAAKmF,EAApBZ,CAA5B3E,IAAgDuF,EADpD;IAEiB,QAAbnF,EAAKkG,IAAQ,KACflG,EAAKkG,IAALlG,GAAKkG,EADU;IAIjB,IAAMC;MACJ/G,MAAMY,EAAKZ,IADP+G;MAEJhB,IAAInF,EAAKmF,EAFLgB;MAGJ3G,UAAUkF,EAAOlF,QAHb2G;MAIJvF,aACKZ,EAAKoG,KAALpG,IAAKoG,EADVxF,EAESE,GAFTF,CAEa;QAAS,SAAMwE,UAANgB,CAAiB,GAAjBA,IAAwBA,EAAMC,MAAND,CAAa,CAAbA,CAAxBA,GAA0CA,CAA1C;MAA0CA,CAFhExF,CAJIuF;MAOJ1G,UAPI0G;MAQJN,YARIM;MASJ/F,eATI+F;MAUJ9E,cAVI8E;MAWJG,UAAUtG,EAAKkG;IAXXC,CAAN;IAyIA,OA3HqB,QAAjBzB,EAAOjF,MAAU,KACnB0G,EAAQ/F,WAAR+F,GACIzB,EAAOjF,MAAPiF,CAAcD,MAAdC,CACI,UAAC5D,CAAD,EAAMyF,CAAN,EAAMA;MAMJ,OALAzF,EAAIyF,EAAMnH,IAAV0B,IAAU1B;QACRsB,MAAM6F,EAAM7F,IADJtB;QAERkB,iBAAiBiG,EAAMhG,KAFfnB;QAGRqB,eAAe8F,EAAM/F;MAHbpB,CAAV0B,EAKOA,CAAP;IAAOA,CAPb4D,EAOa5D,EAPb4D,CAFe,GAaD,QAAhBA,EAAOhF,KAAS,KAClByG,EAAQ9E,UAAR8E,GACIzB,EAAOhF,KAAPgF,CAAaD,MAAbC,CAAiD,UAAC5D,CAAD,EAAMyF,CAAN,EAAMA;MACrD,IAAM7F,IAAO6F,EAAM7F,IAAnB;MAAA,IACIY,SAAQjB,CADZ;;MAEA,QAAQkG,EAAM7F,IAAd;QACE,KAAK,QAAL;UAAK,KAIWL,CAJX,MACHiB,IAAQkF,eACJxG,EAAKkG,IADDM,EACOD,EAAMzD,MADb0D,EACqBD,EAAMtD,YAD3BuD,CADL,KAI0BD,EAAMvC,gBAJhC,KAKD1C,IAAQkF,eACJxG,EAAKkG,IADDM,EACOD,EAAMvC,gBADbwC,EAEJD,EAAMtD,YAFFuD,CALP;UASH;;QACF,KAAK,UAAL;UAAK,KAIWnG,CAJX,MACHiB,IAAQmF,oBACJzG,EAAKkG,IADDO,EACOF,EAAMzD,MADb2D,EACqBF,EAAMtD,YAD3BwD,CADL,KAI0BF,EAAMvC,gBAJhC,KAKD1C,IAAQmF,oBACJzG,EAAKkG,IADDO,EACOF,EAAMvC,gBADbyC,EAEJF,EAAMtD,YAFFwD,CALP;UASH;;QACF,KAAK,QAAL;UAAK,KAIWpG,CAJX,MACHiB,IAAQoF,eACJ1G,EAAKkG,IADDQ,EACOH,EAAMzD,MADb4D,EAEHH,EAAMtD,YAANsD,IAAsB,CAFnBG,CADL,KAI0BH,EAAMvC,gBAJhC,KAKD1C,IAAQoF,eACJ1G,EAAKkG,IADDQ,EACOH,EAAMvC,gBADb0C,EAEJH,EAAMtD,YAFFyD,CALP;UASH;;QACF,KAAK,UAAL;UAAK,KAGWrG,CAHX,MACHiB,IAAQqF,qBACJ3G,EAAKkG,IADDS,EACOJ,EAAMzD,MADb6D,EACqBJ,EAAMtD,YAD3B0D,CADL,KAG0BJ,EAAMvC,gBAHhC,KAID1C,IAAQqF,qBACJ3G,EAAKkG,IADDS,EACOJ,EAAMvC,gBADb2C,EAEJJ,EAAMtD,YAFF0D,CAJP;UAQH;;QACF,KAAK,MAAL;UAAK,KAGWtG,CAHX,MACHiB,IAAQsF,aACJ5G,EAAKkG,IADDU,EACOL,EAAMzD,MADb8D,EACqBL,EAAMtD,YAD3B2D,CADL,KAG0BL,EAAMvC,gBAHhC,KAID1C,IAAQsF,aACJ5G,EAAKkG,IADDU,EACOL,EAAMvC,gBADb4C,EAEJL,EAAMtD,YAFF2D,CAJP;UAQH;;QACF,KAAK,QAAL;UAAK,KAGWvG,CAHX,MACHiB,IAAQuF,kBACJ7G,EAAKkG,IADDW,EACON,EAAMzD,MADb+D,EACqBN,EAAMtD,YAD3B4D,CADL,KAG0BN,EAAMvC,gBAHhC,KAID1C,IAAQuF,kBACJ7G,EAAKkG,IADDW,EACON,EAAMvC,gBADb6C,EAEJN,EAAMtD,YAFF4D,CAJP;UAQH;;QACF,KAAK,OAAL;UAAK,KAGWxG,CAHX,MACHiB,IAAQwF,oBACJ9G,EAAKkG,IADDY,EACOP,EAAMzD,MADbgE,EACqBP,EAAMtD,YAD3B6D,CADL,KAG0BP,EAAMvC,gBAHhC,KAID1C,IAAQwF,oBACJ9G,EAAKkG,IADDY,EACOP,EAAMvC,gBADb8C,EAEJP,EAAMtD,YAFF6D,CAJP;UAQH;;QACF,KAAK,SAAL;UAAK,KAGWzG,CAHX,MACHiB,IAAQyF,yBACJ/G,EAAKkG,IADDa,EACOR,EAAMzD,MADbiE,EACqBR,EAAMtD,YAD3B8D,CADL,KAG0BR,EAAMvC,gBAHhC,KAID1C,IAAQyF,yBACJ/G,EAAKkG,IADDa,EACOR,EAAMvC,gBADb+C,EAEJR,EAAMtD,YAFF8D,CAJP;UAQH;;QACF,KAAK,OAAL;UAAK,KAGW1G,CAHX,MACHiB,IAAQ0F,cACJhH,EAAKkG,IADDc,EACOT,EAAMzD,MADbkE,EACqBT,EAAMtD,YAD3B+D,CADL,KAG0BT,EAAMvC,gBAHhC,KAID1C,IAAQ0F,cACJhH,EAAKkG,IADDc,EACOT,EAAMvC,gBADbgD,EAEJT,EAAMtD,YAFF+D,CAJP;UAQH;;QACF,KAAK,SAAL;UAAK,KAGW3G,CAHX,MACHiB,IAAQ2F,mBACJjH,EAAKkG,IADDe,EACOV,EAAMzD,MADbmE,EACqBV,EAAMtD,YAD3BgE,CADL,KAG0BV,EAAMvC,gBAHhC,KAID1C,IAAQ2F,mBACJjH,EAAKkG,IADDe,EACOV,EAAMvC,gBADbiD,EAEJV,EAAMtD,YAFFgE,CAJP;UAQH;;QACF,KAAK,QAAL;QACA,KAAK,SAAL;UACE;;QACF;UACE,MAAM,IAAIC,KAAJ,CACF,6BAA2BX,EAAM7F,IAAjC,GAAiCA,WAAjC,GAAiDV,EAAKmF,EADpD,CAAN;MAlGJ;;MAsGA,OADArE,EAAIyF,EAAMnH,IAAV0B,IAAU1B;QAASkC,QAATlC;QAAgBsB;MAAhBtB,CAAV0B,EACOA,CAAP;IAAOA,CAzGT4D,EAyGS5D,EAzGT4D,CAFc,CAbC,EA2HdyB,CAAP;EAAOA,CAxPTxB,EAwPSwB,CAEX;AAFWA,CDjLmD,EfnG9D;;AgBoRWA,SAIKgB,YAJLhB,CAIkBiB,CAJlBjB,EAIkBiB;EAC3B,IAAMC,IAASC,MAAMD,MAArB;EACA,SAA2B,CAA3B,KAAWA,EAAOE,IAAlB,EACE,OAAOF,EAAOE,IAAPF,CAAYD,CAAZC,CAAP;EACK,IAAsB,sBAAXG,MAAX,EACL,OAAO,IAAIA,MAAJ,CAAWJ,CAAX,EAAiB,QAAjB,EAA2BK,QAA3B,EAAP;EAEA,MAAM,IAAIP,KAAJ,CACF,kFADE,CAAN;AAMJ;;AAAA,SAAgBQ,gBAAhB,CAAiCC,CAAjC,EAA+CC,CAA/C,EAA+CA;EAC7C,IAAMtG,IACFN,MAAM6G,OAAN7G,CAAc2G,CAAd3G,IAAmB8G,OAAOC,YAAPD,CAAoBE,KAApBF,CAA0B,IAA1BA,EAAgCH,CAAhCG,CAAnB9G,GAAwDmG,aAAaQ,CAAbR,CAD5D;EAEA,OAAOS,IAAWtG,CAAXsG,GAAmBtG,EAAM2G,WAAN3G,EAA1B;AAGF;;AAAA,SAAgBkF,cAAhB,CACI9G,CADJ,EACmDN,CADnD,EACiE8I,CADjE,EAEIN,CAFJ,EAEIA;EAAAA;EACF,IAAMrB,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAa,QAAT6G,CAAS,GACJmB,iBAAiBnB,EAAMoB,CAAvBD,EAA0BE,CAA1BF,CADI,GAGNQ,CAHP;AAMF;;AAAA,SAAgBtB,YAAhB,CACIlH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAO6G,IAAQA,EAAM4B,CAAd5B,GAAkB2B,CAAzB;AAGF;;AAAA,SAAgBxB,cAAhB,CACIhH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,KAAMN,EAApB;EAAA,IACMkC,IACY,QAAdiF,EAAS7D,CAAK,GAAO6D,EAAS7D,CAAhB,GAAmC,QAAd6D,EAAS6B,CAAK,GAAO7B,EAAS6B,CAAhB,GAAoBF,CAFzE;EAGA,OAAyB,mBAAV5G,CAAU,GAAYA,CAAZ,GAAoB+G,SAAS/G,CAAT+G,EAAgB,EAAhBA,CAA7C;AAGF;;AAAA,SAAgBC,eAAhB,CAAgChH,CAAhC,EAAgCA;EAK9B,QAJuB,yBAErBA,IAAQiH,SAAoBjH,CAApBiH,CAFa,GAIfjH,CAAR;IACE,KAAKiH,SAAoBC,QAAzB;MACE,OAAO,SAAP;;IACF,KAAKD,SAAoBE,QAAzB;IACA,KAAKF,SAAoBG,QAAzB;IACA,KAAKH,SAAoBI,OAAzB;IACA,KAAKJ,SAAoBK,QAAzB;MACE,OAAO,OAAP;;IACF,KAAKL,SAAoBM,OAAzB;MACE,OAAO,MAAP;;IACF,KAAKN,SAAoBO,SAAzB;MACE,OAAO,SAAP;;IACF,KAAKP,SAAoBQ,SAAzB;MACE,OAAO,QAAP;;IACF;MAGE,OAAO,IAAP;EAjBJ;AAqBF;;AAAA,SAAgB/B,aAAhB,CACItH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAM7F,IAAf6F,GACK+B,gBAAgB/B,EAAM7F,IAAtB4H,CADL/B,GAGG2B,CAHP;AAMF;;AAAA,SAAgBjB,kBAAhB,CACIvH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAMyC,IAAfzC,IAAuBA,EAAMyC,IAANzC,CAAW7F,IAAlC6F,GACKA,EAAMyC,IAANzC,CAAW7F,IAAX6F,CAAgBzF,GAAhByF,CAAoB;IAAK,uBAAgB0C,CAAhBX;EAAgBW,CAAzC1C,CADLA,GAGG2B,CAHP;AAMF;;AAAA,SAAgBgB,qBAAhB,CAAsCC,CAAtC,EAAsCA;EAEpC,KAAIA,EAAMC,WAAV,EAGA,OAAiB,QAAbD,EAAME,GAAO,GACRF,EAAME,GAANF,CAAUrI,GAAVqI,CACH;IACI,OAAqB,mBAAbE,EAAI7G,IAAS,GAAY6G,EAAI7G,IAAhB,GAAuB6F,SAASgB,EAAI7G,IAAb6F,EAAmB,EAAnBA,CAA5C;EAA+D,CAFhEc,CADQ,GAGwD,EAHzE;AAQF;;AAAA,SAAgBrC,mBAAhB,CACIpH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAM4C,KAAf5C,GACK2C,sBAAsB3C,EAAM4C,KAA5BD,CADL3C,GAGG2B,CAHP;AAMF;;AAAA,SAAgBvB,oBAAhB,CACIjH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,MACOA,EAAMyC,IAANzC,CAAW6B,CAAX7B,IAAgBA,EAAMyC,IAANzC,CAAW6B,CAAX7B,CAAa5D,MAA7B4D,GAAsCA,EAAMyC,IAANzC,CAAW6B,CAAjD7B,GACsCA,EAAMyC,IAANzC,CAAW7D,CAFxD6D,KAEwD7D,EAFxD6D,EAIGzF,GAJHyF,CAIO;IAAK,OAAc,mBAAN0C,CAAM,GAAYA,CAAZ,GAAgBZ,SAASY,CAATZ,EAAY,EAAZA,CAA9B;EAA0C,CAJtD9B,IAMG2B,CANP;AASF;;AAAA,SAAgBzB,mBAAhB,CACI/G,CADJ,EACmDN,CADnD,EACiE8I,CADjE,EAEIN,CAFJ,EAEIA;EAAAA;EACF,IAAMrB,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAMyC,IAAfzC,IAAuBA,EAAMyC,IAANzC,CAAWoB,CAAlCpB,GACKA,EAAMyC,IAANzC,CAAWoB,CAAXpB,CAAazF,GAAbyF,CAAiB,UAAC0C,CAAD,EAACA;IACvB,OAAOvB,iBAAiBuB,CAAjBvB,EAAoBE,CAApBF,CAAP;EAA2BE,CADtBrB,CADLA,GAKG2B,CALP;AAQF;;AAAA,SAAgBnB,wBAAhB,CACIrH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAMyC,IAAfzC,IAAuBA,EAAMyC,IAANzC,CAAW4C,KAAlC5C,GACKA,EAAMyC,IAANzC,CAAW4C,KAAX5C,CAAiBzF,GAAjByF,CAAqB,UAAC0C,CAAD,EAACA;IAC3B,OAAOC,sBAAsBD,CAAtBC,CAAP;EAA6BD,CADxB1C,CADLA,GAKG2B,CALP;AAQF;;AAAA,SAAgBrB,iBAAhB,CACInH,CADJ,EACmDN,CADnD,EAEI8I,CAFJ,EAEIA;EACF,IAAM3B,IAAQ7G,EAAMN,CAANM,CAAd;EACA,OAAI6G,KAASA,EAAMyC,IAAfzC,IAAuBA,EAAMyC,IAANzC,CAAW4B,CAAlC5B,GACKA,EAAMyC,IAANzC,CAAW4B,CADhB5B,GAGG2B,CAHP;AC1aF;;AAAA;EAGE,WACYlI,CADZ,EACgCC,CADhC,EAEYC,CAFZ,EAEYA;IAFZ;IACYqE,eAAoBA,kBAApBA,EACAA,gBADAA,EAHIA,gBAGJA,EAFIA,eAEJA,EAEVA,KAAK9E,MAAL8E,GAAcvE,EAAKY,UAALZ,CAAgBc,GAAhBd,CAAoB;MAAQ,SAAKsJ,QAALrE,CAAc7F,CAAd6F;IAAc7F,CAA1CY,CAFJuE,EAGW,QAAjBvE,EAAKsG,QAAY,KACnB/B,KAAK7E,KAAL6E,GAAaI,OAAOe,IAAPf,CAAY3E,EAAKsG,QAAjB3B,EACKF,MADLE,CACY,UAACjF,CAAD,EAAoCkG,CAApC,EAAoCA;MAE1C,OADAlG,EAAMkG,CAANlG,IAAauF,EAAKsE,OAALtE,CAAaW,CAAbX,CAAbvF,EACOA,CAAP;IAAOA,CAHbiF,EAGajF,EAHbiF,CADM,CAHXJ;EAsEd;;EAAA,OAtDUiF,uBAAR,UAAiBpK,CAAjB,EAAiBA;IACf,OAAOuB,UAAUvB,CAAVuB,EAAgB4D,KAAKtE,SAArBU,EAAgC4D,KAAKrE,OAArCS,CAAP;EAA4CT,CADtCsJ,EAQAA,sBAAR,UAAgBpK,CAAhB,EAA8B6D,CAA9B,EAA8BA;IAC5B,IAAM3B,IAAQiD,KAAKvE,IAALuE,CAAU+B,QAAV/B,CAAmBnF,CAAnBmF,CAAd;IACA,IAAoB,QAAhBjD,EAAMmI,MAAV,EACE,OAAO9I,UAAUvB,CAAVuB,EAAgB4D,KAAKtE,SAArBU,EAAgC4D,KAAKrE,OAArCS,CAAP;IAEF,IAAe,QAAXW,EAAMoB,CAAK,IAAmB,QAAXpB,EAAM8G,CAA7B,EACE,OAAO1B,eAAenC,KAAKvE,IAALuE,CAAU+B,QAAzBI,EAAmCtH,CAAnCsH,EAAyCzD,CAAzCyD,CAAP;IAEF,IAAe,QAAXpF,EAAMqG,CAAV,EACE,OAAOnB,eAAejC,KAAKvE,IAALuE,CAAU+B,QAAzBE,EAAmCpH,CAAnCoH,EAAyCvD,CAAzCuD,CAAP;IAEF,IAAe,QAAXlF,EAAM6G,CAAV,EACE,OAAOvB,aAAarC,KAAKvE,IAALuE,CAAU+B,QAAvBM,EAAiCxH,CAAjCwH,EAAuC3D,CAAvC2D,CAAP;IAEF,IAAmB,QAAftF,EAAM6H,KAAV,EACE,OAAOrC,oBACHvC,KAAKvE,IAALuE,CAAU+B,QADPQ,EACiB1H,CADjB0H,EACuB7D,CADvB6D,CAAP;IAGF,IAAkB,QAAdxF,EAAMZ,IAAV,EACE,OAAOsG,cAAczC,KAAKvE,IAALuE,CAAU+B,QAAxBU,EAAkC5H,CAAlC4H,EAAwC/D,CAAxC+D,CAAP;;IAEF,IAAkB,QAAd1F,EAAM0H,IAAV,EAAwB;MACtB,IAAoB,QAAhB1H,EAAM0H,IAAN1H,CAAWoB,CAAK,IAAwB,QAAhBpB,EAAM0H,IAAN1H,CAAW8G,CAAvC,EACE,OAAOzB,qBACHpC,KAAKvE,IAALuE,CAAU+B,QADPK,EACiBvH,CADjBuH,EACuB1D,CADvB0D,CAAP;MAGF,IAAoB,QAAhBrF,EAAM0H,IAAN1H,CAAWqG,CAAf,EACE,OAAOlB,oBACHlC,KAAKvE,IAALuE,CAAU+B,QADPG,EACiBrH,CADjBqH,EACuBxD,CADvBwD,CAAP;MAGF,IAAwB,QAApBnF,EAAM0H,IAAN1H,CAAW6H,KAAf,EACE,OAAOpC,yBACHxC,KAAKvE,IAALuE,CAAU+B,QADPS,EACiB3H,CADjB2H,EACuB9D,CADvB8D,CAAP;MAGF,IAAoB,QAAhBzF,EAAM0H,IAAN1H,CAAW6G,CAAf,EACE,OAAOtB,kBACHtC,KAAKvE,IAALuE,CAAU+B,QADPO,EACiBzH,CADjByH,EACuB5D,CADvB4D,CAAP;MAGF,IAAuB,QAAnBvF,EAAM0H,IAAN1H,CAAWZ,IAAf,EACE,OAAOuG,mBACH1C,KAAKvE,IAALuE,CAAU+B,QADPW,EACiB7H,CADjB6H,EACuBhE,CADvBgE,CAAP;IAKJ;;IAAA,OAAOhE,CAAP;EAAOA,CApDDuG,EAoDCvG,CAEX;AAFWA,CAxEX;AAAA,ICHayG,YAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,SAAL;IACA,KAAK,OAAL;IACA,KAAK,KAAL;MACE,QAAQwE,IACH7J,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADG6J,EAEJ7J,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFI6J,CAAR;;IAIF,KAAK,MAAL;MACE,QAAQC,KACJ9J,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADI8J,CAAR;;IAGF,KAAK,UAAL;IACA,KAAK,KAAL;MACE,QAAQC,IACJ/J,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+J,EAEJ/J,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFI+J,CAAR;;IAGF,KAAK,KAAL;MACE,QAAQC,IACJhK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgK,EAEJhK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIgK,CAAR;;IAGF,KAAK,SAAL;IACA,KAAK,KAAL;MACE,QAAQC,IACJjK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiK,EAEJjK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIiK,CAAR;;IAIF,KAAK,UAAL;MACE,QAAQC,SACJlK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkK,EAEJlK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIkK,CAAR;;IAIF,KAAK,UAAL;MACE,QAAQC,SACJnK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADImK,EAEJnK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFImK,CAAR;;IAIF,KAAK,KAAL;MACE,QAAQC,IACJpK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIoK,EAEJpK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIoK,CAAR;;IAIF,KAAK,SAAL;MACE,QAAQC,QACJrK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqK,EAEJrK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIqK,CAAR;;IAIF,KAAK,SAAL;MACE,QAAQC,QACJtK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIsK,EAEJtK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIsK,CAAR;;IAIF,KAAK,KAAL;MACE,QAAQC,IACJvK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuK,EAEJvK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIuK,CAAR;;IAIF,KAAK,mBAAL;MACE,QAAQC,kBACJxK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIwK,EAEJxK,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIwK,CAAR;;IAIF;MACE,MAAMC,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA/DJ;AA+DsCpF,CDhExC;AAAA,IEHauE,cAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,KAAL;IACA,KAAK,YAAL;MACE,QAAQqF,IACJ1K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0K,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJ3K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2K,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJ5K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI4K,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJ7K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6K,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJ9K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI8K,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJ/K,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+K,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJhL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgL,EAEJhL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIgL,CAAR;;IAGF,KAAK,OAAL;MACE,QAAQC,MACJjL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiL,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJlL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkL,CAAR;;IAEF,KAAK,SAAL;MACE,QAAQC,QACJnL,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CADImL,EAEJnL,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFImL,CAAR;;IAGF,KAAK,KAAL;MACE,QAAQC,IACJpL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIoL,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJrL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqL,CAAR;;IAEF,KAAK,KAAL;MACE,QAAQC,IACJtL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIsL,CAAR;;IAEF,KAAK,KAAL;MACE,QAAQC,IACJvL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuL,CAAR;;IAEF,KAAK,KAAL;MACE,QAAQC,IACJxL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIwL,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJzL,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyL,CAAR;;IAGF,KAAK,OAAL;MACE,QAAQC,MACJ1L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0L,CAAR;;IAEF,KAAK,KAAL;MACE,QAAQC,IACJ3L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2L,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJ5L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI4L,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJ7L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6L,CAAR;;IAGF,KAAK,KAAL;MACE,QAAQC,IACJ9L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI8L,CAAR;;IAEF,KAAK,YAAL;MACE,QAAQC,WACJ/L,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+L,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJhM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgM,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJjM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiM,CAAR;;IAEF,KAAK,OAAL;MACE,QAAQC,MACJlM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkM,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJnM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADImM,CAAR;;IAEF,KAAK,SAAL;MACE,QAAQC,QACJpM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIoM,CAAR;;IAEF,KAAK,KAAL;MACE,QAAQC,IACJrM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqM,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJtM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIsM,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJvM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuM,CAAR;;IAGF,KAAK,UAAL;MACE,QAAQC,SACJxM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIwM,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJzM,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyM,CAAR;;IAGF,KAAK,QAAL;MACE,QAAQC,OACJ1M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0M,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJ3M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2M,CAAR;;IAGF,KAAK,KAAL;MACE,QAAQC,IACJ5M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI4M,CAAR;;IAEF,KAAK,OAAL;IACA,KAAK,aAAL;MACE,QAAQC,YACJ7M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6M,EAEJ7M,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAFI6M,EAGJ7M,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAHI6M,CAAR;;IAIF,KAAK,OAAL;MACE,QAAQC,MAAUjM,UAAUX,EAAKY,UAALZ,CAAgB,CAAhBA,CAAVW,EAA8BV,CAA9BU,EAAyCT,CAAzCS,CAAViM,CAAR;;IACF,KAAK,MAAL;MACE,QAAQC,KACJ/M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+M,EAEJ/M,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFI+M,CAAR;;IAGF,KAAK,WAAL;MACE,QAAQC,UACJhN,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgN,EAEJhN,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIgN,CAAR;;IAGF,KAAK,OAAL;MACE,QAAQC,MACJjN,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiN,EAEJjN,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIiN,CAAR;;IAGF;MACE,MAAMxC,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA7IJ;AA6IsCpF,CF9IxC;AAAA,IE8IwCA;ECxItC,WACoB/F,CADpB,EACkD4N,CADlD,EAEYC,CAFZ,EAEqCC,CAFrC,EAGoBC,CAHpB,EAIoBC,CAJpB,EAKoBC,CALpB,EAKoBA;IAJA9I,eAA8BA,cAA9BA,EACRA,gBADQA,EACiBA,qBADjBA,EAEAA,+BAFAA,EAGAA,oBAHAA,EAIAA,uBAJAA,EAJZA,iBAIYA,EAHZA,gBAAU,CAGEA,EAKlBA,KAAK+I,EAAL/I,GAAUgJ,EAAYC,MAAZD,EALQhJ;EAqStB;;EAAA,OA7REI,sBAAI4I,WAAJ5I,EAAI4I,QAAJ5I,EAAI4I;IAAAA,KAAJ;MACE,OAAOhJ,KAAKkJ,OAAZ;IAAYA,CADVF;IACUE,cADVF;IACUE;EADVF,CAAJ5I,GAOA4I;IACEhJ,KAAKmJ,OAALnJ,CAAaoB,OAAbpB,CAAqB;MAAU,SAAOkF,MAAPA,CAAckE,OAAdlE;IAAckE,CAA7CpJ,GACAA,KAAKmJ,OAALnJ,GAAKmJ,EADLnJ,EAEAA,KAAKkJ,OAALlJ,GAAKkJ,CAAU,CAFflJ;EAEe,CAVjBI,EAaA4I;IACE,OAAOhJ,KAAKmJ,OAALnJ,CAAa5B,MAApB;EAAoBA,CAdtBgC,EAqBA4I,6BAAK9L,CAAL,EAAKA;IACH,IAAI8C,KAAKkJ,OAAT,EACE,MAAM,IAAIvG,KAAJ,CAAU,iBAAe3C,KAAKnF,IAApB,GAAoBA,2BAA9B,CAAN;IAGF,IAAIqC,IAAQ,CAARA,IAAaA,KAAS8C,KAAKmJ,OAALnJ,CAAa5B,MAAvC,EACE,MAAM,IAAIuE,KAAJ,CAAU,8BAA4BzF,CAA5B,GAA4BA,uBAA5B,GACZ8C,KAAKmJ,OAALnJ,CAAa5B,MADX,CAAN;IAIF,IAAMiL,IAAkBrJ,KAAKmJ,OAALnJ,CAAa9C,CAAb8C,CAAxB;IACA,IAAIqJ,EAAgBC,OAApB,EACE,MAAM,IAAI3G,KAAJ,CACF,iBAAe3C,KAAKnF,IAApB,GAAoBA,yBAApB,GACIqC,CADJ,GACIA,sGAFF,CAAN;IAWF,OALI8C,KAAK8I,cAAL9I,KACFqJ,EAAgBC,OAAhBD,GAAgBC,CAAU,CADxBtJ,GAIJqJ,EAAgBE,IAAhBF,GAAgBE,CAAO,CAJnBvJ,EAKGqJ,EAAgBnE,MAAvB;EAAuBA,CA5CzB9E,EAkDA4I,iCAASQ,CAAT,EAASA;IAAT;IACE,OAAOA,EAAQjN,GAARiN,CAAY;MAAS,SAAKD,IAAL7I,CAAUxD,CAAVwD;IAAUxD,CAA/BsM,CAAP;EAAsCtM,CAnDxCkD,EA2DA4I,8BAAM9L,CAAN,EAAqBgI,CAArB,EAAqBA;IACnB,IAAIlF,KAAKkJ,OAAT,EACE,MAAM,IAAIvG,KAAJ,CAAU,iBAAe3C,KAAKnF,IAApB,GAAoBA,2BAA9B,CAAN;IAGF,IAAIqC,IAAQ,CAARA,IAAQ,CAAM8C,KAAK6I,WAAX,IAA0B3L,KAAS8C,KAAK0I,OAApD,EACE,MAAM,IAAI/F,KAAJ,CAAU,6BACZzF,CADY,GACZA,6CADY,GACuC8C,KAAK0I,OADtD,CAAN;IAIF,IAAMe,IAAIzJ,KAAKmJ,OAALnJ,CAAa9C,CAAb8C,KAAa9C,EAAvB;IAEA,IAAIgI,EAAOuD,KAAPvD,KAAiBlF,KAAKyI,KAA1B,EACE,MAAM,IAAI9F,KAAJ,CAAU,iBACZ3C,KAAKnF,IADO,GACPA,yCADO,GACuCqC,CADvC,GACuCA,0CADvC,GAGZgI,EAAOuD,KAHK,GAGLA,6BAHK,GAG8BzI,KAAKyI,KAHnC,GAGmCA,GAH7C,CAAN;IAiBF,IAVoB,MAAhBzI,KAAK/B,IAAL+B,EAAgB,IACM,QAArBA,KAAK2I,YAAgB,IAAqC,MAA7B3I,KAAK2I,YAAL3I,CAAkB5B,MADhC,KAElB4B,KAAK2I,YAAL3I,GAAoBkF,EAAON,KAFT,GAKpB5E,KAAK0J,mCAAL1J,CACIA,KAAK2I,YADT3I,EACuBkF,EAAON,KAD9B5E,EAEI,iBAAeA,KAAKnF,IAApB,GAAoBA,yCAApB,GACIqC,CADJ,GACIA,GAHR8C,CALoB,EAUhByJ,KAAKA,EAAEF,IAAX,EACE,MAAM,IAAI5G,KAAJ,CACF,iBAAe3C,KAAKnF,IAApB,GAAoBA,yCAApB,GACIqC,CADJ,GACIA,qCAFF,CAAN;IAKF,IAAIuM,KAAKA,EAAEE,OAAX,EACE,MAAM,IAAIhH,KAAJ,CACF,iBAAe3C,KAAKnF,IAApB,GAAoBA,yCAApB,GACIqC,CADJ,GACIA,wCAFF,CAAN;IAKFuM,EAAEvE,MAAFuE,GAAWvE,CAAXuE,EACAA,EAAEE,OAAFF,GAAEE,CAAU,CADZF,EAGAzJ,KAAKmJ,OAALnJ,CAAa9C,CAAb8C,IAAsByJ,CAHtBA;EAGsBA,CAxGxBrJ,EA8GA4I,kCAAUQ,CAAV,EAA6BL,CAA7B,EAA6BA;IAA7B;IACE,IAAIK,EAAQpL,MAARoL,KAAmBL,EAAQ/K,MAA/B,EACE,MAAM,IAAIuE,KAAJ,CACF,iBAAe3C,KAAKnF,IAApB,GAAoBA,6DAApB,GAEI2O,EAAQpL,MAFZ,GAEYA,oCAFZ,GAGI+K,EAAQ/K,MAHZ,GAGYA,GAJV,CAAN;IAOFoL,EAAQpI,OAARoI,CAAgB,UAACrL,CAAD,EAAIjB,CAAJ,EAAIA;MAAU,SAAK0M,KAALlJ,CAAWvC,CAAXuC,EAAcyI,EAAQjM,CAARiM,CAAdzI;IAAsBxD,CAApDsM;EAAoDtM,CAvHtDkD,EAkIA4I,+BAAOQ,CAAP,EAA2Bf,CAA3B,EAA2BA;IACzB,IAAMA,KAASA,MAAUzI,KAAKyI,KAA9B,EACE,MAAM,IAAI9F,KAAJ,CAAU,0BACZ3C,KAAKyI,KADO,GACPA,8BADO,GAC6BA,CADvC,CAAN;;IAIF,KAAKe,CAAL,EAAc;MACZA;;MACA,KAAK,IAAIrL,IAAI,CAAb,EAAgBA,IAAI6B,KAAK/B,IAAL+B,EAApB,EAAiC7B,GAAjC,EACEqL,EAAQnL,IAARmL,CAAarL,CAAbqL;IAIJ;;IAAA,IAAuB,MAAnBA,EAAQpL,MAAZ,EACE,OAAO8G,YAAY,CAAZA,EAAenF,MAAfmF,CAAsBlF,KAAK2I,YAA3BzD,EAAP;IAKF,IAAMiE,IAAUnJ,KAAK6J,QAAL7J,CAAcwJ,CAAdxJ,CAAhB;IAKA,OAHAA,KAAK0J,mCAAL1J,CACIA,KAAK2I,YADT3I,EACuBmJ,EAAQ,CAARA,EAAWvE,KADlC5E,EACyC,8BADzCA,GAGO8J,MAAMX,CAANW,EAAe,CAAfA,CAAP;EAAsB,CA1JxB1J,EAgKA4I,+BAAOP,CAAP,EAAOA;IACL,IAAMA,KAASA,MAAUzI,KAAKyI,KAA9B,EACE,MAAM,IAAI9F,KAAJ,CAAU,0BACZ3C,KAAKyI,KADO,GACPA,8BADO,GAC6BA,CADvC,CAAN;IAIF,IAAoB,MAAhBzI,KAAK/B,IAAL+B,EAAJ,EACE,OAAOkF,YAAY,CAAZA,EAAenF,MAAfmF,CAAsBlF,KAAK2I,YAA3BzD,EAAP;;IAIF,KADA,IAAMsE,MAAN,EACSrL,IAAI,CAAb,EAAgBA,IAAI6B,KAAK/B,IAAL+B,EAApB,EAAiC7B,GAAjC,EACEqL,EAAQnL,IAARmL,CAAarL,CAAbqL;;IAGF,IAAML,IAAUnJ,KAAK6J,QAAL7J,CAAcwJ,CAAdxJ,CAAhB;IAOA,OALAA,KAAK0J,mCAAL1J,CACIA,KAAK2I,YADT3I,EACuBmJ,EAAQ,CAARA,EAAWvE,KADlC5E,EAEI,qDACIA,KAAK2I,YADT,GACSA,2BADT,GACiDQ,EAAQ,CAARA,EAAWvE,KAD5D,GAC4DA,GAHhE5E,GAKOD,OAAOoJ,CAAPpJ,EAAgB,CAAhBA,CAAP;EAAuB,CAtLzBK,EA+LA4I,gCAAQQ,CAAR,EAA2BtE,CAA3B,EAA2BA;IACzB,IAAIA,EAAOuD,KAAPvD,KAAiBlF,KAAKyI,KAA1B,EACE,MAAM,IAAI9F,KAAJ,CAAU,0BACZ3C,KAAKyI,KADO,GACPA,wBADO,GACuBvD,EAAOuD,KADxC,CAAN;IAIF,IAAIe,EAAQpL,MAARoL,KAAmBtE,EAAON,KAAPM,CAAa,CAAbA,CAAvB,EACE,MAAM,IAAIvC,KAAJ,CAAU,wDACZ6G,EAAQpL,MADI,GACJA,OADI,GACU8G,EAAON,KAAPM,CAAa,CAAbA,CADpB,CAAN;IAIF,IAAM6E,IAAWC,KAAKC,GAALD,CAAKC,KAALD,OAAYR,CAAZQ,CAAjB;IAEA,KAAKhK,KAAK6I,WAAV,IAAyBkB,KAAY/J,KAAK0I,OAA1C,EACE,MAAM,IAAI/F,KAAJ,CACF,qCAAmCoH,CAAnC,GAAmCA,QAAnC,GAAoD/J,KAAK0I,OAAzD,GAAyDA,GADvD,CAAN;IAIF1I,KAAKkK,SAALlK,CAAewJ,CAAfxJ,EAAwBmK,QAAQjF,CAARiF,EAAgB,CAAhBA,CAAxBnK;EAAwC,CAjN1CI,EA0NA4I,8BAAM5K,CAAN,EAAwB8G,CAAxB,EAAwBA;IAAxB;IACE,IAAIA,EAAOuD,KAAPvD,KAAiBlF,KAAKyI,KAA1B,EACE,MAAM,IAAI9F,KAAJ,CAAU,0BACZ3C,KAAKyI,KADO,GACPA,wBADO,GACuBvD,EAAOuD,KADxC,CAAN;IAGF,IAAI2B,IAAc,CAAlB;IAAA,IACMC,IAAoBjM,EAAO7B,GAAP6B,CAAW;MAEnC,OADAgM,KAAeE,CACf;IADeA,CADSlM,CAD1B;IAMA,IAAIgM,MAAgBlF,EAAON,KAAPM,CAAa,CAAbA,CAApB,EACE,MAAM,IAAIvC,KAAJ,CAAU,uGAEZyH,CAFY,GAEZA,2BAFY,GAE2BlF,EAAON,KAF5C,CAAN;IAKF,KAAK5E,KAAK6I,WAAV,IAAyBzK,EAAOA,MAAPA,KAAkB4B,KAAK0I,OAAhD,EACE,MAAM,IAAI/F,KAAJ,CACF,6DACI3C,KAAK0I,OADT,GACSA,OADT,GACwBtK,EAAOA,MAD/B,GAC+BA,gEAF7B,CAAN;IAMF,IAAMmM,IAAgC,MAAhBH,CAAgB,GAAI,CAAJ,GAAQlF,EAAOjH,IAAPiH,GAAckF,CAA5D;IAAA,IACMjB,MADN;IAEAqB,KAAK;MACHtF,IAASA,EAAOuF,OAAPvF,CAAOuF,CAAS,CAATA,EAAYL,CAAZK,EAAyBF,CAAzBE,CAAPvF,CAATA;;MACA,KAAK,IAAI/G,IAAI,CAAb,EAAgBA,IAAIC,EAAOA,MAA3B,EAA2BA,EAAUD,CAArC,EAAwC;QACtC,IACMuM,KAAW,CAAXA,EADwB,MAANvM,CAAM,GAAK,CAAL,GAASkM,EAAkBlM,IAAI,CAAtBkM,CACjCK,EAA8B,CAA9BA,CADN;QAAA,IAEMC,KAAS,CAATA,EAAYvM,EAAOD,CAAPC,CAAZuM,EAAuBJ,CAAvBI,CAFN;QAGAxB,EAAQhL,CAARgL,IAAa7M,MAAM4I,CAAN5I,EAAcoO,CAAdpO,EAAuBqO,CAAvBrO,EAA8BmO,OAA9BnO,CAAsCoE,EAAKiI,YAA3CrM,CAAb6M;MAEF;;MAAA,OAAOA,CAAP;IAAOA,CARTqB;;IAWA,KADA,IAAMhB,MAAN,EACSrL,IAAI,CAAb,EAAgBA,IAAIC,EAAOA,MAA3B,EAAmCD,GAAnC,EACEqL,EAAQrL,CAARqL,IAAarL,CAAbqL;;IAEFxJ,KAAKkK,SAALlK,CAAewJ,CAAfxJ,EAAwBmJ,CAAxBnJ;EAAwBmJ,CAlQ1B/I,EA0QQ4I,kDAAR,UACI4B,CADJ,EACsBC,CADtB,EACwCC,CADxC,EACwCA;IAAAA,0BACtCC,KAAKC,MAALD,CACI/K,KAAKiL,6BAALjL,CAAmC4K,CAAnC5K,EAA2C6K,CAA3C7K,CADJ+K,EAEI;MACI,WAAqB,UAArBD,GAAgCF,CAAhCE,GAAgCF,OAAhCE,GAA8CD,CAA9CC,GAA8CD,aAA9C;IAA8CA,CAHtDE,CADsCD;EAIgBD,CA/QxDzK,EAkRQ4I,4CAAR,UAAsCkC,CAAtC,EAAoDC,CAApD,EAAoDA;IAClD,IAAID,EAAG9M,MAAH8M,KAAcC,EAAG/M,MAArB,EACE,QAAO,CAAP;;IAEF,KAAK,IAAID,IAAI,CAAb,EAAgBA,IAAI+M,EAAG9M,MAAvB,EAA+BD,GAA/B,EACE,KAAe,CAAf,KAAI+M,EAAG/M,CAAH+M,CAAJ,IAAO/M,CAAwB,CAAxBA,KAAagN,EAAGhN,CAAHgN,CAApB,IAAoCD,EAAG/M,CAAH+M,MAAUC,EAAGhN,CAAHgN,CAA9C,EACE,QAAO,CAAP;;IAGJ,QAAO,CAAP;EAAO,CA3RT/K,EAbe4I,WAAS,CAaxB5I,EAbwBgL,CA0S1B;AA1S0B,CD4IcxK,EF9IxC;AAAA,IGE0BF,cHF1B;AAAA,IIDayE,cAAqC,UAC9C1J,CAD8C,EAClCC,CADkC,EAE9CC,CAF8C,EAE9CA;EAAAA;IAAAA;;IAAAA;MAAAA;QAAAA;UAAAA,QACMF,EAAKmF,EADXjF;YACWiF,KACN,UADMA;cACN;;YAAA,KAIA,QAJA;cAIA;;YAAA,KASA,OATA;cASA;;YAAA,KAMA,OANA;cAMA;;YAAA,KAQA,MARA;cAQA;;YAAA,KAMA,eANA;cAMA;;YAAA,KAMA,eANA;cAMA;;YAAA,KAoBA,oBApBA;cAoBA;;YAAA,KAUA,mBAVA;cAUA;;YAAA,KAQA,qBARA;cAQA;;YAAA,KAUA,sBAVA;cAUA;;YAAA,KAWA,qBAXA;cAWA;;YAAA,KAQA,oBARA;cAQA;;YAAA,KAWA,mBAXA;cAWA;;YAAA,KAMA,oBANA;cAMA;UA7HLjF;;UA6HK;;QAAA;UA1HH,YACGJ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,EAA+D8P,KAA/D9P,EADH;;QACkE8P;UAQ1D,OALFC,IACF/P,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CADE+P,EAEAC,IACFhQ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAHE+P,EAGqC3P,IAE7B2P,EAAK9O,IAAL8O,EAF6B3P,CAEnC;;QAAWa;UAAnB,WAAQgP,SAAmB,CAAnBA,IAAmB,MAAM1P,CAAN,EAAiByP,EAAKF,KAALE,EAAjB,CAAnBC,GAAyCH,CAChBE,EAAKF,KAALE,EADgBF,EACXA,KAASvP,CADEuP,CAAjD;;QAC+CvP;UAK/C,YAFM4B,IAAYjC,EAAKY,UAALZ,CAAgB4B,IAAhB5B,CACd;YAAQ,YAAwCK,CAAxC,eAAUjB,CAAVuB,EAAgBV,CAAhBU,EAA2BT,CAA3BS;UAA2BT,CADrBF,CAElB,IADuCE,CACnBS,UAAUsB,CAAVtB,EAAqBV,CAArBU,EAAgCT,CAAhCS,EAAyCiP,KAAzCjP,EADmBT,CACvC,GAA6D0P,KAC1CvP,CADnB;;QACmBA;UAQnB,OALM2P,IACFlQ,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CADEkQ,EAEAjP,IACFjB,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHEkQ,EAIN9P,EAAQ+P,UAAR/P,CAAmB8P,CAAnB9P,CAJM8P,EAIaA,KACXjP,EAAK6O,KAAL7O,EADWiP,EACnB;;QAAaJ;UAMb,OAHMnG,IACF3J,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADE2J,EAENvJ,EAAQgQ,SAARhQ,EAFMuJ,EAEEyG,KACAzG,EAAOmG,KAAPnG,EADAyG,EACR;;QAAeN;UAMf,OAHMxJ,IACFtG,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADEsG,EAENlG,EAAQiQ,aAARjQ,EAFMkG,EAEE+J,KACA/J,EAAMwJ,KAANxJ,EADA+J,EACR;;QAAcP;UAoBd,OAjBMpN,IAAO1C,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAP0C,EACAwK,IACFlN,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFE0C,EAGA0K,IACFpN,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAJE0C,EAKA4K,IACFtN,cAAc,aAAdA,EAA6BE,CAA7BF,EAAmCG,CAAnCH,EAA8CI,CAA9CJ,CANE0C,EAOA6K,IACFvN,cAAc,gBAAdA,EAAgCE,CAAhCF,EAAsCG,CAAtCH,EAAiDI,CAAjDJ,CARE0C,EASA2K,IACFrN,cAAc,wBAAdA,EAAwCE,CAAxCF,EAA8CG,CAA9CH,EAAyDI,CAAzDJ,CAVE0C,EAYA4N,IAAOtQ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAZP0C,EAaA6N,IAAc,IAAI9C,WAAJ,CAChB6C,CADgB,EACVpD,CADU,EACHxK,CADG,EACG0K,CADH,EACiBC,CADjB,EACyCC,CADzC,EAEhBC,CAFgB,CAbd7K,EAgBNtC,EAAQoQ,cAARpQ,CAAuBmQ,CAAvBnQ,CAhBMsC,EAgBiB6N,KACfE,OAAOF,EAAY/C,EAAnBiD,CADeF,EACSE,OAAO,CAAPA,CADTF,EACvB;;QAAuC;UAUvC,OAPM/C,IACFxN,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADEwN,EAEA7L,IAAQ3B,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFRwN,EAGAkD,IACF1Q,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAJEwN,EAKmBpN,EAAQuQ,cAARvQ,CAAuBoN,CAAvBpN,EACRiO,KADQjO,CACFuB,CADEvB,EACKsQ,CADLtQ,CALnBoN,EAMwBkD,KACtBD,OAAO,CAAPA,CADsBC,EAC9B;;QAAe;UAQf,OALME,IACF5Q,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADE4Q,EAEAC,IACF7Q,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAHE4Q,EAGsCxQ,KACpBA,EAAQuQ,cAARvQ,CAAuBwQ,CAAvBxQ,EACA4N,IADA5N,CACKyQ,CADLzQ,CADoBA,EAE5C;;QAA6ByQ;UAU7B,OAPMC,IACF9Q,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADE8Q,EAEAC,IACF/Q,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAHE8Q,EAIAE,IACFhR,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CALE8Q,EAKsC1Q,KAClBA,EAAQuQ,cAARvQ,CAAuB0Q,CAAvB1Q,EACA6Q,MADA7Q,CACO2Q,CADP3Q,EACsB4Q,CADtB5Q,CADkBA,EAE5C;;QAAgD4Q;UAWhD,OARME,IACFlR,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADEkR,EAEAC,IACFnR,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAHEkR,EAIAE,IACFpR,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CALEkR,EAMqB9Q,EAAQuQ,cAARvQ,CAAuB8Q,CAAvB9Q,EACRiR,OADQjR,CACA+Q,CADA/Q,EACgBgR,CADhBhR,CANrB8Q,EAOqCE,KACnCX,OAAO,CAAPA,CADmCW,EAC3C;;QAAe;UAQf,OALME,IACFtR,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADEsR,EAEAC,IAAoBnR,EAAQuQ,cAARvQ,CAAuBkR,CAAvBlR,CAFpBkR,EAGAE,IACFxR,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAJEsR,EAIsClR,KACpCmR,EAAkB/M,MAAlB+M,CAAyBC,CAAzBD,CADoCnR,EAC5C;;QAAiCoR;UAWjC,OARMC,IACFzR,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADEyR,EAEAC,IACF1R,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHEyR,EAIAE,IACF3R,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CALEyR,EAMmBrR,EAAQuQ,cAARvQ,CAAuBqR,CAAvBrR,EACRoC,KADQpC,CACFuR,CADEvR,EACOsR,CADPtR,CANnBqR,EAO0BC,KACxBjB,OAAO,CAAPA,CADwBiB,EAChC;;QAAe;UAMf,OAHME,IACF5R,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADE4R,EAEAC,IAAkBzR,EAAQuQ,cAARvQ,CAAuBwR,CAAvBxR,CAFlBwR,EAEyCA,KACvCnB,OAAOoB,EAAgBnP,IAAhBmP,EAAPpB,EAA+B,OAA/BA,CADuCmB,EAC/C;;QAAuC;UAOvC,OAJME,IACF9R,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADE8R,EAEmB1R,EAAQuQ,cAARvQ,CAAuB0R,CAAvB1R,EACR2R,aADQ3R,EAFnB0R,EAGWC,KACTtB,OAAO,CAAPA,CADSsB,EACjB;;QAAe;UAEf,MAAMtH,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;MApIFrK;IAoIoCiF,CApIpCjF;EAoIoCiF,CApIpCjF;AAoIoCiF,CJrIxC;AAAA,IKHauE,cAAgC,UAAC1J,CAAD,EACCC,CADD,EAECC,CAFD,EAECA;EAE5C,QAAQF,EAAKmF,EAAb;IACE,KAAK,QAAL;MACE,IAAM2M,IACFhS,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADJ;MAAA,IAEMiS,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFZ;MAAA,IAGMkS,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACImS,WADJnS,EAJL;MAAA,IAMMoS,IACFpS,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAPJ;MAQA,QAAQqS,OACJrS,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqS,EAEJrS,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAFIqS,EAGJL,CAHIK,EAGIJ,CAHJI,EAG6BH,CAH7BG,EAIJD,CAJIC,CAAR;;IAMF,KAAK,QAAL;MACQL,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGAE,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACImS,WADJnS,EAJCgS;MAAN,IAMMM,IACFtS,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CAPJ;MAQA,QAAQuS,OACJvS,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuS,EAGJvS,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHIuS,EAGqCnS,CACxC4R,EAAO,CAAPA,CADwC5R,EAC7B4R,EAAO,CAAPA,CAD6B5R,CAHrCmS,EAIoBN,CAJpBM,EAKJL,CALIK,EAKJL,CAAgCI,EAAU,CAAVA,CAAhCJ,EAA8CI,EAAU,CAAVA,CAA9CJ,CALIK,CAAR;;IAOF,KAAK,cAAL;IACA,KAAK,4BAAL;MACQ;MAAA,IAACC,QAAD;MAAA,IAAUC,QAAV;MAAA,IAGAC,IAAwB,cAAZF,CAHZ;MAAA,IAIAG,IAA6B,YAAnBF,CAJV;MAAA,IAKAG,IAA0B,qBAAZJ,CALd;MAAA,IAOAK,IACD7S,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CARC;;MASN,IAAI0S,CAAJ,EAAe;QACb,IAAIC,KAAuB,MAAZE,CAAf,EACE,MAAM,IAAIzL,KAAJ,CACF,uGADE,CAAN;QAIF,KAAKuL,CAAL,IAA4B,MAAZE,CAAhB,EACE,MAAM,IAAIzL,KAAJ,CACF,kFADE,CAAN;MAKJ;;MAAA,IAAIwL,CAAJ,EACE,MAAM,IAAIxL,KAAJ,CACF,uEADE,CAAN;MAGI4K,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGAE,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACImS,WADJnS,EAJCgS,EAMAM,IACFtS,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CAPEgS;MAAN,IAQM/B,kCARN;MAAA,IAQO6C,QARP;MAAA,IAQgBC,QARhB;MAaA,SAHiC,mBAAZ7S,EAAKmF,EAAO,GAC7B2N,MAAUC,MADmB,GAE7BD,MAAUE,eACd,EADcA;QAEZC,GAAGnT,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFSkT;QAIZE,QAAQpT,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAJIkT;QAMZG,UAAUrB,EAAO,CAAPA,CAAVqB,EAAqBrB,EAAO,CAAPA,CAArBqB,CANYH;QAOZjB,KAAKA,CAPOiB;QAQZhB,YAAYA,CARAgB;QASZZ,YAAYA,EAAU,CAAVA,CAAZA,EAA0BA,EAAU,CAAVA,CAA1BA,CATYY;QAUZI,MAAMR,CAVMI;QAWZK,YAAYd,CAXAS;QAYZM,wBAAwBT;MAZZG,CACd;;IAcF,KAAK,qBAAL;IACA,KAAK,iBAAL;MACE,IAAM7J,IAAQrJ,cACI,aADJA,EACmBE,CADnBF,EACyBG,CADzBH,EAEII,CAFJJ,CAAd;MAIMgS,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS;MAGN,QAAQyB,gBACJzT,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyT,EAGJzT,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHIyT,EAIJpK,CAJIoK,EAIJpK,CAAQ2I,EAAO,CAAPA,CAAR3I,EAAmB2I,EAAO,CAAPA,CAAnB3I,CAJIoK,EAI2BxB,CAJ3BwB,CAAR;;IAMF,KAAK,uBAAL;IACA,KAAK,iBAAL;MACQzB,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGAM,IACFtS,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CAJEgS,EAKAE,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACImS,WADJnS,EANCgS;MASN,QAAQ0B,gBACJ1T,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADI0T,EAGJ1T,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHI0T,EAGqCtT,CACxC4R,EAAO,CAAPA,CADwC5R,EAC7B4R,EAAO,CAAPA,CAD6B5R,CAHrCsT,EAIoBzB,CAJpByB,EAKJxB,CALIwB,EAKJxB,CAAgCI,EAAU,CAAVA,CAAhCJ,EAA8CI,EAAU,CAAVA,CAA9CJ,CALIwB,CAAR;;IAOF,KAAK,QAAL;MACQ1B,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGAE,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACImS,WADJnS,EAJCgS,EAMAM,IACFtS,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CAPEgS;MAQN,QAAQ2B,OACJ3T,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2T,EAGJ3T,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHI2T,EAGqCvT,CAExC4R,EAAO,CAAPA,CAFwC5R,EAE7B4R,EAAO,CAAPA,CAF6B5R,EAElB4R,EAAO,CAAPA,CAFkB5R,CAHrCuT,EAK+B1B,CAL/B0B,EAMJzB,CANIyB,EAMJzB,CACCI,EAAU,CAAVA,CADDJ,EACeI,EAAU,CAAVA,CADfJ,EAC6BI,EAAU,CAAVA,CAD7BJ,CANIyB,CAAR;;IASF,KAAK,SAAL;MACQ3B,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS;MAAN,IAGM4B,IACF5T,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJJ;MAMA,QAAQ6T,QACJ7T,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6T,EACgCzT,CAEnCwT,EAAW,CAAXA,CAFmCxT,EAEpBwT,EAAW,CAAXA,CAFoBxT,CADhCyT,EAGuB,CAAM7B,EAAO,CAAPA,CAAN,EAAiBA,EAAO,CAAPA,CAAjB,CAHvB6B,EAIJ5B,CAJI4B,CAAR;;IAMF,KAAK,SAAL;MACQ7B,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGA4B,IACF5T,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJEgS;MAMN,QAAQ8B,QACJ9T,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI8T,EACgC1T,CAEnCwT,EAAW,CAAXA,CAFmCxT,EAEpBwT,EAAW,CAAXA,CAFoBxT,CADhC0T,EAGuB,CAAM9B,EAAO,CAAPA,CAAN,EAAiBA,EAAO,CAAPA,CAAjB,CAHvB8B,EAIJ7B,CAJI6B,CAAR;;IAMF,KAAK,mBAAL;MACQ9B,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGA4B,IACF5T,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJEgS;MAAN,IAKM+B,IACF/T,cAAc,qBAAdA,EAAqCE,CAArCF,EAA2CG,CAA3CH,EAAsDI,CAAtDJ,CANJ;MAAA,IAQMgU,oFARN;MAYA;;IAEF,KAAK,WAAL;MACQhC,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGA4B,IACF5T,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJEgS;MAMN,QAAQiC,UACJjU,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiU,EACgC7T,CACnCwT,EAAW,CAAXA,CADmCxT,EACpBwT,EAAW,CAAXA,CADoBxT,EACLwT,EAAW,CAAXA,CADKxT,CADhC6T,EAEsC,CACzCjC,EAAO,CAAPA,CADyC,EAC9BA,EAAO,CAAPA,CAD8B,EACnBA,EAAO,CAAPA,CADmB,CAFtCiC,EAG+BhC,CAH/BgC,CAAR;;IAMF,KAAK,WAAL;MACQjC,IACFhS,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEgS,EAEAC,IAAMjS,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFNgS,EAGA4B,IACF5T,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJEgS;MAMN,QAAQkC,UACJlU,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkU,EACgC9T,CACnCwT,EAAW,CAAXA,CADmCxT,EACpBwT,EAAW,CAAXA,CADoBxT,EACLwT,EAAW,CAAXA,CADKxT,CADhC8T,EAEsC,CACzClC,EAAO,CAAPA,CADyC,EAC9BA,EAAO,CAAPA,CAD8B,EACnBA,EAAO,CAAPA,CADmB,CAFtCkC,EAG+BjC,CAH/BiC,CAAR;;IAMF;MACE,MAAMzJ,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA7MJ;AA6MsCpF,CL9MxC;AAAA,IMHauE,cAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,MAAL;MACE,IAAMgE,IACFrJ,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADJ;MAAA,IAEMkN,IACFlN,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAHJ;MAAA,IAIMwB,IAAQxB,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAJd;MAKA,QAAQmU,KAAS9K,CAAT8K,EAAgB3S,CAAhB2S,EAAuBjH,CAAvBiH,CAAR;;IAEF,KAAK,UAAL;MACE,IAAM1T,IAAQT,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAAd;MAAA,IACMoU,IAAOpU,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CADb;MAAA,IAEMqU,IAAMrU,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFZ;MAGA,QAAQsU,SAAa7T,CAAb6T,EAAoBF,CAApBE,EAA0BD,CAA1BC,CAAR;;IAEF,KAAK,aAAL;MACE,IAAMC,IACFvU,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADJ;MAAA,IAEMwU,IACFxU,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAHJ;MAAA,IAIMyU,IAAOzU,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAJb;MAKA,QAAQ0U,YAAgBH,CAAhBG,EAAwBF,CAAxBE,EAAoCD,CAApCC,CAAR;;IAEF,KAAK,QAAL;MACE,IAAMzG,IACFjO,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADJ;MAAA,IAEM2U,IAAQ3U,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFd;MAAA,IAGM4U,IACF5U,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAJJ;MAAA,IAKM6U,IACF7U,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CANJ;MAOA,QAAQ8U,OAAW7G,CAAX6G,EAAoBH,CAApBG,EAA2BF,CAA3BE,EAAoCD,CAApCC,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQC,KACJ/U,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADI+U,EAEJ/U,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFI+U,CAAR;;IAIF,KAAK,UAAL;MACE,QAAQC,SACJhV,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgV,CAAR;;IAGF,KAAK,eAAL;MACE,QAAQC,cAEJjV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIiV,EAGJjV,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHIiV,EAIJjV,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAJIiV,EAKJjV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CALIiV,CAAR;;IAOF,KAAK,OAAL;MACQxU,IAAQT,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAARS;MAAN,IACMyU,IAAOlV,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CADb;MAAA,IAEMmV,IAAOnV,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFb;MAGA,QAAQoV,MACJ3U,CADI2U,EACGF,CADHE,EACSD,CADTC,EAEJpV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIoV,CAAR;;IAKF,KAAK,iBAAL;MACQ/L,IACFrJ,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADEqJ;MAAN,IAEMgM,IAAOrV,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFb;MAAA,IAGMsV,IACFtV,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAJJ;MAKMyU,IAAOzU,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPyU;MACN,QAAQc,gBACJlM,CADIkM,EACGF,CADHE,EACSD,CADTC,EAEJvV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIuV,EAIJd,CAJIc,CAAR;;IAMF,KAAK,OAAL;MACE,QAAQC,MACJxV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADIwV,EAEJxV,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIwV,CAAR;;IAIF,KAAK,WAAL;MACE,QAAQC,UACJzV,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyV,CAAR;;IAGF;MACE,MAAMhL,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAlFJ;AAkFsCpF,CNnFxC;AAAA,IMmFwCA,gBNnFxC;AAAA,IOHauE,cAAqC,UAC9C1J,CAD8C,EAClCC,CADkC,EAE9CC,CAF8C,EAE9CA;EAAAA;IAAAA;IAAAA;MAAAA;QAAAA;UAAAA,QACMF,EAAKmF,EADXjF;YACWiF,KACN,qBADMA;YACN,KACA,qBADA;YACA,KACA,qBADA;cACA;;YAAA,KA2BA,OA3BA;cA2BA;;YAAA,KAQA,UARA;cAQA;UAvCLjF;;UAuCK;;QAAA;UAAA,OAlCGsV,IACF1V,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADE0V,EAEAC,IACF3V,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHE0V,EAIAE,IACF5V,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CALE0V,EAMAG,IACF7V,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAPE0V,EAQAI,IACF9V,cAAc,gBAAdA,EAAgCE,CAAhCF,EAAsCG,CAAtCH,EAAiDI,CAAjDJ,CATE0V,EAWU,0BAAZxV,EAAKmF,EAAO,GAAPA,MAAO,IACR0Q,IACF/V,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CADE+V,EAC6C3V,IAE9B4V,MAAUC,+BAAVD,CACjBN,CADiBM,EACML,CADNK,EAC8BJ,CAD9BI,EAEjBH,CAFiBG,EAEHF,CAFGE,EAEaD,CAFbC,CAF8B5V,CAFrC,CAuBb;;QAjBiC2V;UAElC,aAJMG,IAASjG,QAIf,EAAekG,eAAf,EAAgCD,EAAOE,cAAvC;;QAAuCA;UAGjC,WAAMJ,MAAUK,sBAAVL,CACVN,CADUM,EACaL,CADbK,EACqCJ,CADrCI,EAEVH,CAFUG,EAEIF,CAFJE,CAAN;;QAEUF;UAFlB,YAAQ7F,QAAR;;QAAQA;UAQQ,OAHVqG,IACDtW,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,EACIuW,MADJvW,CACW,MADXA,CADCsW,EAEU,IACME,WAAeF,CAAfE,CADN,CACA;;QAAqBF;UAErC,OAFMJ,KAAUjG,QAAViG,GACNI,EAAUzI,OAAVyI,EADMJ,EACIrI,IACHqI,CADGrI,CACV;;QAAOqI;UAGP,WAAOO,eACHzW,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADGyW,EAEHzW,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFGyW,CAAP;;QAEwCrW;UAGxC,MAAMqK,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;MA7CFrK;IA6CoCiF,CA7CpCjF;EA6CoCiF,CA7CpCjF;AA6CoCiF,CP5CxC;AAAA,IQHauE,cACT,UAAC1J,CAAD,EAAaC,CAAb,EACCC,CADD,EACCA;EACC,QAAQF,EAAKmF,EAAb;IACE,KAAK,QAAL;MACE,IAAM8N,IAAInT,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAAV;MAAA,IACM0W,IAAI1W,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADV;MAAA,IAEM2W,IACF3W,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHJ;MAAA,IAIMkW,IAASU,KAASzD,CAATyD,EAAYF,CAAZE,EAAeD,CAAfC,CAJf;MAKA,QAAQV,EAAOW,MAAf,EAAuBX,EAAOjI,OAA9B;;IAEF;MACE,MAAMxD,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAVJ;AAUsCpF,CRV5C;AAAA,ISHauE,cAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,OAAL;MACE,OAAOlF,EAAUD,EAAKZ,IAAfa,CAAP;;IAEF,KAAK,wBAAL;MACE,IAAMiI,IACFpI,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADJ;MAEA,QAAQa,UAAUX,EAAKZ,IAAfuB,EAAqBV,CAArBU,EAAgCT,CAAhCS,KAA4CuH,CAApD;;IACF,KAAK,aAAL;MACE,QAAQvH,UAAUX,EAAKZ,IAAfuB,EAAqBV,CAArBU,EAAgCT,CAAhCS,CAAR;;IACF,KAAK,UAAL;IACA,KAAK,cAAL;IACA,KAAK,yBAAL;MACE,QACGb,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EAA4D8P,KAA5D9P,EADH;;IAGF,KAAK,WAAL;MACE,OAAQA,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EACHgB,GADGhB,CACC,UAACkO,CAAD,EAACA;QAAkB,SAAE4B,KAAF5B;MAAE4B,CADtB9P,CAAR;;IAEF,KAAK,UAAL;MAGE,QADKA,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EACY8P,KADZ9P,EACL;;IACF,KAAK,OAAL;MACE,QAAQ8W,SACH9W,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EAA4DqJ,KADzDyN,EAEJ,OAFIA,CAAR;;IAGF,KAAK,QAAL;MACE,OAAQ9W,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EACHgB,GADGhB,CACC,UAACkO,CAAD,EAACA;QAAkB,gBAAaA,EAAE7E,KAAfyN;MAAezN,CADnCrJ,CAAR;;IAEF,KAAK,MAAL;MACE,QAAQ+W,OACH/W,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EAA4D0C,IADzDqU,EAEJ,OAFIA,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQA,OACH/W,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,EAA4DgX,IADzDD,EAEJ,OAFIA,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQA,OAAW,CAAXA,CAAR;;IACF,KAAK,OAAL;MACE,IAAMzQ,IAAQtG,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAAd;MAAA,IACMiB,IACFjB,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFJ;MAAA,IAGMiX,IACFjX,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAJJ;MAAA,IAKMkX,IACFlX,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CANJ;MAOAmX,QAAQC,IAARD,CACI,gGADJA,GAGAA,QAAQE,GAARF,CAAYF,CAAZE,CAHAA;;MAIA,KAAK,IAAIvU,IAAI,CAAb,EAAgBA,IAAI3B,EAAK4B,MAAzB,EAAiCD,GAAjC,EACEuU,QAAQE,GAARF,CACIjW,MAAMC,SAAND,CAAgBH,KAAhBG,CAAsBE,IAAtBF,CAA2BD,EAAK2B,CAAL3B,EAAQI,QAARJ,EAA3BC,EAA+CH,KAA/CG,CAAqD,CAArDA,EAAwDgW,CAAxDhW,CADJiW;;MAGF,QAAQ7Q,CAAR;;IAEF;MACE,MAAMmE,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA3DJ;AA2DsCpF,CT5DxC;AAAA,IUHauE,cAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,gBAAL;MACE,IAAMiS,IACFtX,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADJ;MAAA,IAEM0C,IAAO1C,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFb;MAAA,IAGMuX,IACFvX,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAJJ;MAKA,QAAQgW,MAAUwB,cAAVxB,CACJsB,CADItB,EACJsB,CAAwC5U,EAAK,CAALA,CAAxC4U,EAAiD5U,EAAK,CAALA,CAAjD4U,CADItB,EAEJuB,CAFIvB,CAAR;;IAIF,KAAK,uBAAL;MACQsB,IACFtX,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CADEsX,EAEA5U,IAAO1C,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFPsX,EAGAC,IACFvX,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAJEsX;MAKN,QAAQtB,MAAUyB,qBAAVzB,CACJsB,CADItB,EACJsB,CAAwC5U,EAAK,CAALA,CAAxC4U,EAAiD5U,EAAK,CAALA,CAAjD4U,CADItB,EAEJuB,CAFIvB,CAAR;;IAIF,KAAK,eAAL;MACE,IAAM1R,IACFtE,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADJ;MAAA,IAEM0V,IACF1V,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAHJ;MAAA,IAIM0X,IACF1X,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CALJ;MAAA,IAMM2X,IACF3X,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAPJ;MAAA,IAQM4X,IACF5X,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CATJ;MAAA,IAUM6X,IACF7X,cAAc,oBAAdA,EAAoCE,CAApCF,EAA0CG,CAA1CH,EAAqDI,CAArDJ,CAXJ;MAaA,QAAQgW,MAAU8B,aAAV9B,CACJ1R,CADI0R,EACmBN,CADnBM,EAC0C0B,CAD1C1B,EAEJ2B,CAFI3B,EAE0B4B,CAF1B5B,EAGJ6B,CAHI7B,CAAR;;IAKF;MACE,MAAMvL,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAzCJ;AAyCsCpF,CV1CxC;AAAA,IWHauE,cAAgC,UAAC1J,CAAD,EACCC,CADD,EAECC,CAFD,EAECA;EAE5C,QAAQF,EAAKmF,EAAb;IACE,KAAK,OAAL;MACE,QAAQ0S,MACJ/X,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+X,EAEJ/X,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFI+X,CAAR;;IAIF,KAAK,UAAL;MACE,QAAQC,SACJhY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgY,EAEJhY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIgY,CAAR;;IAIF,KAAK,SAAL;MACE,QAAQC,QACJjY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiY,EAEJjY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIiY,CAAR;;IAIF,KAAK,cAAL;MACE,QAAQC,aACJlY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkY,EAEJlY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIkY,CAAR;;IAIF,KAAK,MAAL;MACE,QAAQC,KACJnY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADImY,EAEJnY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFImY,CAAR;;IAIF,KAAK,WAAL;MACE,QAAQC,UACJpY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIoY,EAEJpY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIoY,CAAR;;IAIF,KAAK,YAAL;MACE,QAAQC,WACJrY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqY,EAEJrY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIqY,CAAR;;IAIF,KAAK,YAAL;MACE,QAAQC,WACJtY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIsY,CAAR;;IAGF,KAAK,WAAL;MACE,QAAQC,UACJvY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuY,EAEJvY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIuY,CAAR;;IAIF,KAAK,QAAL;IACA,KAAK,UAAL;MACE,QAAQC,MACJxY,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CADIwY,EAEJxY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIwY,EAGJxY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAHIwY,CAAR;;IAKF;MACE,MAAM/N,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EArDJ;AAqDsCpF,CXtDxC;AAAA,IYHauE,eAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,aAAL;IACA,KAAK,eAAL;IACA,KAAK,QAAL;MACE,QAAQoT,OACJzY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyY,EAEJzY,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFIyY,EAGJzY,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAHIyY,EAIJzY,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAJIyY,CAAR;;IAMF,KAAK,WAAL;MACE,QAAQC,UACJ1Y,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0Y,EAEJ1Y,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFI0Y,CAAR;;IAIF,KAAK,cAAL;MACQ;MAAA,IAAClG,QAAD;MAAA,IAAUC,QAAV;MAAA,IAGAC,IAAwB,cAAZF,CAHZ;MAAA,IAIAG,IAA6B,YAAnBF,CAJV;MAAA,IAMAI,IACD7S,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAPC;;MAQN,IAAI0S,CAAJ,EAAe;QACb,IAAIC,KAAuB,MAAZE,CAAf,EACE,MAAM,IAAIzL,KAAJ,CACF,oFADE,CAAN;QAIF,KAAKuL,CAAL,IAA4B,MAAZE,CAAhB,EACE,MAAM,IAAIzL,KAAJ,CACF,+DADE,CAAN;MAIE;;MAAA;MAAA,IAAC0L,QAAD;MAAA,IAAUC,QAAV;MAEN,QAAQC,MAAU2F,MAAV3F,CAAU2F;QAChBC,GAAG5Y,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADa2Y;QAEhBtQ,GAAGrI,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAFa2Y;QAGhBE,YAAY7Y,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CAHI2Y;QAKhBG,YAAY9Y,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CALI2Y;QAOhBrF,MAAMR,CAPU6F;QAQhBpF,YAAYd,CARIkG;QAShBnF,wBAAwBT;MATR4F,CAAV3F,CAAR;;IAYF;MACE,MAAMvI,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAlDJ;AAkDsCpF,CZnDxC;AAAA,IaHauE,eAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,gBAAL;IACA,KAAK,kBAAL;IASA,KAAK,kBAAL;MACE,QAAQ0T,UACJ/Y,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+Y,EAEJ/Y,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFI+Y,EAGJ/Y,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAHI+Y,EAIJ/Y,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAJI+Y,EAKJ/Y,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CALI+Y,EAMJ/Y,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CANI+Y,CAAR;;IAQF,KAAK,KAAL;MACE,QAAQC,2BACJhZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgZ,EAGJhZ,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHIgZ,EAIJhZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAJIgZ,EAKJhZ,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CALIgZ,EAMJhZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CANIgZ,CAAR;;IAQF,KAAK,SAAL;MACE,QAAQC,QACJjZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIiZ,CAAR;;IAGF,KAAK,YAAL;MACE,QAAQC,WACJlZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkZ,CAAR;;IAGF,KAAK,eAAL;MACE,QAAQC,cACJnZ,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADImZ,EAGJnZ,cAAc,aAAdA,EAA6BE,CAA7BF,EAAmCG,CAAnCH,EAA8CI,CAA9CJ,CAHImZ,EAIJnZ,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAJImZ,EAKJnZ,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CALImZ,CAAR;;IAQF;MACE,MAAM1O,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA/CJ;AA+CsCpF,CbhDxC;AAAA,IcHauE,eAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,KAAL;MACE,IAAM+T,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAb;MAAA,IACMqZ,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFJ;MAGA,QAAQsZ,IACJtZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIsZ,EACwDF,CADxDE,EAEJD,CAFIC,CAAR;;IAIF,KAAK,MAAL;MACQF,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQG,KACJvZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuZ,EACwDH,CADxDG,EAEJF,CAFIE,CAAR;;IAIF,KAAK,KAAL;MACQH,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQI,IACJxZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIwZ,EACwDJ,CADxDI,EAEJH,CAFIG,CAAR;;IAIF,KAAK,KAAL;MACQJ,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQK,IACJzZ,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyZ,EACwDL,CADxDK,EAEJJ,CAFII,CAAR;;IAIF,KAAK,KAAL;MACQL,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQM,IACJ1Z,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0Z,EACwDN,CADxDM,EAEJL,CAFIK,CAAR;;IAIF,KAAK,KAAL;MACQN,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQO,IACJ3Z,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2Z,EACwDP,CADxDO,EAEJN,CAFIM,CAAR;;IAIF,KAAK,QAAL;MACQP,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ;MACN,QAAQQ,OACJ5Z,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI4Z,EACwDR,CADxDQ,CAAR;;IAGF,KAAK,QAAL;MACQR,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ;MACN,QAAQS,OACJ7Z,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6Z,EACwDT,CADxDS,CAAR;;IAGF,KAAK,MAAL;MACQT,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACAC,IACFrZ,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CAFEoZ;MAGN,QAAQrM,KACJ/M,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+M,EACwDqM,CADxDrM,EAEJsM,CAFItM,CAAR;;IAIF;MACE,MAAMtC,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EApEJ;AAoEsCpF,CdrExC;AAAA,IeHauE,eAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,UAAL;IACA,KAAK,QAAL;MACE,IAAMyU,IAAI9Z,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAAV;MAAA,IACMoZ,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CADb;MAAA,IAEIL,IACAK,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAHJ;MAKA,OADAL,IAASA,EAAOoB,KAAPpB,CAAa,CAAbA,EAAgBma,CAAhBna,CAATA,EAAyBma,CACjBC,OAAWpa,CAAXoa,EAAmBX,CAAnBW,CADiBD,CACzB;;IAEF,KAAK,UAAL;IACA,KAAK,QAAL;MACQV,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ;MAAN,IACM9S,IAAQtG,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADd;MAAA,IAEMiO,IACFjO,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAHJ;MAIA,QAAQga,OAAW1T,CAAX0T,EAAkB/L,EAAQsI,MAARtI,CAAe,OAAfA,CAAlB+L,EAA2CZ,CAA3CY,CAAR;;IAEF,KAAK,WAAL;IACA,KAAK,SAAL;MACQZ,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ,EACA9S,IAAQtG,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADRoZ;MAEN,QAAQa,QAAY3T,CAAZ2T,EAAmBb,CAAnBa,CAAR;;IAEF,KAAK,OAAL;MAEE,IAAMC,IAAQla,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAAd;MAAA,IAEM0C,IAAO1C,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAFb;MAGA,QAAQma,MACJna,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIma,EACwDD,CADxDC,EAEJzX,CAFIyX,CAAR;;IAIF,KAAK,cAAL;MACQD,IACFla,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADEka;MAAN,IAEMxZ,IAAMV,cAAc,KAAdA,EAAqBE,CAArBF,EAA2BG,CAA3BH,EAAsCI,CAAtCJ,CAFZ;MAAA,IAGMqT,IACFrT,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAJJ;MAAA,IAKMoa,IACFpa,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CANJ;MAAA,IAOMqa,IACFra,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CARJ;MAAA,IASMsa,IACFta,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CAVJ;MAAA,IAWMua,IACFva,cAAc,aAAdA,EAA6BE,CAA7BF,EAAmCG,CAAnCH,EAA8CI,CAA9CJ,CAZJ;MAAA,IAaMwa,IACFxa,cAAc,gBAAdA,EAAgCE,CAAhCF,EAAsCG,CAAtCH,EAAiDI,CAAjDJ,CAdJ;MAAA,IAeM2J,IAAS3J,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAff;MAgBA,IAAqB,MAAjBka,EAAMrX,MAAW,IAAK8G,EAAON,KAAPM,CAAa9G,MAAb8G,GAAsB,CAAhD,EACE,KAAK,IAAI/G,IAAI,CAAb,EAAgBA,IAAI+G,EAAON,KAAPM,CAAa9G,MAAjC,EAAyCD,GAAzC,EACEsX,EAAMpX,IAANoX,CAAW,CAAXA,GACAxZ,EAAIoC,IAAJpC,CAASiJ,EAAON,KAAPM,CAAa/G,CAAb+G,CAATjJ,CADAwZ,EAEA7G,EAAQvQ,IAARuQ,CAAaA,EAAQ,CAARA,CAAbA,CAFA6G;MAKJ,QAAQO,aACJ9Q,CADI8Q,EACIP,CADJO,EACW/Z,CADX+Z,EACgBpH,CADhBoH,EACyBL,CADzBK,EACoCJ,CADpCI,EAC6CH,CAD7CG,EAEJF,CAFIE,EAESD,CAFTC,CAAR;;IAIF,KAAK,MAAL;MACE,OAAOC,KAAS;QACd,IAAMtB,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAb;QAAA,IACM4N,IACF5N,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CAFJ;QAAA,IAIMqJ,IAAQuE,EAAQ,CAARA,EAAWvE,KAJzB;QAAA,IAKMsR,IAAgB/M,EAAQ,CAARA,EAAWgN,OAAXhN,GAAqBvE,KAL3C;QAAA,IAMMwR,IAASjN,EAAQ5M,GAAR4M,CAAY;UACzB,IAAMkN,IAAYC,KAASC,WAATD,CAAqBpR,EAAON,KAA5B0R,EAAmC1R,CAAnC0R,CAAlB;UACA,KAAKD,CAAL,IAAKA,CACAC,KAASC,WAATD,CAAqBpR,EAAOiR,OAAPjR,GAAiBN,KAAtC0R,EAA6CJ,CAA7CI,CADL,EAEE,MAAM,IAAI3T,KAAJ,CAAU,wCAAV,CAAN;UAEF,OAAO0T,IAAYnR,CAAZmR,GAAqBnR,EAAOuF,OAAPvF,CAAeN,CAAfM,CAA5B;QAA2CN,CAN9BuE,CANf;QAcA,QAAQqN,MAAUJ,CAAVI,EAAkB7B,CAAlB6B,CAAR;MAA0B7B,CAfrBsB,CAAP;;IAkBF,KAAK,QAAL;MACE,OAAOA,KAAS;QACd,IAAMtB,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAb;QAAA,IACM2J,IACF3J,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAFJ;QAGA,OAAOkb,QAAYvR,CAAZuR,EAAoB9B,CAApB8B,CAAP;MAA2B9B,CAJtBsB,CAAP;;IAOF,KAAK,MAAL;MACE,IAAMS,IAAOnb,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAb;MACA,QAAQob,KACJpb,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIob,EACwDD,CADxDC,CAAR;;IAGF,KAAK,OAAL;IACA,KAAK,QAAL;MACQhC,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ;MAAN,IACMiC,IACFrb,cAAc,iBAAdA,EAAiCE,CAAjCF,EAAuCG,CAAvCH,EAAkDI,CAAlDJ,CAFJ;MAIA,OAAOsb,MACHtb,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADGsb,EAEHD,CAFGC,EAEclC,CAFdkC,CAAP;;IAIF,KAAK,WAAL;MACQrN,IACFjO,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEiO;MAAN,IAEM4I,IACF7W,cAAc,QAAdA,EAAwBE,CAAxBF,EAA8BG,CAA9BH,EAAyCI,CAAzCJ,CAHJ;MAAA,IAIMqJ,IACFrJ,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CALJ;MAMA,QAAQub,UAActN,CAAdsN,EAAuB1E,CAAvB0E,EAA+BlS,CAA/BkS,CAAR;;IAEF,KAAK,UAAL;MACE,IAAMpI,IAAInT,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CAAV;MACMiO,IACFjO,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADEiO;MAEN,QAAQuN,SAAarI,CAAbqI,EAAgBvN,CAAhBuN,CAAR;;IAEF,KAAK,eAAL;MACQvN,IACFjO,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CADEiO,EAGA5E,IACFrJ,cAAc,aAAdA,EAA6BE,CAA7BF,EAAmCG,CAAnCH,EAA8CI,CAA9CJ,CAJEiO;MAAN,IAKMwN,IACFzb,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CANJ;MAAA,IAOMmD,IACFnD,cAAc,cAAdA,EAA8BE,CAA9BF,EAAoCG,CAApCH,EAA+CI,CAA/CJ,CARJ;MASA,QAAQmZ,cACJlL,CADIkL,EACKsC,CADLtC,EACmB9P,CADnB8P,EAEJsC,EAAavO,KAAbuO,KAAuBtY,EAAa+J,KAApCuO,GACItY,CADJsY,GAEItY,EAAaoT,MAAbpT,CAAoBsY,EAAavO,KAAjC/J,CAJAgW,CAAR;;IAMF;MACE,MAAM1O,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAvIJ;AAuIsCpF,CfxIxC;AAAA,IgBHauE,eACT,UAAC1J,CAAD,EAAaC,CAAb,EACCC,CADD,EACCA;EACC,QAAQF,EAAKmF,EAAb;IACE,KAAK,KAAL;MACE,QAAQqW,IACJ1b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI0b,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJ3b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI2b,CAAR;;IAGF,KAAK,MAAL;MACE,QAAQC,KACJ5b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI4b,CAAR;;IAGF,KAAK,OAAL;MACE,QAAQC,MACJ7b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI6b,CAAR;;IAGF;MACE,MAAMpR,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EAlBJ;AAkBsCpF,ChBlB5C;AAAA,IiBHauE,eAAgC,UAAC1J,CAAD,EACDC,CADC,EAEDC,CAFC,EAEDA;EAE1C,QAAQF,EAAKmF,EAAb;IACE,KAAK,MAAL;MACE,QAAQyW,KACJ9b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI8b,EAEJ9b,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFI8b,CAAR;;IAKF,KAAK,YAAL;MACE,IAAM1C,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAb;MACA,QAAQ+b,WACJ/b,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADI+b,EACwD3C,CADxD2C,CAAR;;IAGF,KAAK,SAAL;MACQ3C,IAAOpZ,cAAc,MAAdA,EAAsBE,CAAtBF,EAA4BG,CAA5BH,EAAuCI,CAAvCJ,CAAPoZ;MACN,QAAQ4C,QACJhc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIgc,EACwD5C,CADxD4C,CAAR;;IAIF,KAAK,SAAL;MACE,QAAQC,QACJjc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIic,EAEJjc,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CAFIic,CAAR;;IAIF,KAAK,OAAL;IACA,KAAK,KAAL;MACE,QAAQC,IACJlc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIkc,EAEJ1Z,QACIxC,cAAc,SAAdA,EAAyBE,CAAzBF,EAA+BG,CAA/BH,EAA0CI,CAA1CJ,CADJwC,EAEI,CAFJA,CAFI0Z,EAKJlc,cAAc,eAAdA,EAA+BE,CAA/BF,EAAqCG,CAArCH,EAAgDI,CAAhDJ,CALIkc,CAAR;;IAOF,KAAK,gBAAL;MACE,IAAMC,IACFnc,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CADJ;MAAA,IAEMoc,IAAW5Z,QACbxC,cAAc,UAAdA,EAA0BE,CAA1BF,EAAgCG,CAAhCH,EAA2CI,CAA3CJ,CADawC,EACoD,CADpDA,CAFjB;MAIA,QAAQ6Z,eACJrc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIqc,EAEJF,CAFIE,EAEQD,CAFRC,CAAR;;IAIF,KAAK,gBAAL;MACQF,IACFnc,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,CADEmc;MAAN,IAEMG,IAAQ9Z,QACVxC,cAAc,OAAdA,EAAuBE,CAAvBF,EAA6BG,CAA7BH,EAAwCI,CAAxCJ,CADUwC,EACoD,CADpDA,CAFd;MAIA,QAAQ+Z,eACJvc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIuc,EAEJJ,CAFII,EAEQD,CAFRC,CAAR;;IAIF,KAAK,cAAL;MACE,IAAMC,IACFxc,cAAc,WAAdA,EAA2BE,CAA3BF,EAAiCG,CAAjCH,EAA4CI,CAA5CJ,CADJ;MAAA,IAEMkS,IACDlS,cAAc,YAAdA,EAA4BE,CAA5BF,EAAkCG,CAAlCH,EAA6CI,CAA7CJ,EACQmS,WADRnS,EAHL;MAMA,QAAQyc,aACJzc,cAAc,GAAdA,EAAmBE,CAAnBF,EAAyBG,CAAzBH,EAAoCI,CAApCJ,CADIyc,EAEJD,CAFIC,EAEOvK,CAFPuK,CAAR;;IAIF;MACE,MAAMhS,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;EA9DJ;AA8DsCpF,CjB/DxC;;AkBmBA,SAAgBuE,YAAhB,CACI1J,CADJ,EACgBC,CADhB,EAEIC,CAFJ,EAEIA;EACF,IAAMoB,IACF,UAAEtB,CAAF,EAAcC,CAAd,EAA0CC,CAA1C,EAA0CA;IACxC,QAAQF,EAAKR,QAAb;MACE,KAAK,YAAL;QACE,OAAOgb,KACH;UAAM,iBAAqBxa,CAArBwc,EAA2Bvc,CAA3Buc,EAAsCtc,CAAtCsc;QAAsCtc,CADzCsa,CAAP;;MAEF,KAAK,YAAL;QACE,OAAOA,KACH;UAAM,mBAAoBxa,CAApByc,EAA0Bxc,CAA1Bwc,EAAqCvc,CAArCuc;QAAqCvc,CADxCsa,CAAP;;MAEF,KAAK,SAAL;QACE,OAAOkC,YAAkB1c,CAAlB0c,EAAwBzc,CAAxByc,EAAmCxc,CAAnCwc,CAAP;;MACF,KAAK,aAAL;QACE,OAAOlC,KACH;UAAM,mBAAsBxa,CAAtB2c,EAA4B1c,CAA5B0c,EAAuCzc,CAAvCyc;QAAuCzc,CAD1Csa,CAAP;;MAEF,KAAK,UAAL;QACE,OAAOA,KAAS;UAAM,mBAAmBxa,CAAnB4c,EAAyB3c,CAAzB2c,EAAoC1c,CAApC0c;QAAoC1c,CAAnDsa,CAAP;;MACF,KAAK,SAAL;QACE,OAAOqC,YAAkB7c,CAAlB6c,EAAwB5c,CAAxB4c,EAAmC3c,CAAnC2c,CAAP;;MACF,KAAK,YAAL;QACE,OAAOrC,KACH;UAAM,mBAAqBxa,CAArB8c,EAA2B7c,CAA3B6c,EAAsC5c,CAAtC4c;QAAsC5c,CADzCsa,CAAP;;MAEF,KAAK,OAAL;QACE,OAAOA,KAAS;UAAM,mBAAgBxa,CAAhB+c,EAAsB9c,CAAtB8c,EAAiC7c,CAAjC6c;QAAiC7c,CAAhDsa,CAAP;;MACF,KAAK,OAAL;QACE,OAAOA,KAAS;UAAM,mBAAgBxa,CAAhBgd,EAAsB/c,CAAtB+c,EAAiC9c,CAAjC8c;QAAiC9c,CAAhDsa,CAAP;;MACF,KAAK,SAAL;QACE,OAAOA,KAAS;UAAM,mBAAkBxa,CAAlBid,EAAwBhd,CAAxBgd,EAAmC/c,CAAnC+c;QAAmC/c,CAAlDsa,CAAP;;MACF,KAAK,UAAL;QACE,OAAOA,KAAS;UAAM,oBAAmBxa,CAAnBkd,EAAyBjd,CAAzBid,EAAoChd,CAApCgd;QAAoChd,CAAnDsa,CAAP;;MACF,KAAK,eAAL;QACE,OAAOA,KACH;UAAM,oBAAwBxa,CAAxBmd,EAA8Bld,CAA9Bkd,EAAyCjd,CAAzCid;QAAyCjd,CAD5Csa,CAAP;;MAEF,KAAK,WAAL;QACE,OAAOA,KACH;UAAM,oBAAoBxa,CAApBod,EAA0Bnd,CAA1Bmd,EAAqCld,CAArCkd;QAAqCld,CADxCsa,CAAP;;MAEF,KAAK,YAAL;QACE,OAAOA,KACH;UAAM,oBAAoBxa,CAApBqd,EAA0Bpd,CAA1Bod,EAAqCnd,CAArCmd;QAAqCnd,CADxCsa,CAAP;;MAEF,KAAK,UAAL;QACE,OAAOA,KAAS;UAAM,oBAAmBxa,CAAnBsd,EAAyBrd,CAAzBqd,EAAoCpd,CAApCod;QAAoCpd,CAAnDsa,CAAP;;MACF,KAAK,gBAAL;QACE,OAAOA,KACH;UAAM,oBAAyBxa,CAAzBud,EAA+Btd,CAA/Bsd,EAA0Crd,CAA1Cqd;QAA0Crd,CAD7Csa,CAAP;;MAEF,KAAK,QAAL;QACE,IAAMlb,IAAWM,gBAAgBI,EAAKmF,EAArBvF,CAAjB;QACA,IAAIN,KAAYA,EAASK,cAAzB,EACE,OAAOL,EAASK,cAATL,CACH,IAAIkK,aAAJ,CAAkBxJ,CAAlB,EAAwBC,CAAxB,EAAmCC,CAAnC,CADGZ,CAAP;QAGA,MAAMiL,UAAU,eAAavK,EAAKmF,EAAlB,GAAkBA,qBAA5BoF,CAAN;;MAEJ;QACE,MAAMA,UACF,iBAAevK,EAAKmF,EAApB,GAAoBA,qIADlBoF,CAAN;IAlDJ;EADF,EAwDGvK,CAxDH,EAwDSC,CAxDT,EAwDoBC,CAxDpB,CADJ;;EA0DA,OAAIoB,aAAiBkc,OAAjBlc,GACKA,EAAMmc,IAANnc,CAAW,UAACP,CAAD,EAACA;IAAS,UAAGuD,MAAH,CAAUvD,CAAV;EAAUA,CAA/BO,CADLA,GACoCP,GAE9BuD,MAF8BvD,CAEvBO,CAFuBP,CADxC;ACtEF;;AAAA;EAME,WACoB2c,CADpB,EAEoBC,CAFpB,EAEoBA;IADApZ,oBACAA,uBADAA,EANZA;MAAe+I,IAAI,CAAnB/I;MAAsBqZ,WAAW,EAAjCrZ;MAAqCsZ,aAAa;IAAlDtZ,CAMYA,EALZA,iBAAoCA,KAAKuZ,WAAzCvZ,CAKYA,EAJZA,cAAS,CAIGA,EAElBA,KAAKwZ,yBAALxZ,EAFkBA;EAuHtB;;EAAA,OAlHUyZ,uBAAR,UAAiB1Q,CAAjB,EAA6BsQ,CAA7B,EAA6BA;IAC3B;MAAQtQ,KAAR;MAAYsQ,YAAZ;MAAuBC,aAAa;IAApC;EAAoC,CAD9BG,EASRrZ,sBAAIqZ,WAAJrZ,EAAIqZ,gBAAJrZ,EAAIqZ;IAAAA,KAOJ;MACE,OAAOzZ,KAAK0Z,QAAZ;IAAYA,CARVD;IAQUC,KARd,UAAmBA,CAAnB,EAAmBA;MACb1Z,KAAK0Z,QAAL1Z,KAAkB0Z,CAAlB1Z,KACFA,KAAK0Z,QAAL1Z,GAAgB0Z,CAAhB1Z,EACAA,KAAKwZ,yBAALxZ,EAFEA;IAEGwZ,CAHLC;IAGKD,cAHLC;IAGKD;EAHLC,CAAJrZ,CATQqZ,EAuBRrZ,sBAAIqZ,WAAJrZ,EAAIqZ,kBAAJrZ,EAAIqZ;IAAAA,KAAJ;MACE,OAAOzZ,KAAK2Z,kBAAL3Z,CAAwB,CAAxBA,CAAP;IAA+B,CAD7ByZ;IAC6BG,cAD7BH;IAC6BI;EAD7BJ,CAAJrZ,CAvBQqZ,EA+BRrZ,sBAAIqZ,WAAJrZ,EAAIqZ,mBAAJrZ,EAAIqZ;IAAAA,KAAJ;MACE,OAAOzZ,KAAK2Z,kBAAZ;IAAYA,CADVF;IACUE,cADVF;IACUE;EADVF,CAAJrZ,CA/BQqZ,EAmCAA,wCAAR;IAEE,KADA,IAAMK,MAAN,EACS3b,IAAI,CAAb,EAAgBA,IAAI6B,KAAK0Z,QAAL1Z,CAAc5B,MAAd4B,GAAuB,CAA3C,EAA8C7B,GAA9C,EAAmD;MACjD,IAAMub,IAAW1Z,KAAK0Z,QAAL1Z,CAAc1D,KAAd0D,CAAoB,CAApBA,EAAuBA,KAAK0Z,QAAL1Z,CAAc5B,MAAd4B,GAAuB7B,CAA9C6B,CAAjB;MACA8Z,EAAMzb,IAANyb,CAAW9Z,KAAK+Z,oBAAL/Z,CAA0B0Z,CAA1B1Z,CAAX8Z;IAEFA;;IAAAA,EAAMzb,IAANyb,CAAW,EAAXA,GACA9Z,KAAK2Z,kBAAL3Z,GAA0B8Z,CAD1BA;EAC0BA,CA1CpBL,EA6CAA,mCAAR,UAA6BC,CAA7B,EAA6BA;IAC3B,OAAOA,IACHA,EACKnd,GADLmd,CAEQ;MAAW,OAAgB,MAAf/d,EAAQoN,EAAO,IAA6B,MAAxBpN,EAAQ2d,WAAb,GACvB,EADuB,GAEpB3d,EAAQ0d,SAAR1d,GAAQ0d,GAAR1d,GAAqBA,EAAQ2d,WAFzB;IAEyBA,CAJ5CI,EAKKM,IALLN,CAKU,GALVA,CADGA,GAOH,EAPJ;EAOI,CArDED,EA4DRA,mCAAWhO,CAAX,EAAWA;IACLzL,KAAK0Z,QAAL1Z,KACFA,KAAKia,MAALja,IACAA,KAAK0Z,QAAL1Z,GAAgBA,KAAK0Z,QAAL1Z,CAAc1D,KAAd0D,EADhBA,EAEAA,KAAK0Z,QAAL1Z,CAAc3B,IAAd2B,CAAmBA,KAAKka,QAALla,CAAcA,KAAKia,MAAnBja,EAA2ByL,CAA3BzL,CAAnBA,CAFAA,EAGAA,KAAK2Z,kBAAL3Z,CAAwBma,OAAxBna,CAAgCA,KAAK+Z,oBAAL/Z,CAA0BA,KAAK0Z,QAA/B1Z,CAAhCA,CAJEA;EAI6D0Z,CAjE3DD,EAyERA;IACE,MAAIzZ,KAAK0Z,QAAL1Z,IAAiBA,KAAK0Z,QAAL1Z,CAAc5B,MAAd4B,GAAuB,CAA5C,GAKE,MAAM,IAAI2C,KAAJ,CAAU,yCAAV,CAAN;IAJA3C,KAAK0Z,QAAL1Z,GAAgBA,KAAK0Z,QAAL1Z,CAAc1D,KAAd0D,EAAhBA,EACAA,KAAK0Z,QAAL1Z,CAAcoa,MAAdpa,CAAcoa,CAAQ,CAAtBpa,CADAA,EAEAA,KAAK5C,iBAAL4C,CAAuBqa,KAAvBra,EAFAA;EAEuBqa,CA7EnBZ,EAuFRA;IACE,MAAIzZ,KAAK0Z,QAAL1Z,IAAiBA,KAAK0Z,QAAL1Z,CAAc5B,MAAd4B,GAAuB,CAA5C,GAWE,MAAM,IAAI2C,KAAJ,CAAU,uDAAV,CAAN;IAVA3C,KAAK0Z,QAAL1Z,GAAgBA,KAAK0Z,QAAL1Z,CAAc1D,KAAd0D,EAAhBA,EACAA,KAAKia,MAALja,EADAA;IAEA,IAAMrE,IACFyE,OAAOka,MAAPla,CAAOka,EAAPla,EAAkBJ,KAAK0Z,QAAL1Z,CAAcA,KAAK0Z,QAAL1Z,CAAc5B,MAAd4B,GAAuB,CAArCA,CAAlBI,CADJ;IAEAzE,EAAQ2d,WAAR3d,IAAuB,CAAvBA,EACAA,EAAQoN,EAARpN,GAAaqE,KAAKia,MADlBte,EAEAqE,KAAK0Z,QAAL1Z,CAAcoa,MAAdpa,CAAcoa,CAAQ,CAAtBpa,EAAyB,CAAzBA,EAA4BrE,CAA5BqE,CAFArE,EAGAqE,KAAK2Z,kBAAL3Z,CAAwBoa,MAAxBpa,CACI,CADJA,EACO,CADPA,EACUA,KAAK+Z,oBAAL/Z,CAA0BA,KAAK0Z,QAA/B1Z,CADVA,CAHArE;EAIyC+d,CAjGrCD,EAuGRA,kCAAU5e,CAAV,EAAUA;IACR,OAAOmF,KAAKmZ,SAALnZ,CAAenF,CAAfmF,CAAP;EAAsBnF,CAxGhB4e,EA2GRA,uCAAe3N,CAAf,EAAeA;IACb9L,KAAKoZ,cAALpZ,CAAoB8L,EAAY/C,EAAhC/I,IAAsC8L,CAAtC9L;EAAsC8L,CA5GhC2N,EA+GRA,uCAAe1Q,CAAf,EAAeA;IACb,OAAO/I,KAAKoZ,cAALpZ,CAAoB+I,CAApB/I,CAAP;EAA2B+I,CAhHrB0Q,EAgHqB1Q,CAE/B;AAF+BA,CA5H/B;;ACEA,SAAgBwR,oBAAhB,CACIrf,CADJ,EAC4B4F,CAD5B,EAEIqY,CAFJ,EAEIA;EAYF,KAXA,IAAMqB,IAAY,IAAIC,GAAJ,EAAlB,EACMC,MADN,EAEIC,IAAoB,IAFxB,EAGIC,IAAuB,IAH3B,EAOMC,IAAO,IAAIJ,GAAJ,EAPb,EAQMK,IACF1a,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoB7D,GAApB6D,CAAwB;IAAQ,qBAAcvF,CAAd8C,EAAoB,CAApBA;EAAoB,CAApDyC,CATJ,EAUM2a,IAAeja,SACrB,EAAOia,EAAS3c,MAAT2c,GAAkB,CAAzB,GAA4B;IAC1B,IAAMtf,IAAOsf,EAASC,GAATD,EAAb;IAAsBC,CAClBC,cAAcxf,CAAdwf,KAAuBC,eAAezf,CAAfyf,CADLF,KAED,QAAfL,CAFgBK,KAIlBJ,KADAD,IAAclf,CACdmf,EAAyBtZ,QAAzBsZ,CAAkCre,GAAlCqe,CAAsC;MAAS,SAAM/f,IAAN;IAAMA,CAArD+f,EACkBjM,MADlBiM,CACyB;MAAQ,SAAUO,GAAVX,CAAc3f,CAAd2f;IAAc3f,CAD/C+f,CAJkBI,GAQtBR,EAAUY,GAAVZ,CAAc/e,EAAKZ,IAAnB2f,CARsBQ,EAWM,QAAxB7B,EAAU1d,EAAKZ,IAAfse,CAAwB,IAATte,CAKwB,CALxBA,KAKfigB,EAAeO,OAAfP,CAAuBrf,EAAKZ,IAA5BigB,CALejgB,KAQQ,MAAvBY,EAAKP,MAALO,CAAY2C,MAAW,GAI3B3C,EAAKP,MAALO,CAAY2F,OAAZ3F,CAAoB;MAEdof,EAAKM,GAALN,CAAShZ,EAAMhH,IAAfggB,MAGJA,EAAKO,GAALP,CAAShZ,EAAMhH,IAAfggB,GACAE,EAAS1c,IAAT0c,CAAclZ,CAAdkZ,CAJIF;IAIUhZ,CANhBpG,CAJ2B,GACzBif,EAAcrc,IAAdqc,CAAmBjf,EAAKZ,IAAxB6f,CATiB7f,CAXGmgB;EAgCxB;;EAAA;IAAQ9f,SAAR;IAAgB4F,UAAhB;IAAyB0Z,YAAzB;IAAoCE,gBAApC;IAAmDC,cAAnD;IAAgEC;EAAhE;AAOF;;AAAA,SAAgBU,0BAAhB,CACIrc,CADJ,EACkBka,CADlB,EAEIoC,CAFJ,EAEIA;EACK;EAAA,IAAWrgB,YAAX;EAAA,IACD6f,MADC;EAEY3a,OAAOe,IAAPf,CAAYlF,CAAZkF,EACK7D,GADL6D,CACS;IAAQ,qBAAcvF,CAAd8C,EAAoB,CAApBA;EAAoB,CADrCyC,EAEK7D,GAFL6D,CAES;IAAQ,SAAMK,KAANxB,CAAYpE,CAAZoE;EAAYpE,CAF7BuF,EAGRgB,OAHQhB,CAGA;IACboa,EAAUW,GAAVX,CAAc3Y,EAAMhH,IAApB2f,KACFO,EAAS1c,IAAT0c,CAAclZ,CAAdkZ,CADEP;EACY3Y,CALCzB,GAQnBnB,EAAMuB,OAANvB,CAAcmC,OAAdnC,CAAsB;IAChBub,EAAUW,GAAVX,CAAcgB,EAAO3gB,IAArB2f,KACFO,EAAS1c,IAAT0c,CAAcS,CAAdT,CADEP;EACYgB,CAFlBvc,CARmBmB;;EAenB,KAFA,IAAMya,IAAO,IAAIJ,GAAJ,EAAb,EACMgB,MACN,EAAOV,EAAS3c,MAAT2c,GAAkB,CAAzB,GAA4B;IAC1B,IAAMtf,IAAOsf,EAASC,GAATD,EAAb;IACAF,EAAKO,GAALP,CAASpf,EAAKZ,IAAdggB,GACK1B,EAAU1d,EAAKZ,IAAfse,KACHsC,EAAapd,IAAbod,CAAkBhgB,CAAlBggB,CAFFZ,EAIApf,EAAK6F,QAAL7F,CAAc2F,OAAd3F,CAAsB;MAAAigB,CACfb,EAAKM,GAALN,CAASa,EAAM7gB,IAAfggB,CADea,IACSlB,EAAUW,GAAVX,CAAckB,EAAM7gB,IAApB2f,CADTkB,IAEhBA,EAAMxgB,MAANwgB,CAAaC,KAAbD,CAAmB;QAAS,SAAKP,GAALN,CAAShZ,EAAMhH,IAAfggB;MAAehgB,CAA3C6gB,CAFgBA,IAGlBX,EAAS1c,IAAT0c,CAAcW,CAAdX,CAHkBW;IAGJA,CAHlBjgB,CAJAof;EAWF;;EAAA,OAAOY,CAAP;AAGF;;AAAA,IAAMG,oBAAoB,QAApBA,EAA8B,OAA9BA,EAAuC,OAAvCA,EAAgD,MAAhDA,EAAwD,eAAxDA,CAAN;AAAA,IACMC,qBACJ,qBADIA,EACmB,qBADnBA,EAC0C,qBAD1CA,EACiE,OADjEA,CADN;;AAKA,SAAgBZ,aAAhB,CAA8Bxf,CAA9B,EAA8BA;EAC5B,OAAOmgB,iBAAiBP,OAAjBO,CAAyBngB,EAAKmF,EAA9Bgb,KAAqC,CAA5C;AAGF;;AAAA,SAAgBV,cAAhB,CAA+Bzf,CAA/B,EAA+BA;EAC7B,OAAOogB,kBAAkBR,OAAlBQ,CAA0BpgB,EAAKmF,EAA/Bib,KAAsC,CAA7C;AAA6C;;AAAA;ECrD7C,WAAoB5c,CAApB,EAAoBA;IAAAe,gBArDZA,mBAAmC,IAAI8b,GAAJ,EAqDvB9b,EApDZA,oBAoDYA,EA/CZA,iBAAY,GA+CAA,EAClBA,KAAK+b,QAAL/b,GAAgBf,EAAM6B,OADJd,EAElBA,KAAKgc,OAALhc,GAAef,EAAM/D,MAFH8E,EAGlBA,KAAKic,UAALjc,GAAkBf,EAAMqB,SAHNN;EA4ZtB;;EAAA,OA1cEI,sBAAI8b,WAAJ9b,EAAI8b,WAAJ9b,EAAI8b;IAAAA,KAAJ;MACE,OAAOlc,KAAKmc,UAAZ;IAAYA,CADVD;IACUC,KAEd,UAAchD,CAAd,EAAcA;MACZ,IAAMiD,IAAYhc,OAAOe,IAAPf,CAAY+Y,CAAZ/Y,EAAuB7D,GAAvB6D,CACd;QAAO,SAAUiB,CAAV8X,EAAe5c,GAAf4c,CAAmB;UAAU,SAAOpQ,EAAP;QAAOA,CAApCoQ;MAAoCpQ,CAD7B3I,CAAlB;MAEAJ,KAAKoc,SAALpc,GAAKoc,GAAerc,MAAfqc,CAAerc,KAAfqc,CAAerc,EAAfqc,EAAyBA,CAAzBA,CAALpc,EACAA,KAAKmc,UAALnc,GAAkBmZ,CADlBnZ;IACkBmZ,CAPhB+C;IAOgB/C,cAPhB+C;IAOgB/C;EAPhB+C,CAAJ9b,GAUAA,sBAAI8b,WAAJ9b,EAAI8b,QAAJ9b,EAAI8b;IAAAA,KAAJ;MACE,OAAOlc,KAAKgc,OAALhc,CAAazD,GAAbyD,CAAiB;QACtB;UACEnF,MAAMY,EAAKZ,IADb;UAEE+J,OAAOnJ,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,GACHA,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,CAAyBsB,KADtBtB,GACsBsB,KACzBjB,CAJN;UAKE2M,OAAOhN,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,GACHA,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,CAAyBsB,KADtBtB,GACsBsB,KACzBjB;QAPN;MAOMA,CARDkE,CAAP;IAQQlE,CATNogB;IASMpgB,cATNogB;IASMpgB;EATNogB,CAAJ9b,CAVAA,EAwBAA,sBAAI8b,WAAJ9b,EAAI8b,SAAJ9b,EAAI8b;IAAAA,KAAJ;MACE,OAAOlc,KAAK+b,QAAL/b,CAAczD,GAAdyD,CAAkB;QACvB;UACEnF,MAAMY,EAAKZ,IADb;UAEE+J,OAAOnJ,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,GACHA,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,CAAyBsB,KADtBtB,GACsBsB,KACzBjB,CAJN;UAKE2M,OAAOhN,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,GACHA,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,CAAyBsB,KADtBtB,GACsBsB,KACzBjB;QAPN;MAOMA,CARDkE,CAAP;IAQQlE,CATNogB;IASMpgB,cATNogB;IASMpgB;EATNogB,CAAJ9b,CAxBAA,EAsCAA,sBAAI8b,WAAJ9b,EAAI8b,YAAJ9b,EAAI8b;IAAAA,KAAJ;MACE,OAAOlc,KAAKgc,OAALhc,CAAazD,GAAbyD,CAAiB;QAAQ,SAAKuB,YAAL9F,IAAqBA,EAAKZ,IAA1B;MAA0BA,CAAnDmF,CAAP;IAA0DnF,CADxDqhB;IACwDrhB,cADxDqhB;IACwDrhB;EADxDqhB,CAAJ9b,CAtCAA,EA0CAA,sBAAI8b,WAAJ9b,EAAI8b,aAAJ9b,EAAI8b;IAAAA,KAAJ;MACE,OAAOlc,KAAK+b,QAAL/b,CAAczD,GAAdyD,CAAkB;QAAQ,SAAKuB,YAAL9F,IAAqBA,EAAKZ,IAA1B;MAA0BA,CAApDmF,CAAP;IAA2DnF,CADzDqhB;IACyDrhB,cADzDqhB;IACyDrhB;EADzDqhB,CAAJ9b,CA1CAA,EAoDQ8b,gCAAR,UAA0BhhB,CAA1B,EAA0C4F,CAA1C,EAA0CA;IACxC,IAAMub,IAAenhB,EAAOqB,GAAPrB,CAAW;MAAQ,SAAKL,IAAL;IAAKA,CAAxBK,EAA8BohB,IAA9BphB,EAArB;IAAA,IACMqhB,IAAgBzb,EAAQvE,GAARuE,CAAY;MAAQ,SAAKjG,IAAL;IAAKA,CAAzBiG,EAA+Bwb,IAA/Bxb,EADtB;IAEA,OAAOub,EAAarC,IAAbqC,CAAkBrc,KAAKwc,SAAvBH,IAAoC,IAApCA,GACHE,EAAcvC,IAAduC,CAAmBvc,KAAKwc,SAAxBD,CADJ;EAC4BC,CAxD9Bpc,EA+DQ8b,sBAAR,UAAgBhhB,CAAhB,EAAwC4F,CAAxC,EAAwCA;IACtC,IAAMya,IAAgBhB,qBAAqBrf,CAArBqf,EAA6BzZ,CAA7ByZ,EAAsCva,KAAKmZ,SAA3CoB,CAAtB;IAAA,IACOG,mBADP;IAAA,IACsBC,iBADtB;IAAA,IACmCC,gBADnC;IAEA,IAAmB,QAAfD,CAAJ,EACE,MAAM,IAAIhY,KAAJ,CACF,uCAAqCgY,EAAY9f,IAAjD,GAAiDA,+BAAjD,GACmB8f,EAAY/Z,EAD/B,GAC+BA,2GAD/B,GAGoCga,CAHpC,GAGoCA,GAJlC,CAAN;;IAOF,IAAIF,EAActc,MAAdsc,GAAuB,CAA3B,EAA8B;MAC5B,IAAM+B,IAAW3b,EAAQvE,GAARuE,CAAY;QAAK,SAAEjG,IAAF;MAAEA,CAAnBiG,CAAjB;MAAA,IACM4b,IAAUtc,OAAOe,IAAPf,CAAYlF,CAAZkF,CADhB;MAEA,MAAM,IAAIuC,KAAJ,CACF,iCAA+B8Z,CAA/B,GAA+BA,8BAA/B,GACIC,CADJ,GACIA,oCADJ,GACgDhC,CADhD,GACgDA,GAF9C,CAAN;IAKF;;IAAA,OAAOY,2BACHtb,KAAKf,KADFqc,EACStb,KAAKmZ,SADdmC,EACyBC,CADzBD,CAAP;EACgCC,CAnFlCnb,EA+FA8b,gCAAQhhB,CAAR,EAAgC4F,CAAhC,EAAgCA;IAAhC;IACE5F,IAAS8E,KAAK2c,SAAL3c,CAAe9E,CAAf8E,CAAT9E;IACA,IAAM4e,IAAQ1Z,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoBkc,IAApBlc,EAAd;IACAJ,KAAK4c,WAAL5c,CAAiB9E,CAAjB8E,GACAA,KAAK6c,sBAAL7c,CAA4B9E,CAA5B8E,CADAA,EAEAc,IAAUd,KAAK8c,UAAL9c,CAAgBc,CAAhBd,CAFVA,EAGAA,KAAK+c,YAAL/c,CAAkBc,CAAlBd,CAHAA;IAIA,IAAMgd,IACFlD,EAAMvd,GAANud,CAAU;MAAQ,SAAK7a,KAALyB,CAAWD,KAAXC,CAAiB/C,cAAc9C,CAAd8C,EAAoB,CAApBA,CAAjB+C;IAAqC,CAAvDoZ,CADJ;IAAA,IAEMmD,IACFnc,EAAQvE,GAARuE,CAAY;MAAQ,SAAK7B,KAALyB,CAAWD,KAAXC,CAAiB/C,cAAc9C,CAAd8C,EAAoB,CAApBA,CAAjB+C;IAAqC,CAAzDI,CAHJ;IAAA,IAIMoc,IAAiBld,KAAKmd,iBAALnd,CAAuBgd,CAAvBhd,EAAmCid,CAAnCjd,CAJvB;IAAA,IAMIyb,IAAezb,KAAKod,WAALpd,CAAiBqd,GAAjBrd,CAAqBkd,CAArBld,CANnB;IAOoB,QAAhByb,CAAgB,KAClBA,IAAezb,KAAKsd,OAALtd,CAAa9E,CAAb8E,EAAqBid,CAArBjd,CAAfyb,EACAzb,KAAKod,WAALpd,CAAiBud,GAAjBvd,CAAqBkd,CAArBld,EAAqCyb,CAArCzb,CAFkB;IAIpB,IAAMoZ,MAAN;IACA,OAAO5O,KAAK;MACV,IAAM7O,IAAU,IAAI8d,gBAAJ,CAAqB/Y,EAAKyb,UAA1B,EAAsC/C,CAAtC,CAAhB;MAAA,IACMpc,iBAAkC0D,EAAKyY,SAAvCnc,CADN;;MAEAoD,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoBgB,OAApBhB,CAA4B;QACpB;QAAA,IAACnD,QAAD;QAAA,IACAkM,MADA;QAENA,UAAiBjO,EAAOL,CAAPK,CAAjBiO,EACAnM,EAAWC,CAAXD,IAAuBmM,CADvBA;MACuBA,CAJzB/I;;MAQA,KAFA,IAAMod,IAAgB9c,EAAK+c,kBAAL/c,CAAwB1D,CAAxB0D,CAAtB,EACMgd,MADN,EAESvf,IAAI,CAAb,EAAgBA,IAAIsd,EAAard,MAAjC,EAAyCD,GAAzC,EAA8C;QAC5C,IAAM1C,IAAOggB,EAAatd,CAAbsd,CAAb;;QACA,KAAKze,EAAWvB,EAAKZ,IAAhBmC,CAAL,EAA4B;UAC1B,IAAMmM,IAAUhE,aAAU1J,CAAV0J,EAAgBnI,CAAhBmI,EAA4BxJ,CAA5BwJ,CAAhB;UACA,IAAIgE,aAAmB8P,OAAvB,EACE,MAAM,IAAItW,KAAJ,CACF,8BAA4BlH,EAAKmF,EAAjC,GAAiCA,gEAD/B,CAAN;UAIF5D,EAAWvB,EAAKZ,IAAhBmC,IAAwBmM,CAAxBnM,EACA0D,EAAKid,sBAALjd,CACIjF,EAAKZ,IADT6F,EACejF,CADfiF,EACqB1D,CADrB0D,EACiC/E,CADjC+E,EAC0C8c,CAD1C9c,EACyDI,CADzDJ,EAEIgd,CAFJhd,CADA1D;QAGI0gB;MAGR;;MAAA,OAAO5c,EAAQvE,GAARuE,CAAY;QAAQ,iBAAUjG,CAAVuB,EAAgBY,CAAhBZ,EAA4BT,CAA5BS;MAA4BT,CAAhDmF,CAAP;IAAuDnF,CA1BlD6O,CAAP;EA0ByD7O,CA5I3DyE,EAgJQ8b,iCAAR,UAA2BxgB,CAA3B,EAA2BA;IACzB,IAAMkiB,OAAS7d,MAAT6d,CAAgBna,KAAhBma,CAAgBna,EAAhBma,EAEFxd,OAAOe,IAAPf,CAAY1E,CAAZ0E,EACK7D,GADL6D,CACS;MAAO,SAAUiB,CAAV3F;IAAU2F,CAD1BjB,EAEK7D,GAFL6D,CAES;MAAW,SAAQ7D,GAAR4M,CAAY;QAAU,SAAOJ,EAAP;MAAOA,CAA7BI;IAA6BJ,CAFjD3I,CAFEwd,CAAN;IAKA,OAAO,IAAInD,GAAJ,CAAQmD,CAAR,CAAP;EAAeA,CAtJjBxd,EAwJQ8b,qCAAR,UACIjf,CADJ,EACsBxB,CADtB,EACkCC,CADlC,EAEIC,CAFJ,EAE+B6hB,CAF/B,EAGIK,CAHJ,EAIIH,CAJJ,EAIIA;IAGoB,cAAlBjiB,EAAKR,QAAa,IAAbA,CAA6D,CAA7DA,KAA0B4iB,EAAYxC,OAAZwC,CAAoB5gB,CAApB4gB,CAAb,KAItBniB,EAAUuB,CAAVvB,EAAoB0F,OAApB1F,CAA4B;MACZ,QAAVwJ,CAAU,KACZwY,EAAgCxY,EAAO6D,EAAvC2U,IAAuC3U,CAClC2U,EAAgCxY,EAAO6D,EAAvC2U,KAA8C,CADZ3U,IAEnCtN,EAAK6F,QAAL7F,CAAc2C,MAHN;IAGMA,CAJtB1C,GAOAD,EAAKP,MAALO,CAAY2F,OAAZ3F,CAAoB;MAGlB,IAAuB,cAAnBoG,EAAM5G,QAAV,EAAkC;QAChC,IAAMkO,IACF5L,6BAA6BsE,EAAMhH,IAAnC0C,EAAyC7B,CAAzC6B,EAAoD5B,CAApD4B,CADJ;QAEe,QAAX4L,CAAW,IACbA,EAAQ/H,OAAR+H,CAAgB;UACd,IAAIjE,MAAWsY,EAAcrC,GAAdqC,CAAkBtY,EAAO6D,EAAzByU,CAAf,EAA6C;YAC3C,IAAMM,IAAQJ,EAAgCxY,EAAO6D,EAAvC2U,CAAd;YACc,MAAVI,CAAU,IACZ5Y,EAAOkE,OAAPlE,IAAOkE,OACAsU,EAAgCxY,EAAO6D,EAAvC2U,CAFK,IAGM,QAATI,CAAS,IAGlBJ,EAAgCxY,EAAO6D,EAAvC2U,GANY;UAM2B3U;QAAAA,CAT7CI,CADa;MAUgCJ;IAAAA,CAhBnDtN,CAXsB;EA2B6BsN,CA1LrD3I,EA2MM8b,2BAAN,UAAmBhhB,CAAnB,EAA2C4F,CAA3C,EAA2CA;IAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;QAAAA;UAAAA;YAarC,OAXJ5F,IAAS8E,KAAK2c,SAAL3c,CAAe9E,CAAf8E,CAAT9E,EACA8E,KAAK4c,WAAL5c,CAAiB9E,CAAjB8E,CADA9E,EAEA8E,KAAK6c,sBAAL7c,CAA4B9E,CAA5B8E,CAFA9E,EAGA4F,IAAUd,KAAK8c,UAAL9c,CAAgBc,CAAhBd,CAHV9E,EAIA8E,KAAK+c,YAAL/c,CAAkBc,CAAlBd,CAJA9E,EAKMke,MALNle,EAMMS,IAAU,IAAI8d,gBAAJ,CAAqBzZ,KAAKmc,UAA1B,EAAsC/C,CAAtC,CANhBle,EAMsDke,IAK5CpZ,KAAK+d,sBAAL/d,CAA4B9E,CAA5B8E,EAAoCrE,CAApCqE,EAA6Cc,CAA7Cd,CAL4CoZ,CAKlD;;UAAmDtY;YAiBvD,OAlBMpF,IACFsiB,QADEtiB,EAEAuiB,IAAUnd,EAAQvE,GAARuE,CAAY;cAAQ,iBAAUjG,CAAVuB,EAAgBV,CAAhBU,EAA2BT,CAA3BS;YAA2BT,CAA/CmF,CAFVpF,EAKAwiB,IAAY,IAAIzD,GAAJ,CAAgBwD,EAAQ1hB,GAAR0hB,CAAY;cAAK,SAAElV,EAAF;YAAEA,CAAnBkV,CAAhB,CALZviB,EAMAyiB,IACF,IAAI1D,GAAJ,CAAgBra,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoB7D,GAApB6D,CAAwB;cAAQ,SAAOvF,CAAPK,EAAa6N,EAAb;YAAaA,CAA7C3I,CAAhB,CAPE1E,EAQN0E,OAAOe,IAAPf,CAAY1E,CAAZ0E,EAAuBgB,OAAvBhB,CAA+B;cACT1E,EAAU2F,CAAV3F,EACR0F,OADQ1F,CACA;gBAAAwJ,CACdA,CADcA,IACHA,EAAOkZ,UADJlZ,IACmBgZ,EAAU/C,GAAV+C,CAAchZ,EAAO6D,EAArBmV,CADnBhZ,IAEbiZ,EAAShD,GAATgD,CAAajZ,EAAO6D,EAApBoV,CAFajZ,IAEO6D,CACkB,CADlBA,KACrBrI,EAAK0b,SAAL1b,CAAe2a,OAAf3a,CAAuBwE,EAAO6D,EAA9BrI,CAHcwE,IAIhBA,EAAOkE,OAAPlE,EAJgBA;cAITkE,CALS1N;YAKT0N,CANbhJ,CARM1E,EAcO0N,IAIN6U,CAJM7U,CAIb;QA9ByCtI;MA8BlCmd,CA9BkCnd;IA8BlCmd,CA9BkCnd;EA8BlCmd,CAzOT7d,EAkPc8b,qCAAd,UACIhhB,CADJ,EAC4BS,CAD5B,EAEIkiB,CAFJ,EAEIA;IAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;MAAAA;QAAAA;UAAAA;YACI/D,IAAQ1Z,OAAOe,IAAPf,CAAYlF,CAAZkF,CAAR0Z,EACAkD,IACFlD,EAAMvd,GAANud,CAAU;cAAQ,SAAK7a,KAALyB,CAAWD,KAAXC,CAAiB/C,cAAc9C,CAAd8C,EAAoB,CAApBA,CAAjB+C;YAAqC,CAAvDoZ,CAFEA,EAGAmD,IACFY,EAAYthB,GAAZshB,CAAgB;cAAQ,SAAK5e,KAALyB,CAAWD,KAAXC,CAAiB/C,cAAc9C,CAAd8C,EAAoB,CAApBA,CAAjB+C;YAAqC,CAA7Dmd,CAJE/D,EAKAkE,IACFzD,qBAAqBrf,CAArBqf,EAA6B0C,CAA7B1C,EAA0Cva,KAAKmZ,SAA/CoB,CANET,EAKCU,eALDV,EAKYY,mBALZZ,EAK2Ba,iBAL3Bb,EAKwCc,gBALxCd,EAQAhQ,IACEkT,SAAehd,KAAKf,KAALe,CAAWQ,OAA1Bwc,EAAmCzgB,GAAnCygB,CAAuC;cACzC;gBAAQvhB,OAAR;gBAAcie,UAAU/d,EAAQ0iB;cAAhC;YAAgCA,CAD9BrB,CATFlD,EAYA9c,iBAAkCgD,KAAKmZ,SAAvCnc,CAZA8c,EAaN1Z,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoBgB,OAApBhB,CAA4B;cACpB;cAAA,IAACnD,QAAD;cAAA,IACAkM,MADA;cAENA,UAAiBjO,EAAOL,CAAPK,CAAjBiO,EACAnM,EAAWC,CAAXD,IAAuBmM,CADvBA;YACuBA,CAJzB/I,CAbM0Z,EAmBA4D,MAnBA5D,EAoBA0D,IAAgBxd,KAAKyd,kBAALzd,CAAwBhD,CAAxBgD,CApBhB8Z,EAqBAwE,MArBAxE,EAqBAwE,WArBAxE;;UAqBAwE;YAAAA,OACCxU,EAAM1L,MAAN0L,GAAe,CAAfA,IACCyU,IAAWve,KAAKwe,YAALxe,CACbgd,CADahd,EACD8J,CADC9J,EACMrE,CADNqE,EACehD,CADfgD,EAC2Bse,CAD3Bte,EACkCwd,CADlCxd,EAEb6d,CAFa7d,EAEA0d,CAFA1d,EAEiCwa,CAFjCxa,CAAXue,EAE4C/D,IAC5CvB,QAAQwF,GAARxF,CAAYsF,CAAZtF,CAD4CuB,CAH7C1Q,IAIayU,MALdD;;UAKcC;YAAAA,OAAlB/S,gBAAkB+S;;UAAlB/S;YAaF,IAXmB,QAAfmP,CAAe,IACjBjI,QAAQC,IAARD,CACI,iIADJA,CADiB,EAEb,CAGAgM,IACFzB,EACKtO,MADLsO,CAEQ;cAAQ,QAAChC,cAAcxf,CAAdwf,CAAD,IAAexf,CAClBW,UAAUX,EAAKZ,IAAfuB,EAAqBY,CAArBZ,EAAiCT,CAAjCS,CADG;YAC8BT,CAH9CshB,EAIK1gB,GAJL0gB,CAIS;cAAQ,SAAKpiB,IAAL;YAAKA,CAJtBoiB,CAJE,EASa7e,MATb,GASsB,CAA5B,EAOE,MANIugB,IAAiB,EAAjBA,EACe,QAAfhE,CAAe,KACjBgE,IACI,0FAC2B/D,CAD3B,GAC2BA,GAHd,CADf+D,EAME,IAAIhc,KAAJ,CACF,iCAA+B+b,CAA/B,GAA+BA,8BAA/B,GACW5E,CADX,GACWA,+CADX,GAEIY,CAFJ,GAEIA,KAFJ,GAEuBiE,CAHrB,CAAN;YAKF,WAAO3hB,CAAP;QApDE6gB;MAoDK7gB,CApDL6gB;IAoDK7gB,CApDL6gB;EAoDK7gB,CAxSToD,EA2SQ8b,2BAAR,UACIc,CADJ,EACwBlT,CADxB,EACmDnO,CADnD,EAEID,CAFJ,EAEgC4iB,CAFhC,EAGId,CAHJ,EAGgCK,CAHhC,EAIIH,CAJJ,EAKIlD,CALJ,EAKIA;IAEF,KAPF,cAMQ+D,MANR,EAMQA;MAEJ,IAAMK,IAAO9U,EAAMkR,GAANlR,EAAb;MACAnO,EAAQ0iB,cAAR1iB,GAAyBijB,EAAKlF,QAA9B/d;MACA,IAAIsB,IAAW,EAAf;;MAUA,IANqB,YAAjB2hB,EAAKnjB,IAALmjB,CAAUhe,EAAO,IACjBrF,cAAc,YAAdA,EAA4BqjB,EAAKnjB,IAAjCF,EAAuCG,CAAvCH,EAAkDI,CAAlDJ,CADiB,KAElB0B,0CAFkB,GAElBA,CAIoC,CAJpCA,KAIC+f,EAAW3B,OAAX2B,CAAmB4B,EAAKnjB,IAAxBuhB,CAAJ,EAA0C;QACxC,IAAM7T,IAAUhE,aAAUyZ,EAAKnjB,IAAf0J,EAAqBzJ,CAArByJ,EAAgCxJ,CAAhCwJ,CAAhB;QACKlI,MACFA,0CADEA;QAGL,IAAM4hB,IAAiBljB,EAAQ0iB,cAA/B;QACIlV,aAAmB8P,OAAnB9P,GACFoV,EAASlgB,IAATkgB,CAAcpV,EAAQ+P,IAAR/P,CAAa;UAQzB,OAPAzN,EAAUuB,CAAVvB,IAAsB+N,CAAtB/N,EACAC,EAAQ0iB,cAAR1iB,GAAyBkjB,CADzBnjB,EAEAgF,EAAKid,sBAALjd,CACIzD,CADJyD,EACcke,EAAKnjB,IADnBiF,EACyBhF,CADzBgF,EACoC/E,CADpC+E,EAC6C8c,CAD7C9c,EAEImd,CAFJnd,EAEiBgd,CAFjBhd,CAFAhF,EAKAgF,EAAKoe,iBAALpe,CACIke,EAAKnjB,IADTiF,EACeoJ,CADfpJ,EACsB/E,CADtB+E,EAC+BhF,CAD/BgF,EAC0C4d,CAD1C5d,EACiD8Z,CADjD9Z,CALAhF,EAOO+N,CAAP;QAAOA,CARKN,CAAdoV,CADEpV,IAYFzN,EAAUuB,CAAVvB,IAAsByN,CAAtBzN,EACAqjB,EAAKpB,sBAALoB,CACI9hB,CADJ8hB,EACcH,EAAKnjB,IADnBsjB,EACyBrjB,CADzBqjB,EACoCpjB,CADpCojB,EAC6CvB,CAD7CuB,EAEIlB,CAFJkB,EAEiBrB,CAFjBqB,CADArjB,EAIAqjB,EAAKD,iBAALC,CACIH,EAAKnjB,IADTsjB,EACejV,CADfiV,EACsBpjB,CADtBojB,EAC+BrjB,CAD/BqjB,EAC0CT,CAD1CS,EACiDvE,CADjDuE,CAhBE5V;MAiB+CqR,CAvBrD,MA0BEuE,EAAKD,iBAALC,CACIH,EAAKnjB,IADTsjB,EACejV,CADfiV,EACsBpjB,CADtBojB,EAC+BrjB,CAD/BqjB,EAC0CT,CAD1CS,EACiDvE,CADjDuE;IACiDvE,CA/CvD,EA+CuDA,QAxCrD,EAAO1Q,EAAM1L,MAAN0L,GAAe,CAAtB,GAAsBkV;;IA2CtB,OAAOT,CAAP;EAAOA,CA7VTne,EAgWQ8b,gCAAR,UACIzgB,CADJ,EACgBqO,CADhB,EAC2CnO,CAD3C,EAEID,CAFJ,EAEgC4iB,CAFhC,EAGI9D,CAHJ,EAGIA;IACF/e,EAAK6F,QAAL7F,CAAc2F,OAAd3F,CAAsB,UAACwjB,CAAD,EAACA;MACd;MAAAhiB,CACHqhB,EAAMrhB,CAANqhB,CADGrhB,IACiBud,EAAUW,GAAVX,CAAcyE,EAAUpkB,IAAxB2f,CADjBvd,KAKc,YAAjBgiB,EAAUre,EAAO,GACfqe,EAAU5iB,UAAV4iB,CAAqBC,IAArBD,CAA0B;QACxB,SAAS7iB,UAAUvB,CAAVuB,EAAgBV,CAAhBU,EAA2BT,CAA3BS,CAAT;MAAoCT,CADtCsjB,MAGFX,EAAMrhB,CAANqhB,IAAMrhB,CAAY,CAAlBqhB,EACAxU,EAAMzL,IAANyL,CAAMzL;QAAMqb,UAAU/d,EAAQ0iB,cAAxBhgB;QAAwC5C,MAAMwjB;MAA9C5gB,CAANyL,CAJEmV,CADe,GAQbA,EAAU5iB,UAAV4iB,CAAqBtD,KAArBsD,CAA2B;QACzB,SAAS7iB,UAAUvB,CAAVuB,EAAgBV,CAAhBU,EAA2BT,CAA3BS,CAAT;MAAoCT,CADtCsjB,MAGNX,EAAMrhB,CAANqhB,IAAMrhB,CAAY,CAAlBqhB,EACAxU,EAAMzL,IAANyL,CAAMzL;QAAMqb,UAAU/d,EAAQ0iB,cAAxBhgB;QAAwC5C,MAAMwjB;MAA9C5gB,CAANyL,CAJMmV,CAbDhiB;IAiB+CgiB,CAlBxDxjB;EAkBwDwjB,CAtX1D7e,EA8XA8b;IAAA;IACE9b,OAAOe,IAAPf,CAAYJ,KAAKmZ,SAAjB/Y,EACKgB,OADLhB,CAEQ;MAAO,SAAK+Y,SAALzY,CAAeW,CAAfX,EAAoBU,OAApBV,CAA4B;QAAU,SAAO0I,OAAPlE;MAAOkE,CAA7C1I;IAA6C0I,CAF5DhJ;EAE4DgJ,CAjY9DhJ,EAoYQ8b,qCAAR,UAA+BhhB,CAA/B,EAA+BA;IAA/B;IACEkF,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoBgB,OAApBhB,CAA4B;MAC1B,IAAMyB,IAAQ3G,EAAOL,CAAPK,CAAd;MAAA,IACO+B,uBADP;MAAA,IAEMxB,IAAOiF,EAAKzB,KAALyB,CAAWD,KAAXC,CAAiBzD,CAAjByD,CAFb;;MAGA,IAAIjF,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,IAA4BA,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,CAAyBsB,KAAzD,EAAgE;QAC9D,IAAMoiB,IAAQ1jB,EAAKqB,UAALrB,CAAuBmJ,KAAvBnJ,CAAyBsB,KAAvC;QAAA,IACMqiB,IAAQD,EAAM/gB,MAAN+gB,KAAiBtd,EAAM+C,KAAN/C,CAAYzD,MAA7B+gB,IACVtd,EAAM+C,KAAN/C,CAAY8Z,KAAZ9Z,CACI,UAACiD,CAAD,EAAM5H,CAAN,EAAMA;UAAU,QAAkB,CAAlB,OAAMA,CAANiiB,KAAuBA,EAAMjiB,CAANiiB,MAAiBra,CAAxC;QAAwCA,CAD5DjD,CAFJ;QAIAkJ,KAAKC,MAALD,CACIqU,CADJrU,EAEI;UAAM,+BAAsBtP,EAAKZ,IAA3B,GAA2BA,8CAA3B,GAC8BskB,CAD9B,GAC8BA,cAD9B,GAEEtd,EAAM+C,KAFR,GAEQA,GAFR;QAEQA,CAJlBmG;MAMEtP;;MAAAA,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,IAA4BA,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,CAAyBsB,KAArDtB,IACFsP,KAAKC,MAALD,CACIlJ,EAAM4G,KAAN5G,KAAgBpG,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,CAAyBsB,KAD7CgO,EAEI;QAAM,+BAAsBtP,EAAKZ,IAA3B,GAA2BA,6CAA3B,GAECY,EAAKqB,UAALrB,CAAuBgN,KAAvBhN,CAAyBsB,KAF1B,GAE0BA,YAF1B,GAE4C8E,EAAM4G,KAFlD;MAEkDA,CAJ5DsC,CADEtP;IAK0DgN,CApBhErI;EAoBgEqI,CAzZlErI,EA8ZQ8b,wBAAR,UAAkBhhB,CAAlB,EAAkBA;IAChB,IAAMuW,MAAN;;IACA,KAAK,IAAM/T,CAAX,IAAwBxC,CAAxB,EAAgC;MAC9B,IAAuB,QAAnB8E,KAAKic,UAAc,IAAkC,QAA1Bjc,KAAKic,UAALjc,CAAgB9E,MAAxB,IACkB,QAArC8E,KAAKic,UAALjc,CAAgB9E,MAAhB8E,CAAuBtC,CAAvBsC,CADJ,EAGEyR,EADezR,KAAKic,UAALjc,CAAgB9E,MAAhB8E,CAAuBtC,CAAvBsC,EACDnF,IAAd4W,IAAsBvW,EAAOwC,CAAPxC,CAAtBuW,CAHF,KAKEA,EAAO/T,CAAP+T,IAAoBvW,EAAOwC,CAAPxC,CAApBuW;IAGJ;;IAAA,OAAOA,CAAP;EAAOA,CAzaTrR,EA4aQ8b,0BAAR,UAAoBhhB,CAApB,EAAoBA;IAApB;IAAA,IACQmkB,IAAajf,OAAOe,IAAPf,CAAYlF,CAAZkF,EAAoBuO,MAApBvO,CAA2B;MACrC;MACP,OAAqC,QAA9BM,EAAKzB,KAALyB,CAAWD,KAAXC,CAAiBzD,CAAjByD,CAAP;IAAwBzD,CAFPmD,CADrB;IAKE,IAAIif,EAAWjhB,MAAXihB,GAAoB,CAAxB,EACE,MAAM,IAAI1c,KAAJ,CACF,yDACU0c,CADV,GACUA,8BAFR,CAAN;EAEcA,CApblBjf,EAwbQ8b,yBAAR,UAAmBpb,CAAnB,EAAmBA;IAAnB;IACE,OAAOA,EAAQvE,GAARuE,CAAY;MACjB,OAAuB,QAAnBJ,EAAKub,UAAc,IAAmC,QAA3Bvb,EAAKub,UAALvb,CAAgBI,OAAxB,IACc,QAAjCJ,EAAKub,UAALvb,CAAgBI,OAAhBJ,CAAwB7F,CAAxB6F,CADmB,GAENA,EAAKub,UAALvb,CAAgBI,OAAhBJ,CAAwB7F,CAAxB6F,EACD7F,IAHO,GAKhBA,CALP;IAKOA,CANFiG,EAMEjG,EANFiG,CAAP;EAMSjG,CA/bXuF,EAkcQ8b,2BAAR,UAAqBpb,CAArB,EAAqBA;IAArB;IACEA,EAAQM,OAARN,CAAgB;MACP;MACP,KAAKJ,EAAKzB,KAALyB,CAAWD,KAAXC,CAAiB4e,CAAjB5e,CAAL,EACE,MAAM,IAAIiC,KAAJ,CAAU,iBAAe9H,CAAf,GAAeA,6BAAzB,CAAN;IAA+BA,CAHnCiG;EAGmCjG,CAtcrCuF,EAscqCvF,CAIvC;AAJuCA,CDnWQ;AAAA,IEnHlC0kB,qBAAqB,mBFmHa;AAAA,IElHlCC,qBAAqB,YFkHa;AAAA,IElHbC;EAiDhC,WACYC,CADZ,EAEYC,CAFZ,EAEYA;IAAAA,0BADA3f,iBACA2f,wBAvCJ3f,eAAU,KAuCN2f,EACS,QAAfA,CAAe,KACjB3f,KAAK2f,WAAL3f,GAAK2f,EADY,CADTA;EA4Pd;;EAAA,OA/REvf,sBAAIqf,WAAJrf,EAAIqf,cAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK4f,OAAZ;IAAYA,CADVH;IACUG,cADVH;IACUG;EADVH,CAAJrf,GAIAA,sBAAIqf,WAAJrf,EAAIqf,YAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK6f,QAAL7f,CAAcgd,UAArB;IAAqBA,CADnByC;IACmBzC,cADnByC;IACmBzC;EADnByC,CAAJrf,CAJAA,EAQAA,sBAAIqf,WAAJrf,EAAIqf,aAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK6f,QAAL7f,CAAcid,WAArB;IAAqBA,CADnBwC;IACmBxC,cADnBwC;IACmBxC;EADnBwC,CAAJrf,CARAA,EAYAA,sBAAIqf,WAAJrf,EAAIqf,QAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK6f,QAAL7f,CAAc9E,MAArB;IAAqBA,CADnBukB;IACmBvkB,cADnBukB;IACmBvkB;EADnBukB,CAAJrf,CAZAA,EAgBAA,sBAAIqf,WAAJrf,EAAIqf,SAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK6f,QAAL7f,CAAcc,OAArB;IAAqBA,CADnB2e;IACmB3e,cADnB2e;IACmB3e;EADnB2e,CAAJrf,CAhBAA,EAoBAA,sBAAIqf,WAAJrf,EAAIqf,SAAJrf,EAAIqf;IAAAA,KAAJ;MACE,OAAOzf,KAAK6f,QAAL7f,CAAcmZ,SAArB;IAAqBA,CADnBsG;IACmBtG,cADnBsG;IACmBtG;EADnBsG,CAAJrf,CApBAA,EAyCQqf,4BAAR;IACE,IAAMK,IAAO9f,KAAK0f,QAAlB;IACA,IAAmC,QAA9BI,EAAsBC,IAA3B,EAEE/f,KAAKggB,OAALhgB,GAAe8f,CAAf9f,CAFF,KAGO,IAAoC,QAAhCA,KAAK2f,WAAL3f,CAAiBigB,WAArB,EACLjgB,KAAKggB,OAALhgB,GAAekgB,GAAGC,kBAAHD,CAAsBJ,CAAtBI,EAAsClgB,KAAK2f,WAA3CO,CAAflgB,CADK,KAEA;MACL,IAAMogB,IACFF,GAAGG,eAAHH,CAAmBJ,CAAnBI,EAAmClgB,KAAK2f,WAAL3f,CAAiBsgB,UAApDJ,CADJ;MAEA,IAAwB,MAApBE,EAAShiB,MAAb,EAGEgiB,EAAS/hB,IAAT+hB,CAAcF,GAAGC,kBAAHD,CAAsBJ,CAAtBI,EAAsClgB,KAAK2f,WAA3CO,CAAdE,EAHF,KAIO,IAAIA,EAAShiB,MAATgiB,GAAkB,CAAtB,EACL,MAAM,IAAIzd,KAAJ,CACF,0BAAwByd,EAAShiB,MAAjC,GAAiCA,2BAAjC,GAAiCA,CACxB0hB,CADwB1hB,CAAjC,GACS0hB,GAFP,CAAN;MAIF9f,KAAKggB,OAALhgB,GAAeogB,EAAS,CAATA,CAAfpgB;IAAwB;EAAA,CA5D5BI,EAoEMqf,mBAAN;IAAA;MAAA;MAAA;QAAA;UAAA;YAEE,IADAzf,KAAKugB,aAALvgB,IACyB,QAArBA,KAAKggB,OAALhgB,CAAa+f,IAAjB,EACE,MAAM,IAAIpd,KAAJ,CACF,+GADE,CAAN;YAIe,OAAjBqb,cAAuBhe,KAAKggB,OAALhgB,CAAa+f,IAAb/f,EAAvBA,CAAiB;;UAAmB+f;YAepC,OAfA/B,EAAKwC,SAALxC,GAAiBxS,QAAjBwS,EACM/e,IAAQe,KAAKwgB,SAALxgB,CAAeygB,aAD7BzC,EAEI1d,MAFJ0d,EAG0C,QAAtChe,KAAKwgB,SAALxgB,CAAe0gB,mBAAuB,KACxCpgB,IACKN,KAAKwgB,SAALxgB,CAAe0gB,mBAAf1gB,CAA2CM,SAFR,CAH1C0d,EASAhe,KAAK4f,OAAL5f,GAAkBf,EAAM0hB,QAAN1hB,CAAe2hB,QAAf3hB,GAAe2hB,GAAf3hB,GAA2BA,EAAM0hB,QAAN1hB,CAAe4hB,WAT5D7C,EAUM7E,IACF+G,GAAGY,aAAHZ,CAAiBlgB,KAAKwgB,SAALxgB,CAAe+gB,UAAhCb,EAA4ClgB,KAAKwgB,SAALxgB,CAAeghB,WAA3Dd,CAXJlC,EAYAhe,KAAK6f,QAAL7f,GAAgB,IAAIkc,aAAJ,CACZvc,gBAAgBshB,QAAhBthB,CAAyBuhB,cAAzBvhB,CAAwCV,CAAxCU,EAA+CW,CAA/CX,CADY,CAZhBqe,EAcAhe,KAAK6f,QAAL7f,CAAcmZ,SAAdnZ,GAA0BA,KAAKmhB,4BAALnhB,CAAkCmZ,CAAlCnZ,CAd1Bge,EAc4D7E,KACrD,CADqDA,CAC5D;QAtBF;MAsBS,CAtBT;IAsBS,CAtBT;EAsBS,CA1FT/Y,EA0IMqf,mBAAN,UAAW2B,CAAX,EAA8CC,CAA9C,EAA8CA;IAAAA;MAAAA;MAAAA;QAE5C,IAA4B,mBAAjBD,CAAX,EAAsC;UAEpC,IAAwB,OADlBhB,IAAWF,GAAGoB,eAAHpB,CAAmBkB,CAAnBlB,CACO,EAAX9hB,MAAb,EACE,MAAM,IAAIuE,KAAJ,CACF,4CAA0Cye,CAA1C,GAA0CA,GADxC,CAAN;UAEK,IAAIhB,EAAShiB,MAATgiB,GAAkB,CAAtB,EACL,MAAM,IAAIzd,KAAJ,CACF,0BAAwByd,EAAShiB,MAAjC,GAAiCA,2BAAjC,GACQgjB,CADR,GACQA,GAFN,CAAN;UAIFA,IAAehB,EAAS,CAATA,CAAfgB;QAEF;;QAAA,IAAyB,QAArBA,EAAaG,IAAjB,EACE,MAAM,IAAI5e,KAAJ,CACF,6GADE,CAAN;QAKF,WAAOye,EAAaG,IAAbH,CAAkBphB,KAAKwgB,SAAvBY,CAAP;MAA8BZ,CApBca;IAoBdb,CApBca;EAoBdb,CA9JhCpgB,EAsMAqf,gCAAQvkB,CAAR,EAAgDmmB,CAAhD,EAAgDA;IAE9C,OAAOrhB,KAAKwhB,OAALxhB,CAAa9E,CAAb8E,EAAqBA,KAAKid,WAA1Bjd,CAAP;EAAiCid,CAxMnC7c,EA2MQqf,8BAAR,UAAwBvkB,CAAxB,EAAwBA;IAEtB,MAAMA,aAAkBumB,MAAlBvmB,IAA8BuB,MAAM6G,OAAN7G,CAAcvB,CAAduB,CAApC,GAEE,OAAOvB,CAAP;IAGF,KADAA,IAASuB,MAAM6G,OAAN7G,CAAcvB,CAAduB,IAAwBvB,CAAxBuB,GAAwBvB,CAAUA,CAAVA,CACjC,EAAWkD,MAAX,KAAsB4B,KAAKgd,UAALhd,CAAgB5B,MAAtC,EACE,MAAM,IAAIuE,KAAJ,CACF,qDACuB3C,KAAKgd,UAALhd,CAAgB5B,MADvC,GACuCA,iCADvC,GAEmBlD,EAAOkD,MAF1B,GAE0BA,iBAHxB,CAAN;IAKF,OAAO4B,KAAKgd,UAALhd,CAAgBE,MAAhBF,CAAuB,UAACzD,CAAD,EAAMmB,CAAN,EAAiBS,CAAjB,EAAiBA;MAE7C,OADA5B,EAAImB,CAAJnB,IAAkBrB,EAAoBiD,CAApBjD,CAAlBqB,EACOA,CAAP;IAAOA,CAFFyD,EAEEzD,EAFFyD,CAAP;EAESzD,CA1NX6D,EA8NQqf,+BAAR,UAAyB3e,CAAzB,EAAyBA;IAEvB,OADAA,IAAUA,KAAWd,KAAKid,WAA1Bnc,EACQrE,MAAM6G,OAAN7G,CAAcqE,CAAdrE,IAAqCqE,CAArCrE,GAAqCqE,CAAXA,CAAWA,CAA7C;EAAkCA,CAhOpCV,EAkPAqf,gCAAQvkB,CAAR,EAAgD4F,CAAhD,EAAgDA;IAE9C5F,IAAS8E,KAAK0hB,eAAL1hB,CAAqB9E,CAArB8E,CAAT9E,EACA4F,IAAUd,KAAK2hB,gBAAL3hB,CAAsBc,CAAtBd,CADV9E;IAEA,IAAMuW,IAASzR,KAAK6f,QAAL7f,CAAcwhB,OAAdxhB,CAAsB9E,CAAtB8E,EAA8Bc,CAA9Bd,CAAf;IACA,OAAOyR,EAAOrT,MAAPqT,GAAgB,CAAhBA,GAAoBA,CAApBA,GAA6BA,EAAO,CAAPA,CAApC;EAA2C,CAvP7CrR,EAwQMqf,2BAAN,UACIvkB,CADJ,EAEI4F,CAFJ,EAEIA;IAAAA;MAAAA;MAAAA;QAAAA;UAAAA;YAGa,OAFf5F,IAAS8E,KAAK0hB,eAAL1hB,CAAqB9E,CAArB8E,CAAT9E,EACA4F,IAAUd,KAAK2hB,gBAAL3hB,CAAsBc,CAAtBd,CADV9E,EACgC4F,IACXd,KAAK6f,QAAL7f,CAAc4hB,YAAd5hB,CAA2B9E,CAA3B8E,EAAmCc,CAAnCd,CADWc,CACjB;;UAAyCA;YACxD,YADM2Q,IAASuM,QACf,EAAc5f,MAAd,GAAuB,CAAvB,GAA2BqT,CAA3B,GAAoCA,EAAO,CAAPA,CAApC;QAJE3Q;MAIyC,CAJzCA;IAIyC,CAJzCA;EAIyC,CA9Q7CV,EAiRQqf,2CAAR,UAAqCljB,CAArC,EAAqCA;IACnC,OAAO6D,OAAOe,IAAPf,CAAY7D,CAAZ6D,EAAiBF,MAAjBE,CAAwB,UAACyhB,CAAD,EAA0BxgB,CAA1B,EAA0BA;MAEvD,OADAwgB,EAAOxgB,CAAPwgB,IAAOxgB,CAAQ9E,EAAI8E,CAAJ9E,CAAR8E,CAAPwgB,EACOA,CAAP;IAAOA,CAFFzhB,EAEEyhB,EAFFzhB,CAAP;EAESyhB,CApRXzhB,EA4RAqf;IACEzf,KAAK6f,QAAL7f,CAAcoJ,OAAdpJ;EAAcoJ,CA7RhBhJ,EA6RgBgJ,CAElB;AAFkBA,CA7SgB,EFkHa;;AE4N/C,SAAsB0Y,cAAtB,CACIpC,CADJ,EAEIqC,CAFJ,EAEIA;EAAAA;IAAAA;IAAAA;MAAAA;QAAAA;UACF,IAAgB,QAAZrC,CAAJ,EACE,MAAM,IAAI/c,KAAJ,CACF,wGADE,CAAN;UAiBF,OAbe,QAAXof,CAAW,KACbA,MADa,GAIXA,EAAQC,SAARD,IACqC,QAAlCrC,EAA0BK,IAD7BgC,KAEMrC,EAAoBuC,QAApBvC,CAA6B,GAA7BA,MACJA,KAAkC,GAD9BA,GAGNA,IAAW,KAAGA,CAAH,GAAcF,kBAAd,GAAmCD,kBAL9CwC,CAJW,EASmCxC,KAG5C2C,IAAQ,IAAIzC,UAAJ,CAAeC,CAAf,EAAyBqC,CAAzB,CAHoCxC,EAItCQ,IAJsCR,GAIlD;;QAAYQ;UACZ,OADA/B,cACOkE,CADPlE,CACA;MApBE+D;IAoBKG,CApBLH;EAoBKG,CApBLH;ACvWJ;;AAAA,IAAMnC,UAAU,OAAhB;AAAgB","names":["DataType","SaverDef","CheckpointFormatVersion","CUSTOM_OPS","registerOp","name","opFunc","opMapper","tfOpName","category","inputs","attrs","customExecutor","getRegisteredOp","deregisterOp","getParamValue","paramName","node","tensorMap","context","inputParam","inputParams","undefined","inputIndexStart","start","end","inputIndexEnd","type","getTensor","inputNames","slice","map","data","Array","prototype","call","dataSync","attrParam","attrParams","value","tensorsMap","nodeName","index","contextId","currentContextIds","find","getNodeNameWithContextId","getTensorsForCurrentContenxt","currentContextId","getNodeNameAndIndex","inputName","parseNodeName","lastIndexOf","substring","Number","split","arr","size","res","i","length","push","json","tfName","notSupported","arithmetic","defaultValue","basicMath","control","convolution","creation","dynamic","evaluation","graph","image$1","logical","matrices","normalization","reduction","sliceJoin","spectral","tfDeprecatedName","transformation","OperationMapper","ops","image","mappersJson","concat","this","opMappers","reduce","mapper","Object","_instance","signature","placeholders","weights","nodes","_this","mapNode","op","startsWith","outputs","inputNodeNameToKey","outputNodeNameToKey","mapSignatureEntries","allNodes","keys","forEach","key","children","signatureKey","entries","prev","curr","attr","newNode","input","substr","rawAttrs","param","getStringParam","getStringArrayParam","getNumberParam","getNumericArrayParam","getBoolParam","getBoolArrayParam","getTensorShapeParam","getTensorShapeArrayParam","getDtypeParam","getDtypeArrayParam","Error","decodeBase64","text","global","env","atob","Buffer","toString","parseStringParam","s","keepCase","isArray","String","fromCharCode","apply","toLowerCase","def","b","f","parseInt","parseDtypeParam","tensorflow.DataType","DT_FLOAT","DT_INT32","DT_INT64","DT_INT8","DT_UINT8","DT_BOOL","DT_DOUBLE","DT_STRING","list","v","parseTensorShapeParam","shape","unknownRank","dim","getInput","getAttr","NodeValueImpl","tensor","executeOp","tfc.add","tfc.addN","tfc.mod","tfc.mul","tfc.div","tfc.divNoNan","tfc.floorDiv","tfc.sub","tfc.minimum","tfc.maximum","tfc.pow","tfc.squaredDifference","TypeError","tfc.abs","tfc.acos","tfc.acosh","tfc.asin","tfc.asinh","tfc.atan","tfc.atan2","tfc.atanh","tfc.ceil","tfc.complex","tfc.cos","tfc.cosh","tfc.elu","tfc.erf","tfc.exp","tfc.expm1","tfc.floor","tfc.log","tfc.log1p","tfc.imag","tfc.neg","tfc.reciprocal","tfc.real","tfc.relu","tfc.round","tfc.selu","tfc.sigmoid","tfc.sin","tfc.sign","tfc.sinh","tfc.softplus","tfc.sqrt","tfc.square","tfc.tanh","tfc.tan","tfc.clipByValue","tfc.rsqrt","tfc.prod","tfc.leakyRelu","tfc.prelu","dtype","maxSize","elementShape","identicalElementShapes","dynamicSize","clearAfterRead","id","TensorArray","nextId","closed_","tensors","dispose","tensorWithState","cleared","read","indices","t","assertShapesMatchAllowUndefinedSize","written","write","readMany","stack","maxIndex","Math","max","writeMany","unstack","totalLength","cumulativeLengths","len","elementPerRow","tidy","reshape","indices_1","sizes","shapeA","shapeB","errorMessagePrefix","util","assert","shapesEqualAllowUndefinedSize","n1","n2","e","clone","pred","data_1","_b","frameId","enterFrame","exitFrame","nextIteration","name_1","tensorArray","addTensorArray","scalar","writeTensor","getTensorArray","readId","readIndex","gatherId","gatherIndices","gatherDtype","gather","scatterId","scatterIndices","scatterTensor","scatter","concatId","concatTensorArray","concatDtype","splitId","splitTensor","lengths","sizeId","sizeTensorArray","closeId","clearAndClose","stride","pad","dataFormat","toUpperCase","dilation","tfc.conv1d","dilations","tfc.conv2d","extraOp","activationFunc","isBiasAdd","isPrelu","isBatchNorm","numArgs","biasArg","preluArg","tfc.fused","conv2d","depthwiseConv2d","x","filter","strides","bias","activation","preluActivationWeights","tfc.conv2dTranspose","tfc.depthwiseConv2d","tfc.conv3d","kernelSize","tfc.avgPool","tfc.maxPool","includeBatchInIndex","_c","tfc.avgPool3d","tfc.maxPool3d","tfc.fill","stop_1","num","tfc.linspace","logits","numSamples","seed","tfc.multinomial","depth","onValue","offValue","tfc.oneHot","tfc.ones","tfc.onesLike","tfc.randomUniform","stop_2","step","tfc.range","mean","stdDev","tfc.truncatedNormal","tfc.zeros","tfc.zerosLike","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","tfc.image","nonMaxSuppressionWithScoreAsync","result","selectedIndices","selectedScores","nonMaxSuppressionAsync","condition","asType","tfc.whereAsync","tfc.setdiff1dAsync","k","sorted","tfc.topk","values","tfc.tensor1d","tfc.scalar","rank","message","summarize","console","warn","log","images","alignCorners","resizeBilinear","resizeNearestNeighbor","boxInd","cropSize","method","extrapolationValue","cropAndResize","tfc.equal","tfc.notEqual","tfc.greater","tfc.greaterEqual","tfc.less","tfc.lessEqual","tfc.logicalAnd","tfc.logicalNot","tfc.logicalOr","tfc.where","tfc.matMul","tfc.transpose","matMul","a","transposeA","transposeB","tfc.batchNorm","tfc.localResponseNormalization","tfc.softmax","tfc.logSoftmax","tfc.sparseToDense","axis","keepDims","tfc.max","tfc.mean","tfc.min","tfc.sum","tfc.all","tfc.any","tfc.argMax","tfc.argMin","n","tfc.concat","tfc.gather","tfc.reverse","begin","tfc.slice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","tfc.stridedSlice","tfc.tidy","squeezedShape","squeeze","mapped","sameShape","tfc.util","arraysEqual","tfc.stack","tfc.unstack","reps","tfc.tile","numOrSizeSplits","tfc.split","tfc.scatterND","tfc.gatherND","sparseValues","tfc.fft","tfc.ifft","tfc.rfft","tfc.irfft","tfc.cast","tfc.expandDims","tfc.squeeze","tfc.reshape","tfc.pad","blockShape","paddings","tfc.spaceToBatchND","crops","tfc.batchToSpaceND","blockSize","tfc.depthToSpace","arithmetic.executeOp","basicMath.executeOp","control.executeOp","convolution.executeOp","creation.executeOp","dynamic.executeOp","evaluation.executeOp","image.executeOp","graph.executeOp","logical.executeOp","matrices.executeOp","normalization.executeOp","reduction.executeOp","sliceJoin.executeOp","spectral.executeOp","transformation.executeOp","Promise","then","weightMap","tensorArrayMap","frameName","iterationId","rootContext","generateCurrentContextIds","ExecutionContext","contexts","_currentContextIds","enumerable","configurable","names","contextIdforContexts","join","lastId","newFrame","unshift","splice","shift","assign","getExecutionSubgraph","usedNodes","Set","missingInputs","dynamicNode","syncInputs","seen","inputNodeNames","frontier","pop","isControlFlow","isDynamicShape","has","add","indexOf","getNodesInTopologicalOrder","executionInfo","weight","orderedNodes","child","every","CONTROL_FLOW_OPS","DYNAMIC_SHAPE_OPS","Map","_outputs","_inputs","_signature","GraphExecutor","_weightMap","weightIds","sortedInputs","sort","sortedOutputs","SEPERATOR","outNames","inNames","mapInputs","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","inputNodes","outputNodes","compilationKey","getCompilationKey","compiledMap","get","compile","set","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","checkTensorForDisposal","ids","outputNames","count","executeWithControlFlow","_a","results","outputIds","inputIds","isDisposed","currentContext","added","promises","processStack","all","missingOutputs","alternativeMsg","item","currentContext_1","processChildNodes","this_1","l","childNode","some","shape_1","match","notInGraph","normalizedName","TFHUB_SEARCH_PARAM","DEFAULT_MODEL_NAME","GraphModel","modelUrl","loadOptions","version","executor","path","load","handler","requestInit","io","browserHTTPRequest","handlers","getLoadHandlers","onProgress","findIOHandler","artifacts","modelTopology","userDefinedMetadata","versions","producer","minConsumer","decodeWeights","weightData","weightSpecs","Instance","transformGraph","convertTensorMapToTensorsMap","handlerOrURL","config","getSaveHandlers","save","execute","Tensor","normalizeInputs","normalizeOutputs","executeAsync","newMap","loadGraphModel","options","fromTFHub","endsWith","model"],"sources":["../src/data/compiled_api.ts","../src/operations/custom_op/register.ts","../src/operations/executors/utils.ts","../src/operations/op_list/arithmetic.ts","../src/operations/op_list/basic_math.ts","../src/operations/op_list/control.ts","../src/operations/op_list/convolution.ts","../src/operations/op_list/creation.ts","../src/operations/op_list/dynamic.ts","../src/operations/op_list/evaluation.ts","../src/operations/op_list/graph.ts","../src/operations/op_list/image.ts","../src/operations/op_list/logical.ts","../src/operations/op_list/matrices.ts","../src/operations/op_list/normalization.ts","../src/operations/op_list/reduction.ts","../src/operations/op_list/slice_join.ts","../src/operations/op_list/spectral.ts","../src/operations/op_list/transformation.ts","../src/operations/operation_mapper.ts","../src/operations/custom_op/node_value_impl.ts","../src/operations/executors/arithmetic_executor.ts","../src/operations/executors/basic_math_executor.ts","../src/executor/tensor_array.ts","../src/operations/executors/control_executor.ts","../src/operations/executors/convolution_executor.ts","../src/operations/executors/creation_executor.ts","../src/operations/executors/dynamic_executor.ts","../src/operations/executors/evaluation_executor.ts","../src/operations/executors/graph_executor.ts","../src/operations/executors/image_executor.ts","../src/operations/executors/logical_executor.ts","../src/operations/executors/matrices_executor.ts","../src/operations/executors/normalization_executor.ts","../src/operations/executors/reduction_executor.ts","../src/operations/executors/slice_join_executor.ts","../src/operations/executors/spectral_executor.ts","../src/operations/executors/transformation_executor.ts","../src/operations/operation_executor.ts","../src/executor/execution_context.ts","../src/executor/model_analysis.ts","../src/executor/graph_executor.ts","../src/executor/graph_model.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/* tslint:disable */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  'DT_INVALID' = 0,\n  'DT_FLOAT' = 1,\n  'DT_DOUBLE' = 2,\n  'DT_INT32' = 3,\n  'DT_UINT8' = 4,\n  'DT_INT16' = 5,\n  'DT_INT8' = 6,\n  'DT_STRING' = 7,\n  'DT_COMPLEX64' = 8,\n  'DT_INT64' = 9,\n  'DT_BOOL' = 10,\n  'DT_QINT8' = 11,\n  'DT_QUINT8' = 12,\n  'DT_QINT32' = 13,\n  'DT_BFLOAT16' = 14,\n  'DT_FLOAT_REF' = 101,\n  'DT_DOUBLE_REF' = 102,\n  'DT_INT32_REF' = 103,\n  'DT_UINT8_REF' = 104,\n  'DT_INT16_REF' = 105,\n  'DT_INT8_REF' = 106,\n  'DT_STRING_REF' = 107,\n  'DT_COMPLEX64_REF' = 108,\n  'DT_INT64_REF' = 109,\n  'DT_BOOL_REF' = 110,\n  'DT_QINT8_REF' = 111,\n  'DT_QUINT8_REF' = 112,\n  'DT_QINT32_REF' = 113,\n  'DT_BFLOAT16_REF' = 114\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {'LEGACY' = 0, 'V1' = 1, 'V2' = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allow you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object is based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\n\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[inputParam.inputIndexStart], tensorMap, context);\n    }\n    if (inputParam.type === 'tensors') {\n      const inputs = node.inputNames.slice(start, end);\n\n      return inputs.map(name => getTensor(name, tensorMap, context));\n    }\n    const data = Array.prototype.slice.call(\n        getTensor(node.inputNames.slice(start)[0], tensorMap, context)\n            .dataSync());\n    return inputParam.type === 'number' ? data[0] : data;\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor based on input name by extracting the node name and\n * output index information.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor {\n  const [nodeName, index] = parseNodeName(name);\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContenxt(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number] {\n  const [nodeName, index] = parseNodeName(inputName);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(name: string): [string, number] {\n  const index = name.lastIndexOf(':');\n  if (index === -1) {\n    return [name, 0];\n  }\n\n  const nodeName = name.substring(0, index);\n  return [nodeName, Number(name.substring(index + 1))];\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'DivNoNan',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'clip_value_min', 'name': 'clipValueMin', 'type': 'number'},\n      {'tfName': 'clip_value_max', 'name': 'clipValueMax', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'real', 'type': 'tensor'},\n      {'start': 1, 'name': 'imag', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'alpha', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'clipValueMin',\n        'name': 'clipValueMin',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'clipValueMax',\n        'name': 'clipValueMax',\n        'type': 'number',\n        'defaultValue': 6\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axes', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'pred', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'pred', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs':\n        [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'frame_name', 'name': 'frameName', 'type': 'string'},\n      {'tfName': 'is_constant', 'name': 'isConstant', 'type': 'bool'}\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'size', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'dynamic_size', 'name': 'dynamicSize', 'type': 'bool'},\n      {'tfName': 'clear_after_read', 'name': 'clearAfterRead', 'type': 'bool'},\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {'tfName': 'tensor_array_name', 'name': 'name', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{\n      'tfName': 'dtype',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}, {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'tensorArrayId', 'type': 'number'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPoolWithArgmax',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'}, {\n        'tfName': 'include_batch_in_index',\n        'name': 'includeBatchInIndex',\n        'type': 'bool'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'stride', 'name': 'stride', 'type': 'number'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'useCudnnOnGpu', 'name': 'useCudnnOnGpu', 'type': 'bool'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': '_FusedConv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'use_cudnn_on_gpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool',\n        'defaultValue': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 2, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 0, 'name': 'outputShape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'FusedDepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [1, 1, 1, 1]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ],\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n      {'start': 1, 'name': 'value', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'num', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'depth', 'type': 'number'},\n      {'start': 2, 'name': 'onValue', 'type': 'number', 'defaultValue': 1},\n      {'start': 3, 'name': 'offValue', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'step', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [{'tfName': 'Tidx', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0.0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'Multinomial',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'logits', 'type': 'tensor'},\n      {'start': 1, 'name': 'numSamples', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'},\n      {'tfName': 'seed2', 'name': 'seed2', 'type': 'number'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'output_dtype', 'name': 'output_dtype', 'type': 'dtype'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV5',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'},\n      {'start': 5, 'name': 'softNmsSigma', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [{\n  'tfOpName': 'TopKV2',\n  'category': 'evaluation',\n  'inputs': [\n    {'start': 0, 'name': 'x', 'type': 'tensor'},\n    {'start': 1, 'name': 'k', 'type': 'number'},\n  ],\n  'attrs': [{'tfName': 'sorted', 'name': 'sorted', 'type': 'bool'}]\n}];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'default', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {'tfOpName': 'Const', 'category': 'graph'}, {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'data', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'message', 'name': 'message', 'type': 'string'}, {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {'tfOpName': 'NoOp', 'category': 'graph', 'inputs': []}, {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'min', 'name': 'min', 'type': 'number'},\n      {'tfName': 'max', 'name': 'max', 'type': 'number'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'image', 'type': 'tensor'},\n      {'start': 1, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 2, 'name': 'boxInd', 'type': 'tensor'},\n      {'start': 3, 'name': 'cropSize', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'method', 'name': 'method', 'type': 'string'}, {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SelectV2',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': '_FusedMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n      {'start': 2, end: 0, 'name': 'args', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'num_args', 'name': 'numArgs', 'type': 'number'}, {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'perm', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {'tfName': 'bias', 'name': 'bias', 'type': 'number', 'defaultValue': 1.0},\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': true,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': -1, 'name': 'tensors', 'type': 'tensors'},\n      {'start': -1, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs':\n        [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 1, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n      {'start': 0, 'name': 'axis', 'type': 'number'}\n    ],\n    'attrs': [{'tfName': 'N', 'name': 'n', 'type': 'number', 'defaultValue': 2}]\n\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'dims', 'type': 'bool', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'size', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'end', 'type': 'number[]'},\n      {'start': 3, 'name': 'strides', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'reps', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'axis', 'type': 'number', 'defaultValue': 0},\n      {'start': 1, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'num_split',\n      'name': 'numOrSizeSplits',\n      'type': 'number',\n      'defaultValue': 1\n    }]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'numOrSizeSplits', 'type': 'number[]'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'values', 'type': 'tensor'},\n      {'start': 2, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': false,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {'tfName': 'DstT', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'constant_value',\n      'name': 'constantValue',\n      'type': 'number',\n      'defaultValue': 0\n    }]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'}, {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'axis',\n      'tfDeprecatedName': 'squeeze_dims',\n      'name': 'axis',\n      'type': 'number[]'\n    }]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'paddings', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'crops', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'block_size', 'name': 'blockSize', 'type': 'number'},\n      {'tfName': 'data_format', 'name': 'dataFormat', 'type': 'string'}\n    ]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {getRegisteredOp} from './custom_op/register';\n\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as spectral from './op_list/spectral';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, logical, image, graph, matrices, normalization, reduction,\n      sliceJoin, spectral, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat(...ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model from Tensorflow GraphDef to local representation for\n  // TensorFlow.js API\n  transformGraph(\n      graph: tensorflow.IGraphDef,\n      signature: tensorflow.ISignatureDef = {}): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op.startsWith('Placeholder')) {\n        placeholders.push(map[node.name]);\n      }\n      if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    let inputs: Node[] = [];\n    const outputs: Node[] = [];\n    let inputNodeNameToKey: {[key: string]: string} = {};\n    let outputNodeNameToKey: {[key: string]: string} = {};\n    if (signature != null) {\n      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);\n      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);\n    }\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        node.inputs.push(nodes[nodeName]);\n        nodes[nodeName].children.push(node);\n      });\n    });\n\n    // if signature has not outputs set, add any node that does not have\n    // outputs.\n    if (Object.keys(outputNodeNameToKey).length === 0) {\n      allNodes.forEach(key => {\n        const node = nodes[key];\n        if (node.children.length === 0) {\n          outputs.push(node);\n        }\n      });\n    } else {\n      Object.keys(outputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node != null) {\n          node.signatureKey = outputNodeNameToKey[name];\n          outputs.push(node);\n        }\n      });\n    }\n\n    if (Object.keys(inputNodeNameToKey).length > 0) {\n      Object.keys(inputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node) {\n          node.signatureKey = inputNodeNameToKey[name];\n          inputs.push(node);\n        }\n      });\n    } else {\n      inputs = placeholders;\n    }\n\n    return {nodes, inputs, outputs, weights, placeholders, signature};\n  }\n\n  private mapSignatureEntries(entries: {[k: string]: tensorflow.ITensorInfo}) {\n    return Object.keys(entries || {})\n        .reduce<{[key: string]: string}>((prev, curr) => {\n          prev[entries[curr].name] = curr;\n          return prev;\n        }, {});\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.substr(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  const global = env().global;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value : parseInt(value, 10);\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n    case tensorflow.DataType.DT_INT64:\n    case tensorflow.DataType.DT_INT8:\n    case tensorflow.DataType.DT_UINT8:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim =>\n            (typeof dim.size === 'number') ? dim.size : parseInt(dim.size, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f :\n                                                   param.list.i) ||\n            [])\n        .map(v => (typeof v === 'number') ? v : parseInt(v, 10));\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    });\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    });\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BiasAdd':\n    case 'AddV2':\n    case 'Add': {\n      return [tfc.add(\n          (getParamValue('a', node, tensorMap, context) as tfc.Tensor),\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'AddN': {\n      return [tfc.addN((\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[]))];\n    }\n    case 'FloorMod':\n    case 'Mod':\n      return [tfc.mod(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'Mul':\n      return [tfc.mul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'RealDiv':\n    case 'Div': {\n      return [tfc.div(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'DivNoNan': {\n      return [tfc.divNoNan(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'FloorDiv': {\n      return [tfc.floorDiv(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sub': {\n      return [tfc.sub(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Minimum': {\n      return [tfc.minimum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Maximum': {\n      return [tfc.maximum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Pow': {\n      return [tfc.pow(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SquaredDifference': {\n      return [tfc.squaredDifference(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'arithmetic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Abs':\n    case 'ComplexAbs':\n      return [tfc.abs(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acos':\n      return [tfc.acos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acosh':\n      return [tfc.acosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asin':\n      return [tfc.asin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asinh':\n      return [tfc.asinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan':\n      return [tfc.atan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan2':\n      return [tfc.atan2(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atanh':\n      return [tfc.atanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Ceil':\n      return [tfc.ceil(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Complex':\n      return [tfc.complex(\n          getParamValue('real', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('imag', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cos':\n      return [tfc.cos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cosh':\n      return [tfc.cosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Elu':\n      return [tfc.elu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Erf':\n      return [tfc.erf(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Exp':\n      return [tfc.exp(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Expm1': {\n      return [tfc.expm1(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Floor':\n      return [tfc.floor(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log':\n      return [tfc.log(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log1p': {\n      return [tfc.log1p(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Imag':\n      return [tfc.imag(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n\n    case 'Neg':\n      return [tfc.neg(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Reciprocal': {\n      return [tfc.reciprocal(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Real':\n      return [tfc.real(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu':\n      return [tfc.relu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Round': {\n      return [tfc.round(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Selu':\n      return [tfc.selu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sigmoid':\n      return [tfc.sigmoid(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sin':\n      return [tfc.sin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sign': {\n      return [tfc.sign(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sinh': {\n      return [tfc.sinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Softplus': {\n      return [tfc.softplus(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sqrt': {\n      return [tfc.sqrt(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Square': {\n      return [tfc.square(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tanh': {\n      return [tfc.tanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tan':\n      return [tfc.tan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu6':\n    case 'ClipByValue':\n      return [tfc.clipByValue(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('clipValueMin', node, tensorMap, context) as number,\n          getParamValue('clipValueMax', node, tensorMap, context) as number)];\n    case 'Rsqrt':\n      return [tfc.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];\n    case 'Prod':\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('axes', node, tensorMap, context) as number[])];\n    case 'LeakyRelu':\n      return [tfc.leakyRelu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('alpha', node, tensorMap, context) as number)];\n    case 'Prelu':\n      return [tfc.prelu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('alpha', node, tensorMap, context) as tfc.Tensor)];\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'basic_math';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, slice, stack, Tensor, tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private static nextId = 0;\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly id: number;\n  constructor(\n      public readonly name: string, public readonly dtype: DataType,\n      private maxSize: number, private elementShape: number[],\n      public readonly identicalElementShapes: boolean,\n      public readonly dynamicSize: boolean,\n      public readonly clearAfterRead: boolean) {\n    this.id = TensorArray.nextId++;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Close the current TensorArray.\n   */\n  clearAndClose() {\n    this.tensors.forEach(tensor => tensor.tensor.dispose());\n    this.tensors = [];\n    this.closed_ = true;\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.tensors.length) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.tensors.length}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t && t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t && t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices nummber[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = tensor.reshape([1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = slice(tensor, indices, sizes).reshape(this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n\n  /**\n   * This differs from util.assertShapesMatch in that it allows values of\n   * negative one, an undefined size of a dimensinon, in a shape to match\n   * anything.\n   */\n  private assertShapesMatchAllowUndefinedSize(\n      shapeA: number[], shapeB: number[], errorMessagePrefix = ''): void {\n    util.assert(\n        this.shapesEqualAllowUndefinedSize(shapeA, shapeB),\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n\n  private shapesEqualAllowUndefinedSize(n1: number[], n2: number[]) {\n    if (n1.length !== n2.length) {\n      return false;\n    }\n    for (let i = 0; i < n1.length; i++) {\n      if (n1[i] !== -1 && n2[i] !== -1 && n1[i] !== n2[i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {scalar} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> => {\n  switch (node.op) {\n    case 'LoopCond':\n      return [\n        (getParamValue('pred', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    case 'Switch': {\n      const pred =\n          getParamValue('pred', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor;\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data.clone()] :\n                                      [data.clone(), undefined];\n    }\n    case 'Merge':\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      return inputName ? [getTensor(inputName, tensorMap, context).clone()] :\n                         undefined;\n\n    case 'Enter':\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.enterFrame(frameId);\n      return [data.clone()];\n\n    case 'Exit':\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.exitFrame();\n      return [tensor.clone()];\n\n    case 'NextIteration':\n      const input =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.nextIteration();\n      return [input.clone()];\n\n    case 'TensorArrayV3':\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [scalar(tensorArray.id), scalar(1.0)];\n\n    case 'TensorArrayWriteV3':\n      const id =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const writeTensorArray = context.getTensorArray(id);\n      writeTensorArray.write(index, writeTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArrayReadV3':\n      const readId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId);\n      return [readTensorArray.read(readIndex)];\n\n    case 'TensorArrayGatherV3':\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n\n    case 'TensorArrayScatterV3':\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArrayConcatV3':\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const concatTensorArray = context.getTensorArray(concatId);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      return [concatTensorArray.concat(concatDtype)];\n\n    case 'TensorArraySplitV3':\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId);\n      splitTensorArray.split(lengths, splitTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArraySizeV3':\n      const sizeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const sizeTensorArray = context.getTensorArray(sizeId);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n\n    case 'TensorArrayCloseV3':\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const closeTensorArray = context.getTensorArray(closeId);\n      closeTensorArray.clearAndClose();\n      return [scalar(0)];\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'control';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Conv1D': {\n      const stride =\n          getParamValue('stride', node, tensorMap, context) as number;\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilation =\n          getParamValue('dilation', node, tensorMap, context) as number;\n      return [tfc.conv1d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor3D,\n          stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n          dilation)];\n    }\n    case 'Conv2D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      return [tfc.conv2d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          [stride[1], stride[2]], pad as 'valid' | 'same',\n          dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n    }\n    case '_FusedConv2D':\n    case 'FusedDepthwiseConv2dNative': {\n      const [extraOp, activationFunc] =\n          (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n      const isBiasAdd = extraOp === 'biasadd';\n      const isPrelu = activationFunc === 'prelu';\n      const isBatchNorm = extraOp === 'fusedbatchnorm';\n\n      const numArgs =\n          (getParamValue('numArgs', node, tensorMap, context) as number);\n      if (isBiasAdd) {\n        if (isPrelu && numArgs !== 2) {\n          throw new Error(\n              'FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu ' +\n              'must have two extra arguments: bias and alpha.');\n        }\n        if (!isPrelu && numArgs !== 1) {\n          throw new Error(\n              'FusedConv2d and DepthwiseConv2d with BiasAdd must have ' +\n              'one extra argument: bias.');\n        }\n      }\n      if (isBatchNorm) {\n        throw new Error(\n            'FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.');\n      }\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      const [biasArg, preluArg] =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n      const kernelMethod = node.op === '_FusedConv2D' ?\n          tfc.fused.conv2d :\n          tfc.fused.depthwiseConv2d;\n      return [kernelMethod({\n        x: getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n            tfc.Tensor4D,\n        filter: getParamValue('filter', node, tensorMap, context) as\n            tfc.Tensor4D,\n        strides: [stride[1], stride[2]],\n        pad: pad as 'valid' | 'same',\n        dataFormat: dataFormat as 'NHWC' | 'NCHW',\n        dilations: [dilations[1], dilations[2]],\n        bias: biasArg,\n        activation: activationFunc as tfc.fused.Activation,\n        preluActivationWeights: preluArg\n      })];\n    }\n    case 'Conv2DBackpropInput':\n    case 'Conv2dTranspose': {\n      const shape = getParamValue(\n                        'outputShape', node, tensorMap,\n                        context) as [number, number, number] |\n          [number, number, number, number];\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      return [tfc.conv2dTranspose(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n    }\n    case 'DepthwiseConv2dNative':\n    case 'DepthwiseConv2d': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n\n      return [tfc.depthwiseConv2d(\n          getParamValue('input', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n          [stride[1], stride[2]], pad as 'valid' | 'same',\n          dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n    }\n    case 'Conv3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as string)\n              .toUpperCase();\n      const dilations =\n          getParamValue('dilations', node, tensorMap, context) as number[];\n      return [tfc.conv3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D |\n              tfc.Tensor<tfc.Rank.R5>,\n          getParamValue('filter', node, tensorMap, context) as\n              tfc.Tensor<tfc.Rank.R5>,\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n          dataFormat as 'NDHWC' | 'NCDHW',\n          [dilations[1], dilations[2], dilations[3]])];\n    }\n    case 'AvgPool': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.avgPool(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same')];\n    }\n    case 'MaxPool': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.maxPool(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same')];\n    }\n    case 'MaxPoolWithArgmax': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n      const includeBatchInIndex =\n          getParamValue('includeBatchInIndex', node, tensorMap, context) as\n          boolean;\n      const {result, indexes} = tfc.maxPoolWithArgmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D,\n          [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n          pad as 'valid' | 'same', includeBatchInIndex);\n      return [result, indexes];\n    }\n    case 'AvgPool3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.avgPool3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n          [kernelSize[1], kernelSize[2], kernelSize[3]],\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n    }\n\n    case 'MaxPool3D': {\n      const stride =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const pad = getParamValue('pad', node, tensorMap, context);\n      const kernelSize =\n          getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n      return [tfc.maxPool3d(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n          [kernelSize[1], kernelSize[2], kernelSize[3]],\n          [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n    }\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'convolution';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Fill': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const value = getParamValue('value', node, tensorMap, context) as number;\n      return [tfc.fill(shape, value, dtype)];\n    }\n    case 'LinSpace': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const num = getParamValue('num', node, tensorMap, context) as number;\n      return [tfc.linspace(start, stop, num)];\n    }\n    case 'Multinomial': {\n      const logits =\n          getParamValue('logits', node, tensorMap, context) as tfc.Tensor1D;\n      const numSamples =\n          getParamValue('numSamples', node, tensorMap, context) as number;\n      const seed = getParamValue('seed', node, tensorMap, context) as number;\n      return [tfc.multinomial(logits, numSamples, seed)];\n    }\n    case 'OneHot': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      const depth = getParamValue('depth', node, tensorMap, context) as number;\n      const onValue =\n          getParamValue('onValue', node, tensorMap, context) as number;\n      const offValue =\n          getParamValue('offValue', node, tensorMap, context) as number;\n      return [tfc.oneHot(indices, depth, onValue, offValue)];\n    }\n    case 'Ones': {\n      return [tfc.ones(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'OnesLike': {\n      return [tfc.onesLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'RandomUniform': {\n      return [tfc.randomUniform(\n          // tslint:disable-next-line:no-any\n          getParamValue('shape', node, tensorMap, context) as any,\n          getParamValue('minval', node, tensorMap, context) as number,\n          getParamValue('maxval', node, tensorMap, context) as number,\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'Range': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const step = getParamValue('step', node, tensorMap, context) as number;\n      return [tfc.range(\n          start, stop, step,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32')];\n    }\n    case 'TruncatedNormal': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const mean = getParamValue('mean', node, tensorMap, context) as number;\n      const stdDev =\n          getParamValue('stdDev', node, tensorMap, context) as number;\n      const seed = getParamValue('seed', node, tensorMap, context) as number;\n      return [tfc.truncatedNormal(\n          shape, mean, stdDev,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32',\n          seed)];\n    }\n    case 'Zeros': {\n      return [tfc.zeros(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'ZerosLike': {\n      return [tfc.zerosLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'creation';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> => {\n  switch (node.op) {\n    case 'NonMaxSuppressionV5':\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const scores =\n          getParamValue('scores', node, tensorMap, context) as tfc.Tensor;\n      const maxOutputSize =\n          getParamValue('maxOutputSize', node, tensorMap, context) as number;\n      const iouThreshold =\n          getParamValue('iouThreshold', node, tensorMap, context) as number;\n      const scoreThreshold =\n          getParamValue('scoreThreshold', node, tensorMap, context) as number;\n\n      if (node.op === 'NonMaxSuppressionV5') {\n        const softNmsSigma =\n            getParamValue('softNmsSigma', node, tensorMap, context) as number;\n\n        const result = await tfc.image.nonMaxSuppressionWithScoreAsync(\n            boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n            iouThreshold, scoreThreshold, softNmsSigma);\n\n        return [result.selectedIndices, result.selectedScores];\n      }\n\n      return [await tfc.image.nonMaxSuppressionAsync(\n          boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n          iouThreshold, scoreThreshold)];\n    }\n    case 'Where': {\n      const condition =\n          (getParamValue('condition', node, tensorMap, context) as tfc.Tensor)\n              .asType('bool');\n      const result = [await tfc.whereAsync(condition)];\n      condition.dispose();\n      return result;\n    }\n    case 'ListDiff': {\n      return tfc.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'dynamic';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'TopKV2': {\n          const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n          const k = getParamValue('k', node, tensorMap, context) as number;\n          const sorted =\n              getParamValue('sorted', node, tensorMap, context) as boolean;\n          const result = tfc.topk(x, k, sorted);\n          return [result.values, result.indices];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'evaluation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Const': {\n      return tensorMap[node.name];\n    }\n    case 'PlaceholderWithDefault':\n      const def =\n          getParamValue('default', node, tensorMap, context) as tfc.Tensor;\n      return [getTensor(node.name, tensorMap, context) || def];\n    case 'Placeholder':\n      return [getTensor(node.name, tensorMap, context)];\n    case 'Identity':\n    case 'StopGradient':\n    case 'FakeQuantWithMinMaxVars':  // This op is currently ignored.\n      return [\n        (getParamValue('x', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    case 'IdentityN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => t.clone());\n    case 'Snapshot':\n      const snapshot =\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor);\n      return [snapshot.clone()];\n    case 'Shape':\n      return [tfc.tensor1d(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).shape,\n          'int32')];\n    case 'ShapeN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => tfc.tensor1d(t.shape));\n    case 'Size':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).size,\n          'int32')];\n    case 'Rank':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).rank,\n          'int32')];\n    case 'NoOp':\n      return [tfc.scalar(1)];\n    case 'Print':\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor[];\n      const message =\n          getParamValue('message', node, tensorMap, context) as string;\n      const summarize =\n          getParamValue('summarize', node, tensorMap, context) as number;\n      console.warn(\n          'The graph has a tf.print() operation,' +\n          'usually used for debugging, which slows down performance.');\n      console.log(message);\n      for (let i = 0; i < data.length; i++) {\n        console.log(\n            Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));\n      }\n      return [input];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'graph';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ResizeBilinear': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeBilinear(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'ResizeNearestNeighbor': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeNearestNeighbor(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'CropAndResize': {\n      const image =\n          getParamValue('image', node, tensorMap, context) as tfc.Tensor;\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const boxInd =\n          getParamValue('boxInd', node, tensorMap, context) as tfc.Tensor;\n      const cropSize =\n          getParamValue('cropSize', node, tensorMap, context) as number[];\n      const method =\n          getParamValue('method', node, tensorMap, context) as string;\n      const extrapolationValue =\n          getParamValue('extrapolationValue', node, tensorMap, context) as\n          number;\n      return [tfc.image.cropAndResize(\n          image as tfc.Tensor4D, boxes as tfc.Tensor2D, boxInd as tfc.Tensor1D,\n          cropSize as [number, number], method as 'bilinear' | 'nearest',\n          extrapolationValue)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'image';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                              tensorMap: NamedTensorsMap,\n                                              context: ExecutionContext):\n                                                 tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Equal': {\n      return [tfc.equal(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'NotEqual': {\n      return [tfc.notEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Greater': {\n      return [tfc.greater(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'GreaterEqual': {\n      return [tfc.greaterEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Less': {\n      return [tfc.less(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LessEqual': {\n      return [tfc.lessEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalAnd': {\n      return [tfc.logicalAnd(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalNot': {\n      return [tfc.logicalNot(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalOr': {\n      return [tfc.logicalOr(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Select':\n    case 'SelectV2': {\n      return [tfc.where(\n          getParamValue('condition', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'logical';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BatchMatMul':\n    case 'BatchMatMulV2':\n    case 'MatMul':\n      return [tfc.matMul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('transposeA', node, tensorMap, context) as boolean,\n          getParamValue('transposeB', node, tensorMap, context) as boolean)];\n\n    case 'Transpose':\n      return [tfc.transpose(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('perm', node, tensorMap, context) as number[])];\n\n    case '_FusedMatMul':\n      const [extraOp, activationFunc] =\n          (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n      const isBiasAdd = extraOp === 'biasadd';\n      const isPrelu = activationFunc === 'prelu';\n\n      const numArgs =\n          (getParamValue('numArgs', node, tensorMap, context) as number);\n      if (isBiasAdd) {\n        if (isPrelu && numArgs !== 2) {\n          throw new Error(\n              'Fused MatMul with BiasAdd and Prelu must have two ' +\n              'extra arguments: bias and alpha.');\n        }\n        if (!isPrelu && numArgs !== 1) {\n          throw new Error(\n              'Fused MatMul with BiasAdd must have one extra argument: bias.');\n        }\n      }\n      const [biasArg, preluArg] =\n          getParamValue('args', node, tensorMap, context) as tfc.Tensor[];\n      return [tfc.fused.matMul({\n        a: getParamValue('a', node, tensorMap, context) as tfc.Tensor2D,\n        b: getParamValue('b', node, tensorMap, context) as tfc.Tensor2D,\n        transposeA: getParamValue('transposeA', node, tensorMap, context) as\n            boolean,\n        transposeB: getParamValue('transposeB', node, tensorMap, context) as\n            boolean,\n        bias: biasArg,\n        activation: activationFunc as tfc.fused.Activation,\n        preluActivationWeights: preluArg\n      })];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'matrices';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'FusedBatchNorm':\n    case 'FusedBatchNormV2': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'FusedBatchNormV3': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'LRN': {\n      return [tfc.localResponseNormalization(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('radius', node, tensorMap, context) as number,\n          getParamValue('bias', node, tensorMap, context) as number,\n          getParamValue('alpha', node, tensorMap, context) as number,\n          getParamValue('beta', node, tensorMap, context) as number)];\n    }\n    case 'Softmax': {\n      return [tfc.softmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogSoftmax': {\n      return [tfc.logSoftmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SparseToDense': {\n      return [tfc.sparseToDense(\n          getParamValue('sparseIndices', node, tensorMap, context) as\n              tfc.Tensor,\n          getParamValue('outputShape', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('sparseValues', node, tensorMap, context) as number[],\n          getParamValue('defaultValue', node, tensorMap, context) as\n              tfc.Scalar)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'normalization';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Max': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.max(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Mean': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.mean(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Min': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.min(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Sum': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.sum(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'All': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.all(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Any': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.any(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'ArgMax': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'ArgMin': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Prod': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'reduction';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ConcatV2':\n    case 'Concat': {\n      const n = getParamValue('n', node, tensorMap, context) as number;\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      let inputs =\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n      inputs = inputs.slice(0, n);\n      return [tfc.concat(inputs, axis)];\n    }\n    case 'GatherV2':\n    case 'Gather': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      return [tfc.gather(input, indices.asType('int32'), axis)];\n    }\n    case 'ReverseV2':\n    case 'Reverse': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.reverse(input, axis)];\n    }\n    case 'Slice': {\n      // tslint:disable-next-line:no-any\n      const begin = getParamValue('begin', node, tensorMap, context) as any;\n      // tslint:disable-next-line:no-any\n      const size = getParamValue('size', node, tensorMap, context) as any;\n      return [tfc.slice(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, begin,\n          size)];\n    }\n    case 'StridedSlice': {\n      const begin =\n          getParamValue('begin', node, tensorMap, context) as number[];\n      const end = getParamValue('end', node, tensorMap, context) as number[];\n      const strides =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const beginMask =\n          getParamValue('beginMask', node, tensorMap, context) as number;\n      const endMask =\n          getParamValue('endMask', node, tensorMap, context) as number;\n      const ellipsisMask =\n          getParamValue('ellipsisMask', node, tensorMap, context) as number;\n      const newAxisMask =\n          getParamValue('newAxisMask', node, tensorMap, context) as number;\n      const shrinkAxisMask =\n          getParamValue('shrinkAxisMask', node, tensorMap, context) as number;\n      const tensor = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      if (begin.length === 1 && tensor.shape.length > 1) {\n        for (let i = 1; i < tensor.shape.length; i++) {\n          begin.push(0);\n          end.push(tensor.shape[i]);\n          strides.push(strides[0]);\n        }\n      }\n      return [tfc.stridedSlice(\n          tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask)];\n    }\n    case 'Pack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensors =\n            getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n        // Reshape the tensors to the first tensor's shape if they don't match.\n        const shape = tensors[0].shape;\n        const squeezedShape = tensors[0].squeeze().shape;\n        const mapped = tensors.map(tensor => {\n          const sameShape = tfc.util.arraysEqual(tensor.shape, shape);\n          if (!sameShape &&\n              !tfc.util.arraysEqual(tensor.squeeze().shape, squeezedShape)) {\n            throw new Error('the input tensors shape does not match');\n          }\n          return sameShape ? tensor : tensor.reshape(shape);\n        });\n        return [tfc.stack(mapped, axis)];\n      });\n    }\n    case 'Unpack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensor =\n            getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n        return tfc.unstack(tensor, axis);\n      });\n    }\n    case 'Tile': {\n      const reps = getParamValue('reps', node, tensorMap, context) as number[];\n      return [tfc.tile(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, reps)];\n    }\n    case 'Split':\n    case 'SplitV': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const numOrSizeSplits =\n          getParamValue('numOrSizeSplits', node, tensorMap, context) as number |\n          number[];\n      return tfc.split(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          numOrSizeSplits, axis);\n    }\n    case 'ScatterNd': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as tfc.Tensor;\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      return [tfc.scatterND(indices, values, shape)];\n    }\n    case 'GatherNd': {\n      const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.gatherND(x, indices)];\n    }\n    case 'SparseToDense': {\n      const indices =\n          getParamValue('sparseIndices', node, tensorMap, context) as\n          tfc.Tensor;\n      const shape =\n          getParamValue('outputShape', node, tensorMap, context) as number[];\n      const sparseValues =\n          getParamValue('sparseValues', node, tensorMap, context) as tfc.Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as tfc.Scalar;\n      return [tfc.sparseToDense(\n          indices, sparseValues, shape,\n          sparseValues.dtype === defaultValue.dtype ?\n              defaultValue :\n              defaultValue.asType(sparseValues.dtype))];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'slice_join';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'FFT': {\n          return [tfc.fft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IFFT': {\n          return [tfc.ifft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'RFFT': {\n          return [tfc.rfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IRFFT': {\n          return [tfc.irfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'spectral';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, split} from './utils';\n\nexport const executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Cast': {\n      return [tfc.cast(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('dtype', node, tensorMap, context) as 'int32' |\n              'float32' | 'bool')];\n    }\n    case 'ExpandDims': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.expandDims(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Squeeze': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      return [tfc.squeeze(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n\n    case 'Reshape': {\n      return [tfc.reshape(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('shape', node, tensorMap, context) as number[])];\n    }\n    case 'PadV2':\n    case 'Pad': {\n      return [tfc.pad(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          split(\n              getParamValue('padding', node, tensorMap, context) as number[],\n              2) as Array<[number, number]>,\n          getParamValue('constantValue', node, tensorMap, context) as number)];\n    }\n    case 'SpaceToBatchND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const paddings = split(\n          getParamValue('paddings', node, tensorMap, context) as number[], 2);\n      return [tfc.spaceToBatchND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, paddings)];\n    }\n    case 'BatchToSpaceND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const crops = split(\n          getParamValue('crops', node, tensorMap, context) as number[], 2);\n      return [tfc.batchToSpaceND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, crops)];\n    }\n    case 'DepthToSpace': {\n      const blockSize =\n          getParamValue('blockSize', node, tensorMap, context) as number;\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as\n           string).toUpperCase() as 'NHWC' |\n          'NCHW';\n      return [tfc.depthToSpace(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D,\n          blockSize, dataFormat)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'transformation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[]|Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return tfc.tidy(\n                () => arithmetic.executeOp(node, tensorMap, context));\n          case 'basic_math':\n            return tfc.tidy(\n                () => basicMath.executeOp(node, tensorMap, context));\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return tfc.tidy(\n                () => convolution.executeOp(node, tensorMap, context));\n          case 'creation':\n            return tfc.tidy(() => creation.executeOp(node, tensorMap, context));\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return tfc.tidy(\n                () => evaluation.executeOp(node, tensorMap, context));\n          case 'image':\n            return tfc.tidy(() => image.executeOp(node, tensorMap, context));\n          case 'graph':\n            return tfc.tidy(() => graph.executeOp(node, tensorMap, context));\n          case 'logical':\n            return tfc.tidy(() => logical.executeOp(node, tensorMap, context));\n          case 'matrices':\n            return tfc.tidy(() => matrices.executeOp(node, tensorMap, context));\n          case 'normalization':\n            return tfc.tidy(\n                () => normalization.executeOp(node, tensorMap, context));\n          case 'reduction':\n            return tfc.tidy(\n                () => reduction.executeOp(node, tensorMap, context));\n          case 'slice_join':\n            return tfc.tidy(\n                () => sliceJoin.executeOp(node, tensorMap, context));\n          case 'spectral':\n            return tfc.tidy(() => spectral.executeOp(node, tensorMap, context));\n          case 'transformation':\n            return tfc.tidy(\n                () => transformation.executeOp(node, tensorMap, context));\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (value instanceof Promise) {\n    return value.then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      public readonly weightMap: NamedTensorsMap,\n      public readonly tensorArrayMap: TensorArrayMap) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[],\n    weightMap: NamedTensorsMap): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      Object.keys(inputs).map(name => parseNodeName(name)[0]);\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n\n    if (inputNodeNames.indexOf(node.name) !== -1) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, weightMap: NamedTensorsMap,\n    executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const frontier: Node[] = [];\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  inputNodes.forEach(input => {\n    if (usedNodes.has(input.name)) {\n      frontier.push(input);\n    }\n  });\n  graph.weights.forEach(weight => {\n    if (usedNodes.has(weight.name)) {\n      frontier.push(weight);\n    }\n  });\n  const seen = new Set<string>();\n  const orderedNodes: Node[] = [];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    seen.add(node.name);\n    if (!weightMap[node.name]) {\n      orderedNodes.push(node);\n    }\n    node.children.forEach(child => {\n      if (!seen.has(child.name) && usedNodes.has(child.name) &&\n          child.inputs.every(input => seen.has(input.name))) {\n        frontier.push(child);\n      }\n    });\n  }\n  return orderedNodes;\n}\n\nconst CONTROL_FLOW_OPS = ['Switch', 'Merge', 'Enter', 'Exit', 'NextIteration'];\nconst DYNAMIC_SHAPE_OPS = [\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n];\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private SEPERATOR = ',';\n  get weightMap(): NamedTensorsMap {\n    return this._weightMap;\n  }\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this.weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map(node => node.signatureKey || node.name);\n  }\n\n  constructor(private graph: Graph) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._signature = graph.signature;\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  execute(inputs: NamedTensorMap, outputs: string[]): Tensor[] {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes =\n        outputs.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n    const tensorArrayMap: TensorArrayMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this._weightMap, tensorArrayMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context) as Tensor[];\n          if (tensors instanceof Promise) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep, outputs,\n              intermediateTensorConsumerCount);\n        }\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs: string[]):\n      Promise<Tensor[]> {\n    inputs = this.mapInputs(inputs);\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const tensorArrayMap: TensorArrayMap = {};\n    const context = new ExecutionContext(this._weightMap, tensorArrayMap);\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap =\n        await this.executeWithControlFlow(inputs, context, outputs);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = new Set<number>(results.map(t => t.id));\n    const inputIds =\n        new Set<number>(Object.keys(inputs).map(name => inputs[name].id));\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !outputIds.has(tensor.id) &&\n            !inputIds.has(tensor.id) &&\n            this.weightIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n    });\n    return results;\n  }\n\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext,\n      outputNames: string[]): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodes =\n        outputNames.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(inputs, outputNodes, this.weightMap);\n\n    const stack: NodeWithContexts[] =\n        [...inputNodes, ...this.graph.weights].map(node => {\n          return {node, contexts: context.currentContext};\n        });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not provided as input nodes.\n      if (inputNodes.indexOf(item.node) === -1) {\n        const tensors = executeOp(item.node, tensorMap, context);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (tensors instanceof Promise) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null &&\n          this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null &&\n          this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\n/**\n * A `tf.GraphModel` is a directed, acyclic graph of built from\n * SavedModel GraphDef and allows inference exeuction.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class GraphModel implements InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: io.IOHandler;\n  private artifacts: io.ModelArtifacts;\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: string|io.IOHandler,\n      private loadOptions: io.LoadOptions = {}) {\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n  }\n\n  private findIOHandler() {\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as io.IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = io.browserHTTPRequest(path as string, this.loadOptions);\n    } else {\n      const handlers =\n          io.getLoadHandlers(path as string, this.loadOptions.onProgress);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0];\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  async load(): Promise<boolean> {\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n    this.artifacts = await this.handler.load();\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n    let signature = {};\n    if (this.artifacts.userDefinedMetadata != null) {\n      signature =  // tslint:disable-next-line:no-any\n          (this.artifacts.userDefinedMetadata as any).signature as\n          tensorflow.ISignatureDef;\n    }\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    const weightMap =\n        io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   */\n  /**\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size and\n   * output node names. Currently the batch size option is ignored for graph\n   * model.\n   *\n   * @returns Inference result tensors. The output would be single `tf.Tensor`\n   * if model has single output node, otherwise Tensor[] or NamedTensorMap[]\n   * will be returned for model with multiple outputs.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    return this.execute(inputs, this.outputNodes);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n    if (inputs.length !== this.inputNodes.length) {\n      throw new Error(\n          'Input tensor count mismatch,' +\n          `the graph model has ${this.inputNodes.length} placeholders, ` +\n          `while there are ${inputs.length} input tensors.`);\n    }\n    return this.inputNodes.reduce((map, inputName, i) => {\n      map[inputName] = (inputs as Tensor[])[i];\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  dispose() {\n    this.executor.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction with\n * a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send credentials\n *    and custom headers.\n */\n/** @doc {heading: 'Models', subheading: 'Loading'} */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler,\n    options: io.LoadOptions = {}): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub) {\n    if ((modelUrl as io.IOHandler).load == null) {\n      if (!(modelUrl as string).endsWith('/')) {\n        modelUrl = (modelUrl as string) + '/';\n      }\n      modelUrl = `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n    }\n  }\n  const model = new GraphModel(modelUrl, options);\n  await model.load();\n  return model;\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '1.7.4';\nexport {version};\n"]},"metadata":{},"sourceType":"module"}